{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9863aae-afda-4686-9dc2-06177ab7fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/network/xz4134/miniconda/miniconda_envs/repe/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import copy\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pynvml\n",
    "\n",
    "# from repe import repe_pipeline_registry\n",
    "# repe_pipeline_registry()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    print(pynvml.nvmlDeviceGetName(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b908a11-a597-44da-8a44-933d3450f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "use_fast_tokenizer = \"LlamaForCausalLM\" not in model.config.architectures\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=use_fast_tokenizer, padding_side=\"left\", legacy=False)\n",
    "tokenizer.pad_token_id = 0 \n",
    "\n",
    "user_tag = \"USER:\"\n",
    "assistant_tag = \"ASSISTANT:\"\n",
    "\n",
    "# Uncomment for first time loading the dataset\n",
    "# ds = load_dataset('tatsu-lab/alpaca', cache_dir='../../storage/cache')\n",
    "# ds.save_to_disk(\"../../storage/cache/alpaca_filtered/\")\n",
    "\n",
    "ds = load_from_disk('../../storage/cache/alpaca_filtered/')\n",
    "instructions = ds['train']['instruction']\n",
    "outputs = ds['train']['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_start = \"{user_tag} {instruction} {aug_start}\"\n",
    "template_end = \"{aug_end} {assistant_tag} {response}\"\n",
    "# Not sure why they set this offset\n",
    "cutoff_offset = 0\n",
    "\n",
    "def get_augmented_ds_tokenmod(instructions,\n",
    "                              responses,\n",
    "                              aug_start,\n",
    "                              aug_var,\n",
    "                              aug_end,\n",
    "                              max_res_len,\n",
    "                              num_examples,\n",
    "                              user_tag,\n",
    "                              assistant_tag,\n",
    "                              aug_var_length=1,\n",
    "                              ):\n",
    "    \n",
    "    ds = []\n",
    "    aug_var_tokens = tokenizer.tokenize(aug_var)\n",
    "    assert len(aug_var_tokens) == aug_var_length, aug_var_tokens\n",
    "\n",
    "    for i, (q, a) in tqdm(enumerate(zip(instructions, responses))):\n",
    "        \n",
    "        # Replaced \\n since it resulted in nontrivial peak\n",
    "        # s_tokens = tokenizer.tokenize(s)\n",
    "        a_tokens = tokenizer.tokenize(a.replace(\"\\n\", \"\"))\n",
    "\n",
    "        l_start = template_start.format(\n",
    "            user_tag=user_tag,\n",
    "            instruction=q,\n",
    "            aug_start=aug_start\n",
    "        )\n",
    "\n",
    "        l_end_base = template_end.format(\n",
    "            aug_end=aug_end,\n",
    "            assistant_tag=assistant_tag,\n",
    "            response=\"\",\n",
    "        )\n",
    "        end_token_offset = len(tokenizer.tokenize(l_end_base))\n",
    "\n",
    "        for cutoff in range(1, min(max_res_len, len(a_tokens)) - cutoff_offset):\n",
    "            a_truncated = tokenizer.convert_tokens_to_string(a_tokens[:cutoff])\n",
    "            l_end = template_end.format(\n",
    "                aug_end=aug_end,\n",
    "                assistant_tag=assistant_tag,\n",
    "                response=a_truncated,\n",
    "            )\n",
    "            neg_aug_var_offset = -end_token_offset - cutoff + 1\n",
    "            var_token_inds = list(range(neg_aug_var_offset - aug_var_length, neg_aug_var_offset))\n",
    "            l = \" \".join([l_start, aug_var, l_end])\n",
    "            ds.append([l, var_token_inds, (i, cutoff)])         \n",
    "            if len(ds) >= num_examples:\n",
    "                break\n",
    "        if len(ds) >= num_examples:\n",
    "            break\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 751.13it/s]\n",
      "17it [00:00, 769.13it/s]\n"
     ]
    }
   ],
   "source": [
    "max_res_len = 128\n",
    "n_samples = 1000\n",
    "\n",
    "aug_start = \"Respond with a\"\n",
    "aug_end = \"tone.\"\n",
    "\n",
    "aug_neutral = \"normal\"\n",
    "aug_target = \"angry\"\n",
    "aug_token_len = 1\n",
    "\n",
    "neutral_ds = get_augmented_ds_tokenmod(\n",
    "    instructions,\n",
    "    outputs,\n",
    "    aug_start,\n",
    "    aug_neutral,\n",
    "    aug_end,\n",
    "    max_res_len,\n",
    "    n_samples,\n",
    "    user_tag,\n",
    "    assistant_tag,\n",
    "    aug_token_len\n",
    ")\n",
    "\n",
    "target_ds = get_augmented_ds_tokenmod(\n",
    "    instructions,\n",
    "    outputs,\n",
    "    aug_start,\n",
    "    aug_target,\n",
    "    aug_end,\n",
    "    max_res_len,\n",
    "    n_samples,\n",
    "    user_tag,\n",
    "    assistant_tag,\n",
    "    aug_token_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_reps(model, tokenizer, input_str, rep_tokens=[-1]):\n",
    "    inputs = tokenizer(input_str, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "    return [m[:, rep_tokens] for m in outputs.hidden_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_embedding(seq, tokenizer, model):\n",
    "    \n",
    "    tokens = tokenizer(seq, return_tensors=\"pt\").to(model.model.device)\n",
    "    embedding = (model.model.embed_tokens(tokens['input_ids'][:, 1:]))\n",
    "    return embedding.squeeze().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping classes for customized injection\n",
    "\n",
    "class WrappedModBlock(torch.nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super().__init__()\n",
    "        self.block = block\n",
    "        self.mod = None\n",
    "        self.pos = None\n",
    "        self.mask = None\n",
    "        self.mod_method = None\n",
    "\n",
    "        self.verbose = False\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "\n",
    "        output = self.block(*args, **kwargs)\n",
    "        # print(output.shape)\n",
    "        # mask = self.mask if self.mask is not None else 1.0\n",
    "\n",
    "        if self.mod is not None:\n",
    "\n",
    "            if isinstance(self.pos[0], int):\n",
    "                assert len(self.mod.shape) == 3\n",
    "                if self.mod_method == \"add\":\n",
    "                    output[:, self.pos] += self.mod\n",
    "                elif self.mod_method == \"substitute\":\n",
    "                    output[:, self.pos] = self.mod\n",
    "                else:\n",
    "                    raise NotImplementedError(\"pos dimension not implemented\")\n",
    "                # self.modify(output[:, self.pos], self.mod)\n",
    "                if self.verbose:\n",
    "                    print(\"Modifying with broadcasting: pos:{} modshape:{}\".format(self.pos, self.mod.shape))\n",
    "\n",
    "            elif isinstance(self.pos[0], list) or isinstance(self.pos[0], torch.Tensor): # assume the modification differs for different elements in the batch\n",
    "                if self.verbose:\n",
    "                    print(\"Modifying iteratively: pos:{}\".format(self.pos))\n",
    "                assert len(self.pos) == len(self.mod)\n",
    "                for i in range(len(self.pos)):\n",
    "                    if self.mod_method == \"add\":\n",
    "                        output[i, self.pos] += self.mod[i]\n",
    "                    elif self.mod_method == \"substitute\":\n",
    "                        output[i, self.pos] = self.mod[i]\n",
    "                    else:\n",
    "                        raise NotImplementedError(\"pos dimension not implemented\")\n",
    "                    # self.modify(output[:, self.pos], self.mod)\n",
    "            else:\n",
    "                raise NotImplementedError(\"Indexing not accepted\")\n",
    "\n",
    "        return output\n",
    "\n",
    "    def set_mod(self, mod, pos, mod_method, verbose=False):\n",
    "        self.mod = mod\n",
    "        # self.mask = masks\n",
    "        self.pos = pos\n",
    "        self.mod_method = mod_method\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def reset(self):\n",
    "        self.output = None\n",
    "        self.mod = None\n",
    "        self.pos = None\n",
    "        self.verbose = False\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        self.mask = masks\n",
    "\n",
    "    \n",
    "class WrappedModModel(torch.nn.Module):\n",
    "    def __init__(self, model, tokenizer, verbose=False):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.verbose = verbose\n",
    "        if verbose:\n",
    "            print(\"Creating wrapped model\")\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "        \n",
    "    def generate(self, prompt, max_new_tokens=100, random_seed=0, use_cache=True):\n",
    "        with torch.no_grad():\n",
    "            torch.random.manual_seed(random_seed)\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, max_length=512, truncation=True)\n",
    "            attention_mask = inputs.attention_mask.to(self.model.device)\n",
    "            generate_ids = self.model.generate(inputs.input_ids.to(self.model.device), attention_mask=attention_mask, max_new_tokens=max_new_tokens, use_cache=use_cache)\n",
    "            return self.tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    def get_logits(self, tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(tokens.to(self.model.device)).logits\n",
    "            return logits\n",
    "        \n",
    "    def run_prompt(self, prompt, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, max_length=512, truncation=True)\n",
    "            input_ids = inputs.input_ids.to(self.model.device)\n",
    "            attention_mask = inputs.attention_mask.to(self.model.device)\n",
    "            output = self.model(input_ids, attention_mask=attention_mask)\n",
    "            return output\n",
    "        \n",
    "    def wrap_decoder_block(self, layer_id):\n",
    "        block = self.model.model.layers[layer_id]\n",
    "        if not self.is_wrapped(block):\n",
    "            self.model.model.layers[layer_id] = WrappedModBlock(block)\n",
    "    \n",
    "    def wrap_embedding_block(self):\n",
    "        block = self.model.model.embed_tokens\n",
    "        if not self.is_wrapped(block):\n",
    "            self.model.model.embed_tokens = WrappedModBlock(block)\n",
    "    \n",
    "    def wrap_all(self):\n",
    "        for layer_id, layer in enumerate(self.model.model.layers):\n",
    "            self.wrap_decoder_block(layer_id)\n",
    "            \n",
    "    def wrap_block(self, layer_ids):\n",
    "        def _wrap_block(layer_id):\n",
    "            self.wrap_decoder_block(layer_id)\n",
    "        if isinstance(layer_ids, list) or isinstance(layer_ids, tuple) or isinstance(layer_ids, np.ndarray):\n",
    "            for layer_id in layer_ids:\n",
    "                _wrap_block(layer_id)\n",
    "        else:\n",
    "            _wrap_block(layer_ids)\n",
    "    \n",
    "    def wrap_embedding_block(self):\n",
    "        block = self.model.model.embed_tokens\n",
    "        if not self.is_wrapped(block):\n",
    "            self.model.model.embed_tokens = WrappedModBlock(block)\n",
    "\n",
    "    def get_activations(self, layer_ids):\n",
    "\n",
    "        def _get_activations(layer_id):\n",
    "            current_layer = self.model.model.layers[layer_id]\n",
    "\n",
    "            if self.is_wrapped(current_layer):\n",
    "                current_block = current_layer.block\n",
    "                return current_layer.output\n",
    "                \n",
    "        if isinstance(layer_ids, list) or isinstance(layer_ids, tuple) or isinstance(layer_ids, np.ndarray):\n",
    "            activations = {}\n",
    "            for layer_id in layer_ids:\n",
    "                activations[layer_id] = _get_activations(layer_id)\n",
    "            return activations\n",
    "        else:\n",
    "            return _get_activations(layer_ids)\n",
    "\n",
    "    def set_mod(self, layer_ids, activations, block_name='decoder_block', pos=None, masks=None, normalize=False):\n",
    "\n",
    "        def _set_mod(layer_id, activations, block_name, masks, normalize):\n",
    "            current_layer = self.model.model.layers[layer_id]\n",
    "            current_layer.set_mod(activations, pos, masks, normalize)\n",
    "                \n",
    "        if isinstance(layer_ids, list) or isinstance(layer_ids, tuple) or isinstance(layer_ids, np.ndarray):\n",
    "            assert isinstance(activations, dict), \"activations should be a dictionary\"\n",
    "            for layer_id in layer_ids:\n",
    "                _set_mod(layer_id, activations[layer_id], block_name, masks, normalize)\n",
    "        else:\n",
    "            _set_mod(layer_ids, activations, block_name, masks, normalize)\n",
    "    \n",
    "    def set_mod_embedding(self, mod, pos, mod_method=\"substitute\"):\n",
    "        block = self.model.model.embed_tokens\n",
    "        assert self.is_wrapped(block)\n",
    "        block.set_mod(mod, pos, mod_method, verbose=self.verbose)\n",
    "        if self.verbose:\n",
    "            print(\"Setting embedding modification\")\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.model.model.layers:\n",
    "            if self.is_wrapped(layer):\n",
    "                layer.reset()\n",
    "        self.model.model.embed_tokens.reset()\n",
    "\n",
    "    def set_masks(self, masks):\n",
    "        for layer in self.model.model.layers:\n",
    "            if self.is_wrapped(layer):\n",
    "                layer.set_masks(masks)\n",
    "\n",
    "    def is_wrapped(self, block):\n",
    "        if hasattr(block, 'block'):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def unwrap(self):\n",
    "        for l, layer in enumerate(self.model.model.layers):\n",
    "            if self.is_wrapped(layer):\n",
    "                self.model.model.layers[l] = layer.block\n",
    "        if self.is_wrapped(self.model.model.embed_tokens):\n",
    "            self.model.model.embed_tokens = model.model.embed_tokens.block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0051, -0.0053,  0.0044,  ..., -0.0010, -0.0022,  0.0003],\n",
      "         [-0.0051, -0.0053,  0.0044,  ..., -0.0010, -0.0022,  0.0003],\n",
      "         [-0.0051, -0.0053,  0.0044,  ..., -0.0010, -0.0022,  0.0003]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wrapped_model = WrappedModModel(model, tokenizer, verbose=False)\n",
    "wrapped_model.unwrap()\n",
    "wrapped_model.wrap_embedding_block()\n",
    "test_tokens = tokenizer(neutral_ds[0][0], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "# wrapped_model(**test_tokens)\n",
    "init_embedding = get_seq_embedding(\"_ _ _\", tokenizer, model).unsqueeze(0)\n",
    "test_pos = [-1, -2, -3]\n",
    "\n",
    "wrapped_model.set_mod_embedding(init_embedding, test_pos)\n",
    "wrapped_model(**test_tokens)\n",
    "# get_hidden_reps(wrapped_model, tokenizer, neutral_ds[0][0])\n",
    "\n",
    "# wrapped_model.reset()\n",
    "get_hidden_reps(wrapped_model, tokenizer, neutral_ds[0][0], rep_tokens=[-1, -2])\n",
    "print(init_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_reps(wrapped_model: WrappedModModel, tokenizer, input_strs, sample_ids, mod, mod_pos, rep_tokens, grad_comp=True):\n",
    "    # Return hidden representation for (modified) inputs\n",
    "\n",
    "    wrapped_model.reset()\n",
    "    wrapped_model.model.zero_grad()\n",
    "    if mod is not None:\n",
    "        wrapped_model.set_mod_embedding(mod, mod_pos)\n",
    "    \n",
    "    tokenized_inputs = tokenizer(input_strs, return_tensors=\"pt\", padding=True).to(wrapped_model.model.device)\n",
    "    if not grad_comp:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_inputs, output_hidden_states=True)\n",
    "    else:\n",
    "        outputs = model(**tokenized_inputs, output_hidden_states=True)\n",
    "    reps = [m[:, rep_tokens] for m in outputs.hidden_states]\n",
    "    assert len(sample_ids) == reps[0].shape[0], \"sample_id passed incorrectly\"\n",
    "    \n",
    "    res = {sample_id: [x[i] for x in reps] for i, sample_id in enumerate(sample_ids)}\n",
    "    return res, outputs\n",
    "\n",
    "def comp_target_reps_interpolation(reps_init, reps_dest, dest_weight):\n",
    "    # Interpolate between reps_init and reps_dest\n",
    "    res = {}\n",
    "    for k in reps_init.keys():\n",
    "        l = []\n",
    "        for i in range(len(reps_init[k])):\n",
    "            l.append((reps_init[k][i] * (1 - dest_weight) + reps_dest[k][i] * dest_weight).detach())\n",
    "            # print(torch.norm(reps_init[k][i] - reps_dest[k][i]))\n",
    "        res[k] = l\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_rep_diff(base, target, layer_ids):\n",
    "    loss = 0\n",
    "    for l in layer_ids:\n",
    "        # print(base[l], target[l])\n",
    "        loss += torch.norm(base[l] - target[l])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07204132080078125\n",
      "tensor(181., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(132.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(124.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(72.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(107.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(108.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(154.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(165.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(84.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(84.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(85.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(95.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(62., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(82.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(85.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(42.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(157.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(161.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(75.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(58.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(57.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(59.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(70.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.8906, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(71.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(104.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(122., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(45.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(36.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(30.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.3281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(39.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(24.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.3281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(45.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(62.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(61.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(30.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(53.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(49.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(34.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.7344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.6094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(70.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(81.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(111.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(87.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(82., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(42.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.1094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.7969, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(56.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(63.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(36.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.1094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(58.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(40.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(35.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.8281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.9453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.8828, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(32.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(46.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(136.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(44.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(78.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(24.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.7344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.7969, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.6094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(56.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(30.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(33.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.7422, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.4453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(51.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(46.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(44.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(46.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(62.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(71.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.0781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(34.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.5781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(57.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(83.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.1406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(46.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(59.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(28.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.8906, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.5156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.5234, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.5547, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(9.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(36., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(33.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(40.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(37.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(24.1719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.8906, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.8594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.4922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.4297, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(54.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(57.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(83.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(62.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2969, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.0234, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(43.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.6406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(53.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(33.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(32.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.8281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.6797, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(9.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(44.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(129.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(39.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(74.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.9297, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.1094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.2031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.2578, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.8203, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(35.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(30.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.8047, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.9453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(50., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(44.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(42.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(28.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(42.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(43.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(55.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(63.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.7969, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.0469, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.8594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(77.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.2031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.7344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.6797, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(39.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(55.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.8594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.2891, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(24.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.0078, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.4453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(7.6406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(32.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(39.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(39.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.5781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.3281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.1094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(37.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(35.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.0469, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.2656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.4141, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.8828, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.3594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.6016, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.7266, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.2266, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(81.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(34.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.6016, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.1172, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(47.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.4375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.5781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(31.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.1719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(23.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.0859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.0781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(9.3984, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(9.2891, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(43.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(128.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(34.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(70.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(13.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(11.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.9688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.5156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(9.3516, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(12.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.8047, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(33.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(25.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.2031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(14.0234, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(15.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(29.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(10.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(8.5859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(48.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(28.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(17.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(26.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(41.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(52.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(61.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(22.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.3594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(27.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(18.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(19.1719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(21.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(16.1406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(51.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(74.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07204132080078125\n",
      "tensor(20.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(21.1719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.0234, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(37.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(53.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(24.0781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(11.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.7656, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.6484, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.4844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.3516, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(23.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.5781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.0703, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(7.5078, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(31.5781, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(39.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(39.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(37.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(33.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(21.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(24.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.5859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.0859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.8281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.2031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.3594, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(44.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(49.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(80.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(44.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(33.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.4844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.0859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.5078, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(45.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(37.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(26.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(50.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.8906, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(22.9219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.9453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.5156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.8906, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.3359, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.6016, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(41.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(127.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(33., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(68.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.8516, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.4453, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.9141, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.4844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.1875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(51.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(32.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(24.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.8281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.7344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.5078, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.5156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.6016, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(48.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(40.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(40.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(39.7812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(25.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(40.7500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(40.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(51.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(59.6562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(21.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.6719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(26.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.0469, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.4297, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(50.4688, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(73.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.6250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.4062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(11.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.3047, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(36.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(51.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(24.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(11.4922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.2109, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(23.1406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.3984, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(11.5391, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.0391, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(7.8203, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(7.1523, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.2188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(38.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(38.5312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(34.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.2031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(23.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.1406, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.9844, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(7.7305, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.5391, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.7891, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.9531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.9297, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.5859, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(42.8125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(47.8750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(80.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(43.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(32.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.9141, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(43.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(36.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(25.8281, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.1562, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.5625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.7422, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.4531, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(49.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(29.5938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(20.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(27.0938, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(22.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.6484, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.9922, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.3125, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.7734, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.1094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.2812, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(40.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(127.0625, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(30.9062, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(66.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(19.0156, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.4219, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.2344, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.3438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.6875, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.4297, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(12.3672, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(11.7578, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(9.7031, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(51.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(31.8438, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(24.5469, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(18.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(15.9609, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.2500, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(13.1016, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(14.1719, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.3750, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(10.1250, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(8.0469, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(47.9375, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(28.0312, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(17.6094, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
      "0.07194366455078124\n",
      "tensor(16.7188, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train_contrastive(model, tokenizer, ds_dest, init_str, target_str, epochs, batchsize, rep_tokens, coef=1, caching_base=True):\n",
    "\n",
    "    cached_target_reps = {}\n",
    "    loss_record = []\n",
    "\n",
    "    # Created wrapped model for injection\n",
    "    wrapped_model = WrappedModModel(model, tokenizer, verbose=False)\n",
    "    wrapped_model.unwrap()\n",
    "    wrapped_model.wrap_embedding_block()\n",
    "    wrapped_model.reset()\n",
    "\n",
    "    embedding_init = get_seq_embedding(init_str, tokenizer, wrapped_model.model)\n",
    "    # print(embedding_init)\n",
    "\n",
    "    var_embedding = embedding_init.clone().float()\n",
    "    optimizer = torch.optim.SGD([var_embedding], lr=0.001)\n",
    "    # var_embedding.requires_grad = True\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for batch_ind in range((len(ds_dest) + batchsize - 1) // batchsize):\n",
    "\n",
    "            if device != \"cpu\":\n",
    "                info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                print(info.free / info.total)\n",
    "            \n",
    "            # Compute or retrive target representation\n",
    "            sample_id_ls = [] # all sample ids\n",
    "            sample_id_ls_target_recomp = [] # ids not found in cache\n",
    "\n",
    "            input_strs, mod_pos_ls = [], []\n",
    "            input_strs_target_recomp, mod_pos_ls_target_recomp = [], []\n",
    "            \n",
    "            for target_str, mod_pos, sample_id in ds_dest[batch_ind * batchsize : (batch_ind + 1) * batchsize]:\n",
    "                \n",
    "                # sample_id: (i, j) - the j-th truncation for the i-th sentence\n",
    "                sample_id_ls.append(sample_id)\n",
    "                input_strs.append(target_str)\n",
    "                mod_pos_ls.append(mod_pos)\n",
    "                \n",
    "                if sample_id not in cached_target_reps:\n",
    "                    sample_id_ls_target_recomp.append(sample_id)\n",
    "                    input_strs_target_recomp.append(target_str)\n",
    "                    mod_pos_ls_target_recomp.append(mod_pos)\n",
    "                \n",
    "            # Compute reps at init and target token\n",
    "            if len(sample_id_ls_target_recomp) != 0:\n",
    "                # Recompute\n",
    "                reps_init_recomp, _ = comp_reps(\n",
    "                    wrapped_model,\n",
    "                    tokenizer,\n",
    "                    input_strs_target_recomp,\n",
    "                    sample_id_ls_target_recomp,\n",
    "                    mod=[embedding_init.clone() for i in range(len(sample_id_ls_target_recomp))],\n",
    "                    mod_pos=mod_pos_ls_target_recomp,\n",
    "                    rep_tokens=rep_tokens,\n",
    "                    grad_comp=False\n",
    "                )\n",
    "\n",
    "                reps_dest_recomp, _ = comp_reps(\n",
    "                    wrapped_model,\n",
    "                    tokenizer,\n",
    "                    input_strs_target_recomp,\n",
    "                    sample_id_ls_target_recomp,\n",
    "                    mod=None,\n",
    "                    mod_pos=None,\n",
    "                    rep_tokens=rep_tokens,\n",
    "                    grad_comp=False\n",
    "                )\n",
    "\n",
    "                reps_target_recomp = comp_target_reps_interpolation(reps_init_recomp, reps_dest_recomp, coef)\n",
    "                cached_target_reps.update(reps_target_recomp)\n",
    "\n",
    "            reps_target = {sample_id: cached_target_reps[sample_id] for sample_id in sample_id_ls}\n",
    "            # Compute the representation with the varying embedding\n",
    "\n",
    "            # Create the varying embedding representations\n",
    "            var_embedding_dups = [var_embedding.clone().half() for i in range(len(sample_id_ls))]\n",
    "            for x in var_embedding_dups:\n",
    "                x.requires_grad = True\n",
    "\n",
    "            reps_var, all_reps = comp_reps(\n",
    "                wrapped_model,\n",
    "                tokenizer,\n",
    "                input_strs,\n",
    "                sample_id_ls,\n",
    "                mod=var_embedding_dups,\n",
    "                mod_pos=mod_pos_ls,\n",
    "                rep_tokens=rep_tokens,\n",
    "                grad_comp=True\n",
    "            )\n",
    "            # print(var_embedding_dups)\n",
    "\n",
    "            # Compute representation difference in l2 metric\n",
    "            losses = {}\n",
    "            for sample_id in reps_var:\n",
    "                losses[sample_id] = l2_rep_diff(reps_var[sample_id], reps_target[sample_id], [-5])\n",
    "            \n",
    "            # Back prop the loss to modified embeddings\n",
    "            total_loss = 0\n",
    "            for sample_id in losses:\n",
    "                total_loss += losses[sample_id]\n",
    "            total_loss.backward()\n",
    "            del all_reps\n",
    "            print(total_loss)\n",
    "            \n",
    "            # for i in range(len(var_embedding_dups)):\n",
    "            #     print(i, var_embedding_dups[i].grad)\n",
    "\n",
    "            # tokenized_var_strs = tokenizer(var_strs, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "            # print(model(**tokenized_var_strs))\n",
    "            optimizer.zero_grad()\n",
    "            ave_grad = torch.mean(torch.stack([var_embedding_dups[i].grad for i in range(len(var_embedding_dups))]), dim=0)\n",
    "            var_embedding.grad = ave_grad.float()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            wrapped_model.model.model.zero_grad()\n",
    "            for x in var_embedding_dups:\n",
    "                del x\n",
    "            \n",
    "            if not caching_base:\n",
    "                cached_target_reps = {}\n",
    "            \n",
    "            loss_record.append(total_loss.detach().item())\n",
    "\n",
    "            \n",
    "\n",
    "    return loss_record, var_embedding\n",
    "res = train_contrastive(model, tokenizer, target_ds, aug_neutral, aug_target, epochs=5, batchsize=8, rep_tokens=[-1], coef=1, caching_base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14ff00882810>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBdklEQVR4nO2deZgU1b3+395mYZgZGQZmkQFRUVQWBRTEBVCCEpcYTNRoEr0xJkYkIWo06r0/Se6NmMUl0YTEJe6KSVwTTQSUTREXBFlU9h2GYRlmX3vq90d3VZ86daqqe6aXYub9PM88DN013adPnzrnPd/t+DRN00AIIYQQ4iH8mW4AIYQQQogMBQohhBBCPAcFCiGEEEI8BwUKIYQQQjwHBQohhBBCPAcFCiGEEEI8BwUKIYQQQjwHBQohhBBCPEcw0w3oDB0dHdizZw/y8/Ph8/ky3RxCCCGExIGmaairq0N5eTn8fmcbyREpUPbs2YOKiopMN4MQQgghnWDnzp0YMGCA4zVHpEDJz88HEPmABQUFGW4NIYQQQuKhtrYWFRUVxjruxBEpUHS3TkFBAQUKIYQQcoQRT3gGg2QJIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAIIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAIIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAIIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAUbN5fj8eWbEFzWzjTTSGEEEJ6JEfkacap5vz7FwMADjW24o4Lh2a4NYQQQkjPgxYUB1Zsr850EwghhJAeCQUKIYQQQjwHBYoDvkw3gBBCCOmhUKAQQgghxHNQoBBCCCHEc1CgEEIIIcRzUKA44GMQCiGEEJIRKFAIIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAc8LESCiGEEJIRKFAIIYQQ4jkoUAghhBDiOShQCCGEEOI5KFAcYB0UQgghJDNQoBBCCCHEc1CgEEIIIcRzUKAQQgghxHNQoDjAGBRCCCEkM1CgEEIIIcRzUKAQQgghxHNQoBBCCCHEc1CgOMCzeAghhJDMQIFCCCGEEM9BgUIIIYQQz5GQQJk9ezZOP/105Ofno3///rjsssuwfv160zXXXXcdfD6f6WfcuHGma1paWjBjxgwUFxcjLy8Pl156KXbt2tX1T0MIIYSQbkFCAmXx4sWYPn06li9fjvnz56O9vR1TpkxBQ0OD6boLL7wQe/fuNX7eeust0/MzZ87Eq6++irlz5+K9995DfX09Lr74YoTD4a5/oiTCOiiEEEJIZggmcvF//vMf0/+ffPJJ9O/fHytWrMC5555rPJ6dnY3S0lLla9TU1OCJJ57As88+i8mTJwMAnnvuOVRUVGDBggW44IILEv0MhBBCCOlmdCkGpaamBgBQVFRkenzRokXo378/TjjhBNxwww2oqqoynluxYgXa2towZcoU47Hy8nIMGzYMy5YtU75PS0sLamtrTT+EEEII6b50WqBomoZbbrkFZ599NoYNG2Y8PnXqVDz//PN49913cf/99+Pjjz/Geeedh5aWFgBAZWUlsrKy0KdPH9PrlZSUoLKyUvles2fPRmFhofFTUVHR2WYTQggh5AggIRePyM0334zVq1fjvffeMz1+5ZVXGr8PGzYMY8aMwaBBg/Dmm29i2rRptq+naRp8NkEfd955J2655Rbj/7W1tWkRKXbtIYQQQkhq6ZQFZcaMGXjjjTewcOFCDBgwwPHasrIyDBo0CBs3bgQAlJaWorW1FdXV1abrqqqqUFJSonyN7OxsFBQUmH4IIYQQ0n1JSKBomoabb74Zr7zyCt59910MHjzY9W8OHjyInTt3oqysDAAwevRohEIhzJ8/37hm7969WLt2LcaPH59g8wkhhBDSHUnIxTN9+nS88MILeP3115Gfn2/EjBQWFiI3Nxf19fWYNWsWLr/8cpSVlWHbtm246667UFxcjK9//evGtddffz1uvfVW9O3bF0VFRbjtttswfPhwI6uHEEIIIT2bhATKnDlzAAATJ040Pf7kk0/iuuuuQyAQwJo1a/DMM8/g8OHDKCsrw6RJk/DSSy8hPz/fuP7BBx9EMBjEFVdcgaamJpx//vl46qmnEAgEuv6JkggjUAghhJDMkJBA0TTN8fnc3Fy8/fbbrq+Tk5ODhx9+GA8//HAib08IIYSQHgLP4iGEEEKI56BAIYQQQojnoEBxgGVQCCGEkMxAgUIIIYQQz0GBQgghhBDPQYFCCCGEEM9BgeIAQ1AIIYSQzECBQgghhBDPQYFCCCGEEM9BgUIIIYQQz0GB4oCPhVAIIYSQjECBQgghhBDPQYFCCCGEEM9BgUIIIYQQz0GB4gAjUAghhJDMQIFCCCGEEM9BgUIIIYQQz0GBQgghhBDPQYHiAMugEEIIIZmBAoUQQgghnoMChRBCCCGegwKFEEIIIZ6DAsURBqEQQgghmYAChRBCCCGegwKFEEIIIZ6DAoUQQgghnoMCxQHWQSGEEEIyAwUKIYQQQjwHBQohhBBCPAcFCiGEEEI8BwUKIYQQQjwHBYoDjJElhBBCMgMFCiGEEEI8BwUKIYQQQjwHBQohhBBCPAcFigMs1EYIIYRkBgoUQgghhHgOChRCCCGEeA4KFAlN0zLdBEIIIaTHQ4EiIeoTHyuhEEIIIRmBAkWC9hNCCCEk81CgSNDFQwghhGQeChQJyhNCCCEk81CgSJhiUBiCQgghhGQEChQJjTYUQgghJONQoEgwBIUQQgjJPBQohBBCCPEcFCgSjEEhhBBCMg8FigRjUAghhJDMQ4Ei0cFKsoQQQkjGoUCRYKE2QgghJPNQoEiY5AkNKIQQQkhGSEigzJ49G6effjry8/PRv39/XHbZZVi/fr3pGk3TMGvWLJSXlyM3NxcTJ07EunXrTNe0tLRgxowZKC4uRl5eHi699FLs2rWr658mCdCAQgghhGSehATK4sWLMX36dCxfvhzz589He3s7pkyZgoaGBuOa3/zmN3jggQfwyCOP4OOPP0ZpaSm+8pWvoK6uzrhm5syZePXVVzF37ly89957qK+vx8UXX4xwOJy8T9ZZKFAIIYSQjOPTuhB0sX//fvTv3x+LFy/GueeeC03TUF5ejpkzZ+KOO+4AELGWlJSU4Ne//jV++MMfoqamBv369cOzzz6LK6+8EgCwZ88eVFRU4K233sIFF1zg+r61tbUoLCxETU0NCgoKOtt8JYcbW3HqL+cDAC4aUYY/Xj0qqa9PCCGE9FQSWb+7FINSU1MDACgqKgIAbN26FZWVlZgyZYpxTXZ2NiZMmIBly5YBAFasWIG2tjbTNeXl5Rg2bJhxjUxLSwtqa2tNP6nCVAclZe9CCCGEECc6LVA0TcMtt9yCs88+G8OGDQMAVFZWAgBKSkpM15aUlBjPVVZWIisrC3369LG9Rmb27NkoLCw0fioqKjrbbFfo4SGEEEIyT6cFys0334zVq1fjxRdftDznk0qwappmeUzG6Zo777wTNTU1xs/OnTs722xXmGZMCCGEZJ5OCZQZM2bgjTfewMKFCzFgwADj8dLSUgCwWEKqqqoMq0ppaSlaW1tRXV1te41MdnY2CgoKTD+pgvKEEEIIyTwJCRRN03DzzTfjlVdewbvvvovBgwebnh88eDBKS0sxf/5847HW1lYsXrwY48ePBwCMHj0aoVDIdM3evXuxdu1a45pMIhpQKFYIIYSQzBBM5OLp06fjhRdewOuvv478/HzDUlJYWIjc3Fz4fD7MnDkT9957L4YMGYIhQ4bg3nvvRa9evXD11Vcb115//fW49dZb0bdvXxQVFeG2227D8OHDMXny5OR/wgQxncVDhUIIIYRkhIQEypw5cwAAEydOND3+5JNP4rrrrgMA3H777WhqasJNN92E6upqjB07FvPmzUN+fr5x/YMPPohgMIgrrrgCTU1NOP/88/HUU08hEAh07dMkA5M+oUIhhBBCMkGX6qBkilTWQdlX24yx974DAPjq8FL86ZrRSX19QgghpKeStjoo3RFTDMoRJ90IIYSQ7gEFioTo1qFAIYQQQjIDBYqExhgUQgghJONQoEhQkhBCCCGZhwJFQowZpouHEEIIyQwUKBIs1EYIIYRkHgoUB2hBIYQQQjIDBYoERQkhhBCSeShQJMyZO1QrhBBCSCagQJFgoTZCCCEk81CgSNB+QgghhGQeChSJI/BoIkIIIaTbQYEiYbKgUKwQQgghGYECRYJ1UAghhJDMQ4FigZVkCSGEkExDgSJBUUIIIYRkHgoUgS376/GVB5cY/6dWIYQQQjIDBYoDDJIlhBBCMgMFikDA78t0EwghhBACChQTfh8FCiGEEOIFKFAEZAsKPTyEEEJIZqBAEbAIFIbJEkIIIRmBAkVA9vDQgkIIIYRkBgoUgQBjUAghhBBPQIEiwBgUQgghxBtQoAj4GYNCCCGEeAIKFAHZxUMLCiGEEJIZKFAEWKiNEEII8QYUKAKWLJ7MNIMQQgjp8VCgCFiyeKhQCCGEkIxAgSLAQm2EEEKIN6BAEfCxDgohhBDiCShQHGAWDyGEEJIZKFAcoD4hhBBCMgMFigMaTSiEEEJIRqBAIYQQQojnoEBxgPYTQgghJDNQoDhADw8hhBCSGShQHKA+IYQQQjIDBQohhBBCPAcFihP08RBCCCEZgQLFAcoTQgghJDNQoDhAAwohhBCSGShQCCGEEOI5KFAc4GnGhBBCSGagQHGALh5CCCEkM1CgOECBQgghhGQGChRCCCGEeA4KFAdoQCGEEEIyAwWKAxp9PIQQQkhGoEAhhBBCiOegQCGEEEKI50hYoCxZsgSXXHIJysvL4fP58Nprr5mev+666+Dz+Uw/48aNM13T0tKCGTNmoLi4GHl5ebj00kuxa9euLn2QVEAPDyGEEJIZEhYoDQ0NGDlyJB555BHbay688ELs3bvX+HnrrbdMz8+cOROvvvoq5s6di/feew/19fW4+OKLEQ6HE/8EKYSF2gghhJDMEEz0D6ZOnYqpU6c6XpOdnY3S0lLlczU1NXjiiSfw7LPPYvLkyQCA5557DhUVFViwYAEuuOCCRJuUMmhBIYQQQjJDSmJQFi1ahP79++OEE07ADTfcgKqqKuO5FStWoK2tDVOmTDEeKy8vx7Bhw7Bs2TLl67W0tKC2ttb0QwghhJDuS9IFytSpU/H888/j3Xffxf3334+PP/4Y5513HlpaWgAAlZWVyMrKQp8+fUx/V1JSgsrKSuVrzp49G4WFhcZPRUVFsputhAYUQgghJDMk7OJx48orrzR+HzZsGMaMGYNBgwbhzTffxLRp02z/TtM0+Hw+5XN33nknbrnlFuP/tbW1aREprINCCCGEZIaUpxmXlZVh0KBB2LhxIwCgtLQUra2tqK6uNl1XVVWFkpIS5WtkZ2ejoKDA9JMOKE8IIYSQzJBygXLw4EHs3LkTZWVlAIDRo0cjFAph/vz5xjV79+7F2rVrMX78+FQ3hxBCCCFHAAm7eOrr67Fp0ybj/1u3bsWqVatQVFSEoqIizJo1C5dffjnKysqwbds23HXXXSguLsbXv/51AEBhYSGuv/563Hrrrejbty+Kiopw2223Yfjw4UZWj2egCYUQQgjJCAkLlE8++QSTJk0y/q/Hhlx77bWYM2cO1qxZg2eeeQaHDx9GWVkZJk2ahJdeegn5+fnG3zz44IMIBoO44oor0NTUhPPPPx9PPfUUAoFAEj5S8qA+IYQQQjKDTzsCI0Fra2tRWFiImpqapMejHPPzN2O/9+2FRT+b5HA1IYQQQuIlkfWbZ/FI+NWJRIQQQghJIxQoEmKq8xFnWiKEEEK6CRQoEqIF5chzfhFCCCHdAwoUCbMFhQqFEEIIyQQUKBKMQSGEEEIyDwWKhF+0oNCAQgghhGQEChQJChRCCCEk81CgSNDDQwghhGQeChQJmwOVCSGEEJJGKFAk/H7RxUMfDyGEEJIJKFAk/CzURgghhGQcChQJFmojhBBCMg8FioSPQSiEEEJIxqFAkRDlCSvJEkIIIZmBAkVCroPSHu7AoYbWDLaIEEII6XlQoEiYYlAAfO/pTzDqf+djfWVdxtqUaT7fU4u/vrcV7eGOTDeFEEJID4ECRUKOQVmyYT8A4PkPt2eiOZ7gq39Yil/+63O8+NGOTDeFEEJID4ECRcIv9IiYxVPb1Jb+xniMdXtqM90EQgghPQQKFAm/zxwmq1Pb3J7+xhBCCCE9FAoUiStPrzB+pwWFEEIIyQwUKBI/PPc4/OLSUyyP1zZToBBCCCHpggJFIuD34czj+gIwl7qvoQWFEEIISRsUKAr0KBTxsMDaJsagEEIIIemCAkWBHicrWlCa2sIZaQvpOWw90IBrHl+OZZsOZLophBCScShQlPA8HpJ+bn7hU7y/6SCufvzDTDel27NhXx32HG7KdDMIIQ4EM90AL8PTjEk6qaxpznQTegRVtc2Y8uASAMC2+y7KcGu6P+3hDgQD3AuTxOGoUWC4eCSFIv+/p8GDnkl3YNP++kw3ocfw36+twSn3vI1d1Y2Zbkq3Zl9tM/7ntbXYsK97HclCgaLACJKVHu/o2fqEFqUUQwGYJjiO08Zzy3egpb0Djy/dmummdGt+/OJKPLt8Oy7+w3uZbkpSoUBRIJ/Ho9PBFZqkEA4vQkhnWLu7BgDQ2s0OdKVAcUBeMHq6QOEOnxBCSLqgQFGgr8Ntkhrt4fqkx39+Qkjn4OYmtXTXqZkCRYF+M4WloJOebkEhhJDOwKmTdAYKFAW+qA2lXRIosmDpaXAXRAghJF1QoCRAD9cnhHQ7enrpgHTBzQ3pDBQoCuxuJk5mJJVwdKUfbjoI8S4UKAnAyYyQIx/xNmZcGekOdNdhTIGiwM6CwsmMkO4Fb2lCvAsFSgJQoBDSveA9TYh3oUBRYFtJtnsV6SOEkLTg4wnxpBNQoCiwu5W42yKphEHY6Yf3dHrQGAJOOgEFigLGoBDSfRFvYwa+k+5AdxWAFCgJQH1CUomda5GkDlqt0gNdPKQzUKAosLuZaEEhqYSLZXoQdSAtKIR4FwoUBXYb2Z5e6p6Q7oCoAykK0wONg6QzUKAosA+STWszCCEphvokPbCfSWegQEkA7rYI6V7QbUuId6FAUWGbxZPeZhBCko+Y8cBbOj3QxUM6AwWKAgbJ2sFZJpX09NGVLjpMacbsdXLk012HMQWKAgbJ2tHTPz/pDoiipLtO7IR0ByhQEqAnTmaMu0kftE+lB40ChZAjAgoUBSx1H8P8kbmEppKeN7oyg3imVk+8pwk5UqBAUWB7WGAPnMx64mcm3RvN5neSOri1IZ0hYYGyZMkSXHLJJSgvL4fP58Nrr71mel7TNMyaNQvl5eXIzc3FxIkTsW7dOtM1LS0tmDFjBoqLi5GXl4dLL70Uu3bt6tIHSSasgxKjJ35m0r0RRXcHB3haYC+nlu7avwkLlIaGBowcORKPPPKI8vnf/OY3eOCBB/DII4/g448/RmlpKb7yla+grq7OuGbmzJl49dVXMXfuXLz33nuor6/HxRdfjHA43PlPkgZ6ojWhux5CRXoujEEh5MggmOgfTJ06FVOnTlU+p2kaHnroIdx9992YNm0aAODpp59GSUkJXnjhBfzwhz9ETU0NnnjiCTz77LOYPHkyAOC5555DRUUFFixYgAsuuKALHyc52J5m3AN3W5zASXdDvI0pwNMDXTykMyQ1BmXr1q2orKzElClTjMeys7MxYcIELFu2DACwYsUKtLW1ma4pLy/HsGHDjGtkWlpaUFtba/pJJfZ1UFL6tp6kJ1qNMgW7Oj2I/dwT7+l0wQxA0lWSKlAqKysBACUlJabHS0pKjOcqKyuRlZWFPn362F4jM3v2bBQWFho/FRUVyWy2FRu53xNvuB74kUk3xxSDwgGeMti1pKukJItHzoLRNM02Myaea+68807U1NQYPzt37kxaWxOhJ+62OIGT7gYLtaUHzh1ppJt2dVIFSmlpKQBYLCFVVVWGVaW0tBStra2orq62vUYmOzsbBQUFpp9UYltJtgfecD1RlJHujXgb90SraLpgz5KuklSBMnjwYJSWlmL+/PnGY62trVi8eDHGjx8PABg9ejRCoZDpmr1792Lt2rXGNZmGhdpicAIn3Q0eFpgexPmShwWmmG7avwln8dTX12PTpk3G/7du3YpVq1ahqKgIAwcOxMyZM3HvvfdiyJAhGDJkCO6991706tULV199NQCgsLAQ119/PW699Vb07dsXRUVFuO222zB8+HAjqyfT2LmaeuJi3QM/MunmsJJsemDXppFu2tcJC5RPPvkEkyZNMv5/yy23AACuvfZaPPXUU7j99tvR1NSEm266CdXV1Rg7dizmzZuH/Px8428efPBBBINBXHHFFWhqasL555+Pp556CoFAIAkfqevYWlA6bJ7oxnACTx89UQBnAnOhtgw2pJvDuYN0lYQFysSJEx0nUp/Ph1mzZmHWrFm21+Tk5ODhhx/Gww8/nOjbZ5SeeMOZY1B63ucn3Q9TDArHdMrogdNlxuiu45hn8SiwLdTWA+84ceBzt5la3DLdSHJgFk966InzJUkuFCgKWKgthrmoVQ/sgDRCF096EHuZYzp1iPMlxXdqsVuzjnQoUBQkYkHZVFWPBZ/vS3GLMoe5qFUGG0JIkqAFJT2YzzxiR6cSuniIcoGe/MBifP+ZT/DxtkPpb1Aa4LklpLvRQatgWmDXkq5CgZIATruAdbtr0tiS9MGTX0l3wzSmM9iO7o65Dkr3dEGQ1EKBokC8lwpzQxgxoBAAEHbwcQQC3bMrGYNCuhusJJseOtjPpIt0z1W1i4gBR9eeOQh9emUBcI7BCHTTHQL99emD3ZseGFeVHmh9JV2FAsWFUMCPgD8iPpwsCN3UgEILCul2mHf2mWtHd8ecLZWxZvQIuus47qbLatcQjSHBgB9RfeJopvR7wILS0aFh9a7DaG1PXsESWlBId0MzWVA4qFNFB/uZdBEKFAWi1AgFfEaAl7wLECc63cqSSR5bugWXPvI+fvrSqqS9JrN4SHeDVsH0QKsJ6SoUKArEiPOQYEGRg2TbO7wlUP6yZAsA4M01e5P2mqbdJivJkm6ASZRwEU0ZHR20oJCuQYHiQkSgRMSH7OJpD3tLoKQCVt0k3Q1zHZTMtaO7ozHWh3QRChQFotQIBnzw+9UuntZwzKTQI7J4MtgOQpKFeUxzVKcK0zleVCgppbv2LgWKAlFrZAkWFPkmaxcESnctRCS6dVjLIMbfPtmJReurMt0M0gk0phmnBVqqSFcJZroBXsQuBkW+ydrC4gOZvwNTIZFYM8LKpqo63P6P1QCAbfddlLwXZv+mBQbJpgdz37KfSeLQguJCMOCLWVCkFbpNsKD0hMWbFpQIlTUtmW4C6QIdXDfTAgPsSVehQHEhK+A3XD7ybksUKE5l8I9kvGJB2XmoEb/45zrsPNSYuUaQbgHrc6QHWqrSR3fdPFKguBAM+IwAWCcXT3e9Ab1y8uu1f/0IT76/Ddc9+VHG2qBjCv7rpsLUKyzfchAPzFtvivfqKizBnh7MNZQISRzGoLgQcgiSNbt4uuct6BVlvuVAAwBg8/6GDLfEvKiFNQ3+lET/ZI6/fbITJ5Tk49SKozLdFFz16HIAQP+CHHx73KCkvCZT59MDLVXpw+fzdUu1TQuKC6GAD/5oL8mLtUmgeMDHmopEIq9YULxKezg1fZIpYfjexgO4/R+rcdkf38/I+9ux7UDyhKlX3JYPLdiAbz26HC3t4cw1IoWwIF768MpGMtlQoLhQlJdtZPXIVuae4OJhoJsV8ZtuT2KneOFwtS8razPzxmnE3LeZu28fWrARH2w5iLeSWPm5s3xZWYuv/+l9vL/pQNJe0ysxKDsPNeLet77A3pqmjLWBdA66eGx46MpTcaihFYOL84Q0Y/s6KN4QKMk3ofAsHiuiaEutBSX9riNvjGMrybQOesWCotOWojGUCDc88wl2HmrCNY9/mLTUebNAScpLdoprHv8QOw41YvmWg3jj5rMz15Ao4Q4Nfl/3rZ2VTChQbLjstKON3wM2pe5be0CaMYtaWRGHQXsSO0WcrjLV10mMRfUsXtnZ63ihCvX+uuSnznulCvWOaObf6l01GWxFhKbWMCY/sBgnlRXg8WvHZLo5nocCJQ7sTjMWd8/dN8049nt39XMmSqrSy70QvBnuAX48r2XxBAOZFyipgEGyVpZs3I/dh5uw+zDdTfHAGJQ4iCeLx2uLd7La47XJ3AuIVpO2bmZy8OrHSaY53GuB334PWFBSgUdCfXoE3bV7KVDiQI9BCR9BLp5kuR68sKsX8cKp0eko0JcxC4oHvuNU44VxLI4bL4zpVHSJ5jELSjfVgd0aCpQ40E8zlu8xr7l4xBuwtT05W2GvBRR6wV8vfu/JjEERydR87tXCc8n81r0QgyKK3O5qQfGapcoLc4eI16zuXoQCJQ7iO4vHW4MtWa4Hr1WD9MJuU0wtTmaasUimxlOqBFeXSeLX7oXUefH+9MKYTgXifOmF6dHvgX42FXlM2ebGA52dJChQ4sD2NOMOZxPmiu3VmP78p2kLiBInhFRYULww8L0wmYtpoclMM/ZCxpSXhHaqxpsXRLc4hgLddBY2W1Ay1w4dr1lQupv1NRUwiycObINk251jUC6fswwAcLChBXN/cGbqGhhFjIlpTVa0o/C5Vu+qwed7anFyeUFyXrsTeECfmOrfpMzikKFJJlV1XTpDOuJ7MmapEsaQr5sdlaAj1k3ywuYm6IXJQyCZc4fstuwux290U+2eXOwKtcXr4tmaxDLdTojtSYUFBQC++oelSXndzuIFC4o4saQqLTdTC6eXLCipEn9eSJ1v9Zh7OBUt8Fqley+4eMSeCKeqyGNKXjUzUKDEgc/GgiJOoE7Bhekyb4pm42RVp/SCaVYk4M/8kE2Vi0ckc3VQvPOFt6XMypD52Ig2jwXYpwIvWKpEvGBBEbuhrZttblJB5mf7IwB91y7PI60uLh6ddOzSwh2aaaJLVpCsF0yzIl7w16fKxaPZ/J5OvJRmLIq/pJa6F26NTGmDNq+VKEhBG8yWquS/fqJ4wYJitr4yBsUND0z33kcf1/JiLWZwOA22dExAsiBpSZqLJykvkzS8EOgmBkenyo+cqQJwotk50ynH4g4zmbtCcwn2zKcZd6cdr4jX6qB4Ye4Q14xU3eMe6OqkQYESB4aLx+E0YydLQzqsEHJQbHe1oHhiFyRaUJI4yYiT+ITfLErqa8dL2EOLSnuKXGleyC7pGSehq3/PFF6IX+vO7uFUQIESB3oWj6WSbLwunpS0ykybZDFJXpBsUl4maXjBjxxOlQVF+L013IHt0UPO0on42TLt7gmnyBwuiu7/eW0tNuyrS9prx0s6qhFnGi9YqkS8IFDSUuQxJa+aGShQ4sAui8fk4nGYzNNhKpeDYpNmQUnjcJ/70Q58Y84yHKy3P1nVCxaUVAU4ytaqTFQYFT9PpjdibaZYn+RZk+SP9fOXVyftteNF3FBkup+B1NznJkuVB8548oRA6cZFHlMBBUocBGxK3YuTudOgSIsFJXzkW1B+/soafLK9Gn9ZssX0uLhwd2c/stzXmZhPRaGd6Z29uMNMrotHFvPp/5xtaQiWzDTiffvBloP452d7Mtgar9RQSr2LpxvpEwqUeLBLMzYJFIdJJh0DRo5BSVahtkzEoMgTtrhQeWEXlCoLijy+MlHAqyNO0Z0O2lKULeUFIWgu8tiNVhQBuZ9nvLgyMw2J4oW5w2xBSZVA6T7jiQIlDuxK3YsaINNpxi1tcpBsct4zE2O9MDdk+r/Xzi1JWZqx9FKZ8Nuba/uk/e1NmHebqQlGBpCRY257WhaPF/BaDaVUFXl8bOkW94uOEDL/jR0B2JW6D3sozfhwY6vp/6mqJJsqmtvCxu8FOeYTGNravWVBSYXrQTWZp8r0v3Z3DcbPfgevrdxteU60oGQ6SNbUz8nsCw9YUFq9VgclBXjhc5ncwx5Y7dpTUExTnjv+uHAzqhtaba4+svDAV+Z9DAuKdMeJ48sxzTgNO+H9UmBpKk4zTiWHhBuqV5ZZoIiTuc8DMSjmDIzU9XOqxOEPn12BPTXNmPnSKstzbgdgppP2FGW6WF1pqeOFD3fgP2srLY+3e6ySbCq+6kyPH8Dct16LX0vW967q5qSdxZZhKFDiwO9XW1DM/nr7v0/H/HOg/si2oIgCRd65i4LAC2bjVOyCVP2cqjnmkMPuShQFmS7UJlpNkhnIahEoKVq4NlXV465X1+DG51ZYnvPamE4F6fxUq3cdxp8Xb7a4AsUx5LUMwORtIq097QEtlhR4mnEcxFw85sfjTTNOx516QLKgpOI041RSLbioLEGyHitqlYpdkFqgpOazNgnuNBlzX6fk7eMmFZYqwPq5UjWX7z7cZPuc1+qgiC3QNC0poi2dwuvSR94HABTkhHD12IHG4+I86IUaSuYij8maOxQPZn5IJQVaUOLArtS9qAHk59Jd5vlAnSRQjmQLinTHtZom87Q0x5G2FBRbUnVzJsSYqa8z7uJJTQyK/LFSVW+msaVdeE/ZKugdISiTrL7OxPjdvL/e9H8xW8oL7uFUxFWpQggyfe8mCwqUOPDZWFDEG1BeVE0Fr1LXNAPdgpKXFQBw5MWgVDsIFK+Zw02pgklL57Y+lomddZtHXTzJrBlhGUMpWrcaW2OWKqcx7QWroEjSdvYZ2EzkhgKm/5tcgx7o5lQUH/TK3JEKKFDiQA+ukhVvu0MMSrrP2tBjUMqOyo2+/5FlQTnc1Gb87jSZe+HGS4UFRdXPqaqT4ISXFs5UuNIA6+dKleW/UXClyd+ll/pZJmkLZ1JeJTFys2SB4h2LIJCa4Oh0uofTDQVKHGSHIt3UIvnunYpatZp2/SlsXBS9PHxZYU7k/ZPk4knXMDftNh2CZL0wmbenYBek+lyp/qxZQevt7yXXgykYOaUxKKlRKE2tMRePdX4QF6qUvH2nSV5sRHoGkLgYZ0tj2mtzR5upCnXqYlAoUHoQOcGIKm+WBIpTJVnZgpFqc3lLVJDoRc5aU1ifIxU0CP56qwXFfdFsag2nra2p8SNbSfUk0zvbGiPvJWtVqtpizeJJ2kubEEW3xfrqoYVT07SUHICZtrlDEIJWC4r9HJ0J2lNQqE3Vz5keU8mCAiUO9EHfLFVrDTu6eFJTet4OfVLRfbBJC5JN003d1AV//YZ9dTjp//0Hd726JnUNNLVHmGSSJQQVX1cq+l6czPKyA5bnvRTvk6o0Y5lUBcmaxrTDYZ6ZXjitR0scWfFr4uZGztQxzx3paY8T7WmyoGTCPZwKKFDiICfq4mlulywoYpCs7JZoN/9fLkWfbPRJLjfJQbLxDvP9dS340XMrsHTj/k69j7gLkm8ucQJV7aT/tHATAODFj3Z26r0TJRWl7pV+5BQIhAZh0czLUllQ7Md0ujEXaktdqftUWVCcxrSnXGkOaf1dIV3Dp75ZtL6an2v1kEUQSM3xDemsQp1uKFDiIDvq4hF3RIB8NL19DAoAtITta08kA30xyUm2BUUxzlU3xK/e/Bz/XluJ7zzxUafeRzSHWyr2mvrZ+rfp3i2YXTypi0FJxSRTIwQjhxS1v807e+vfH6hvcazvkUxSVepe/lypSj+ta3aKQfFO8KZT8H9XSJebod7kHpYKtXmuhlIqAuwVj3ksrqmzJF2gzJo1Cz6fz/RTWlpqPK9pGmbNmoXy8nLk5uZi4sSJWLduXbKbkVRiLh6nGBTz31hcPEkSDHbog10XKEmzoMS5cFbWNnfpfRz99S4WlHTvFmodMo46S7oC3eqandtudltanx/zfwtw1n3volZ4nVSRqqPp01XqXhQoTjEodq60ujT0sdwW1f87S7pchKJA8Xq2VCpO6FZnAHYPhZISC8opp5yCvXv3Gj9r1sRiA37zm9/ggQcewCOPPIKPP/4YpaWl+MpXvoK6urpUNCUp6It+syQyTK4Hh8wTIBbEmioMF49uQUlhmrFqx6fajcvMW1eJ7/71I1TVWcWM6Ee2HsrovGim04LS0aGZqt4m7cAvVbElxefSNA0zXlyJ2/7+Wafep6HFPtYHkFPn7RfVXYdSb0VpS1GasfxKqXLxmMSgNE7cRPev//Mlhs+ah8UbOucyTQR5DKdyZ58KzC4ee0uVXXt2HmpM2obOjVSkGXulyGMqSIlACQaDKC0tNX769esHIDK5PvTQQ7j77rsxbdo0DBs2DE8//TQaGxvxwgsvpKIpSSEnmrrW2t5hu1haK0WaB7zsHko2MRdPrK0iizfsx98+STxGQzn4FfdyPALlB8+uwJIN+/HLf35uec5kQQknJlDSaUGpbW4zTXTpnmSq6lrwz8/24B8rdpl2jvHSKMRFqISmU7yPKNDTcaq0+cyj5C0g8r1q90mWbTqA2//xWaetRaIFRe5rpwB7AJizaDMA4H//Zb1Xko28207lCd127K1p6nSwcL1DBmDYJYvn/U0HcM5vFuLav3bONZ0o5iDZVFq5k/LSGSclAmXjxo0oLy/H4MGDcdVVV2HLli0AgK1bt6KyshJTpkwxrs3OzsaECROwbNky29draWlBbW2t6Sed5AjVCVva1TtQi3KXgmSdzj/R2XmoEZMfWIznlm9PqH0dHZqxwOUqXDyapuHav36E2/+xGtsPNsTa1BpWWjNMr61yPShuiETOudincAeZYlASnMzTaUGRD9pLZUE81UuLvdwZU7yTBUVON5W7VXRxpuPo+tSdZmz+v10Wz9WPf4i/fbIL97+9vlPv4xgb4RC/JpKOE3hlQZLuLJ7/rN2LM2e/i1s7aRV0cvGYLFWKfn7mg20AgGWbD3bqvROlLSWF2qyP2X2HT76/tVMb1UyR9Glm7NixeOaZZ/D222/jscceQ2VlJcaPH4+DBw+isjJy7HhJSYnpb0pKSoznVMyePRuFhYXGT0VFRbKb7YgoUMRUY6fJXB4gDXHsdu96dQ02VdXjv19bm1D7xBtPj5cRTZv7hYMExQVq0u8W4YxfveMY9BivxSIeC4pOe0dkIRQDNhtNGQ/2k7nqvdOZpim6d4DUHvilDJ4U1qvOxDU1tNj3s9y38ncvuinTIQrbUhUkm2AWz5YDDc4X2OAUVxWOc6FKxwm8mQ6SffjdSBbeqyt3d+p9nGoouVtfO/WWnSY1acaqOdF6XWVNM37xz89x+z9WHzFZPkkXKFOnTsXll1+O4cOHY/LkyXjzzTcBAE8//bRxjRw173Z65p133omamhrjZ+fO9CrAgN+HrOgCLO4ixQVEHiTyzroxDhfPqh2HO9U+cbAZQbKCBWdXdUyAiO3UA1uXJujnVgmCYCD+iTTcoeHHL67EyF/Mw+b99ejo0KRzS+TrnQPd0hkQdqjBbO5vaU+O605ZbMkliFWuy6NzqKEVt/39M3y09ZDlOVEIyt0mL0zy+4tjP5lBq3aIAjZZgZuA1Z3mlsXT2c/qtHA6HZMhkm5LVeT/qXNbqujqKcN1jv3snJWW7liNlKQZq95H8WFFK36qkzaSRcqHf15eHoYPH46NGzca2TyytaSqqspiVRHJzs5GQUGB6Sfd6OXuxS/ZSZ3LLh43gdLRoZlutEQQ26EKkhUFimpBdXJTKBdJpYsnAQtKWMOba/YCAB5futVaX8bBguK2aKeaQw3mU6PtREKixJs+LX5WO3F071tf4B8rduGKv3xgea7BtKuXqh3LrjXNXqCkuvAgEDu+AUj2acaJvZbT+Prz4s148v2tlsfbwx0mi5OTdcppkUyHi8caJJvec7yCXVRhXbOgpFegpCSLR2VVdnHDJ2tjlWpSLlBaWlrwxRdfoKysDIMHD0ZpaSnmz59vPN/a2orFixdj/PjxqW5KlzAyeewEikuasbhzVXHAsvDFP4CULp52UaA0Gr+rCsY5lcVX59irXDyJWVB0KmuaTG6nyPP275eudFw7dAtKQU6kyJksrjqL2kzrJlDUC8mOg43KxwGgMc5dPWAVTaIYS4cFRT8AE0i2i8f8fzfBYncO0MH6Ftz37y/xi39+brlfG6QNifNBo5l18chiM5XHN6j6Op6A65c+3oGL/rAUe2us7uh6p3RuN/dwui0oJrdl6jY3bvsHOwvKlv31mPr7pfjX6j1JaFnXSbpAue2227B48WJs3boVH374Ib7xjW+gtrYW1157LXw+H2bOnIl7770Xr776KtauXYvrrrsOvXr1wtVXX53spiSV3JC13H0iacbyIiwj3mQAcFAKxnRCXMj0c4PsLSjWgeloQYkzzVh08bgJBvHG3FvTbBFvThYUt8yTVKPHoJRHT42OJztr8/563PnKGuw8ZC8c4o1BiceC4jThNzgcKSCnwsrPt5hcPKm3oBwQLCjhDi1psUZOQdgq7J4XLQ/yfSXHnFmLD8YXANxV90c8HKgzb45SeVig6rPG8xnveHkN1u2pxb1vfWl5rt4U+B3/cSR2bUwldhvcrqDuZ+v9Gc/m5s5X1uCLvbW4+YWVSWlbV7HWuu4iu3btwre+9S0cOHAA/fr1w7hx47B8+XIMGjQIAHD77bejqakJN910E6qrqzF27FjMmzcP+fn5yW5KUjHK3QsDzCnNWFbybhYUOWV0U1U9/vbxTnzl5BIMO7rQ8W/F99LbKYoOcQJSungc/JEq8eIWJNvcFkae4iA61d/vOdxkcX85lbpX7cDkjIhUVQYFYt9j395ZAMw3ekNLO+6ftwEXjSjF6EFFxuNXPboc++tasGL7Icz76QTl68Y7mccTg+IUD9ToUH7dEoMiu3ja0+vikRfOlvYOy2FwnUHuVrf12C6YUVxX3SymTuXkndapVJ0TJLJPyuRLXqE262NhTbMsOom4eFTF6+pbxOKD5ufcLFXp3NyEOzSTVTB5NZRU76V4TPj8dpubBpd1Kt0kXaDMnTvX8Xmfz4dZs2Zh1qxZyX7rlKJy8TgFusm7ELcYFNmC8vjSLVi68QB+/85GLP7ZRAzqm2f7t/ruzO8DsqI1W9psMi70RU1c6J0sKKp2u9VBaWnvQF627Uua2lPb3I7lW8wpfpYCYS5mWvGxtrCGrGDqJnX9vfSTgMXxsHjDfvz1/a3YWFWHZ68fazy+P7rQbthXb/u68dZBiWeScdqR1jukGbtl8aTTxdPUGra4SZrawq4CpaaxDb1zgo5WJFnkullm7BZs8c/kHWm9xW3pEBvhlMWTBoFSVWsVgslAGRuheOlErESq+98pnTvsUkk2nQLlQH2L67linSFeK3c8m5tAArGE6cBbrfEwuuvE1sXjYMIF3C0ocoDslv2x1MZPd1Q7/q0+GAN+nyFQWm2CsfRFTXzMKQZFVQxMNfg7TIPfWYzJffWLaOG2oaURK5pzoTbn10t1Ro/ett7ZIQDmoGldzIm7pHhRWoYU34v4mN0BlOIkc7C+Bb9fsBF7oqnkzjEoUtCs9PJmcZ7aftbdO1lBv5FBJ/b1O1/sw9vrzMH2Ow42YuQv5ymDg0Xkru6si0fsA9mn39jiYkGJMwYlkey4ziLXQhL7WdM0ZaG69nCHa+kE1adSjZtEBIrqnhDd5xbrq/BfdQxK3G/dZSprzP2crEwadaE262u3O7gkddLhUkwECpQ4yYnu3MSbV1yU3Vw8icagiJOGW6aIPvACfp9hyWgLa0abxB2gPjDjrdKpmoSUVgwtfoHS3qGhl2InPPHE/gDcYwScDhNMltnUjpgFRWFRi/ZjTWPiAiVe/7j4mF2Arhiw/Ku3vsCDCzZg2p8ihRBFE66bBUUWouKk5iRqk4EuUIrzsgyriR7v0xbuwPVPf4IfPrsC1UKs1hufReporNjuLOgTjUGxC5IV/05ebGRh7zRmnarMZsKCIsZV/d+bX2DErHlYtvmA6Zqv/fF9nHLP26b+l4m3PkeiJQpk6hxK3YsLtTqYNH0KRT6vLJ7inR0dGrbsr3cM5FZv2lTXuVtf05E1lggUKHGil7u3c/HIk4zVxeNiQZF2KeJC6xaIqQ+8gC9mQQFiVhTVrlucdJ0Eij7RzjjveMv7icQTgCVeq9oJ5UczYxKNjRA/Szz+81U7D+OBees7lWqnFw/LM1w8HTEhGH3ucFPipdHjPQTRZA2zjUGJjYHPdh4GEJsc4z2UEbCKbpUYSxV6O/NzQkKAeuQxUQyIgbTxxjK4pVPL2LmzVJZJHbe4KnPclPl1xddKx4ZWj0EpjsZViQvnE+9tBQDMloJT1+2JVPNestG+hlK8gd+JuBVUFph4681k+qBRuYJ2PAH2//fmFzjv/sV4bOkW22vizQBsj2OO9piHhwIlXvQFSV+wLWXBbYKzsqOCwdWC4mAudUtl1dshFpQDYiJHvKkNF0+cFhR9oj2lvBDFvbMtfyu3AXC3oLSFO5S7Ut2q4uYus+zsxdiIOCacK//yAf7w7ibc++YXrtfK6G3pnRML34pZpSL/NraGExY/KgHrnsXjbqY9oSQWfN6mMMubUrgt/W5+3XTGoOhjMhjwxSwobdaxKwqBeM3TcstdLSg2n7VD+i7ufesLvLxiFwDr/WzNLrHP4hHHczrOPNItKAOLegFQ3792wZNOfacOaLeO2ZA//gxAiwAJd9jWpgLMmWluFslUn76su3gG9IlmAMZhQflrtMaOKntJpzM1lOzcS4nUs0oH3mqNh+lfEFmc99U2Q9M0XPGXDxz9yPoEVJAbiVVodBmMTkXa3Fw8skDRrXS6H1wVJCtOFE6vry9oedkBo6qlmwXFrb1t4Q7lTZWXFbS8VuT/5uus9TkSq5CoL+zPf7jD9VqZWAxKTKDo7y/2c02CVhSVQHWvg+IeJFtSkGP8vnZ3jcUPbq7L4GypSrRQW1u4A/M/35dwXwCxzxn0+ywB6uLY7YxAkQW5W6qpyp8faUfs71buqMajS7bg1r9/hpb2sCJ13v5vnbKl0rHB1xfKfvmROU61s2+02WA5CVVl4LeiKwMJFBBr79Cwr7YZH287BKDr9WZSEbRqh16iQBco4v20eX89xt37jrLonxudCZK129ykQxAnAgVKnJRFJ/rKmmZUN7bh421mP7dd5ole0EsOmpORY1BEWtyCToUgWb/fh6Oioqi6MbIwmIOjVLtQ+/euNwRK0FDXbqZSt0nGTsDkxmtB6ZAn9M5VZ2zv0NDY2o6VO6qxNc7zVvT3zgkGjAWxSSVQGhNblFXZUspUwTiEoOjTFxebO15ejYbWMIryspSv55rFI3yv8bh43lqzFzc88wnO/vW7CZ/mrVstggE/cvUqzq3WfhZdo0GT9dBJdDtn2MjYjSnx75paY+/32c4ay/3sdO6R5cwj4XuN9zDKcIfW6YMr9bkgP8d+M2VnQbGLzwFsFkmXGkp2bkvj7zs0XPDQEnzzzx9g+ZaDCkuVPHeI/ax+PZ1Uny+lj+kCvZ+Fe+K+f3+JytpmI2EgEZSxNYqxYLKk26wpFChHKKWFEdW7eX+90jQnj239pjcsKG5pxtEbrU+vkOW5eLNi9MHVJ7oA6Sfvml081riUJodJQW937+yg4Z90m3g6U/49O+g3gjvdKpyayoR3aCaridvCKbs4Pt9Ti6//aRkm/W5RXCbedqGv5eJ94nuLcSjxxJ0ps6Vciy25TzL1wsKipzlPO+3o2Otp9hO008IZz2S+Mfp+dc3tmPe5/WGgKsQxrVtQ9PtOXIhrBSEgWlCc7hm3RU3Gzkog/p24gC9cX4XnJOucc5qx+XXF3W08oqO1vQPn3b8IX3vk/bgOJZXR5wcjdV4xVzXZFPhz6juVKHVL6Y4nfu1wVPy/8dkeHJYC0hONQRHHeDx9vedwE975Yl+n3EH6/KC7h8V1pCu6QNVnqiErjjPbGBQGyR6ZlBVGLCgb9tXj249/aHlevvH0G0NVL0OFvuPq29taQCRuF090cBX1iggU/eZVBcmKoqUpDgtKr6yA8fqddT04kRMKGDeHU1ZD5P1jv8uuBrcsnv1S8a8v9tYav1dJz6kwXA8BH7Itrge1BSUUh19XmS3lZqa1s6AI76eyzJUWxtw+5lN15V2++e8SdfGI18uuJTf08RkK+CxBsuJ4rhWEoDi52vn328IdFjdgIpWPzY/H/k4UPXMWbTY2B8cW5ynfwymLJ9FDGfccbsL2g434fG+tcTJwIsjWXlXfiZ/VdJ6MQ/tUllmVsFVZeO0Q+23noUb86LlPHV9fHtOysEg0A/C/X1uL65/+BA/O3+B6rUysnyObUFEI6u7tzqCaO9RBstaNqgzTjI9QyoRJXeUOsItB0QeeW2yEHoPSVzC/68QbJOuXLSi6QBHdAoo6KHbWHXEyj1hQ1BYO+TE3M62K7KDfMPUmYkGxniPi/N5i1kfk/7Ed2IZ9da7t1CfnyM7eXJ9DnGhFC0o8aZTqdG7rdfH4kcX+UVlmxPgZsb/kxcYpBiWehVOMPTmUYOp1LHXeH0vxN1w8ogUl9h6iu6G5Vd03qlgKtyweu4XLZEFR9PMZxxTh2H5qgSJXPxZJ1IIi9vNKl5pJMuEOzXAR6C4et+BN84F38bvS9PezPKa5j+nY+8Wu3VXdZNT3KY264J2OyVC9v/jdxuO2fPfLKgDAH97dlHDMimFVVwjBXtmdr5AcrxCMy/oqzFWpDhqOBwqUOFFZNkTk8aAPfD0zxe3G0wdZkUKgxJtmrKtf3YKi1ygw1UHR04yFx+xeX5zMe2UFDQuK284+nuh0meyQP2ZBsVhMpElGdEuE7SccFbIFRTx8zKnSq/HeQvCmvLMXF0jR9ByPX1euPAqog9/MAc82gYsuC2ev7KBhUnaMQZGzSxJcOEXxcLihDXsON2HR+irXvwMEC4rQz02G9U+0oAil+8PuY7BeMZl39owfcXFWWapyswLGd++0UFqyeITFI55dvamfE4x9Er9Hw/XgMt+YMwDt26cM/O6kVVB17dYDDUa//nDCsZG2uQgS+as29XUc40Ccn6sTFd1SBmC74J4WjwZJNJZIJQQ7289iHZR0HGfhBgVKnAT8Pkw+qb/t83YmXF0Zt4Y7HCfCtnazS0ik2W1XEbaxoERP3lVWkk1gMs8K+JEV9BuTrWrTJH7+zmRtBP1+2yBcJwuKfDO73dz7JQvKnsMx18PGOCwo7YZA8RuxEfrNLrpLxD4IxVGfQ5lm7OIzt7WgmIJIFQtnKLZwimJPFp7y24uCKJ6FU7agXPrI+7juyY8xb517PIoq1kdlqTJZUETRbTOm43WlxYN4H6gW416CQLEE0ZtKsJv/zpTOHUfFXrGfqxtb0dregYXrq+KKRxHHmF6HyLVMgEMFXZG4izwm4B62s1ro1h+nYzJUz4t97XQmGRCxKIjfsxz/4obs4gFi41Qf44DZbRkPqgBm9352z+JJ1pEHXYECJQEe/c4Y24BHu0qyojJ2UqT65Ko6ZM81SFYo1AYARXl6Fo/VxWMEycbh4hFTjAHYxogA5sF/KM6TmLOkhdsIwnXbBQndKAsSN9eDfPPrJmIgvhL1RrxPQOHiEdop7mRFv67dBKsOknW2oNhN5naxETriwin2l7VMeNfM4aJ143Bjq+Fee+XT3a5/q7crFPAb2V3NqiBZ4fuMx7qkTue2XhdfwLRgQVG8bkQIRsaI8/ENXbOgiALlcFMb5izajP968mPMeHGl69+K7VK5ePQxLrZZbFMiwcjia9g95u7i6bDMwaK71dLPLm5Lsa/dxGBzmzl+qTpBa5XettysWAag3n9ityRa6FFlQVG6eETXeBxBsskqxd8VKFASwO/3KS0cgHUy1ydwMfjJyXzZJkXSi7ilGev3lZHF08ucxSNO6HJRMSCye1eJigYjQDZoen1lkKwmLs7W11L9jeh31TStUxYUi4vHZZKRS7TvEVw8btV+xba41ecwxaDEkV2i9/UdFw7F+OP6ArCxoMQxmYddBEpOKKDsa3kylxdpcRwlGhshjq/thxpd/1a0oBhZPIo0Y9GC0t5JC4pqYZL7Xn3eiXM/iwuR05juapqx2M+t7R14atlWALF4CSfE+0Wfe8QNSy9h/tLdWPH0MxD/zj4e0R173lpDqVcovn6Wn4+kZsfnrgKsluF4N2Kx14/Fr+WGrMc32L2PG/EGycZjqdLiEDHphAIlQUTznIg8Hox6GSG/4e9vCdvffPpCq7aguO8qAKtA0YWCqsqrOSpfw6j/nY+Pth4yva4+QPXdSbxBsocUOwtl/QMpuyVgk8bsdI6JvLi4WVD0yTVfKFWvIxd9cvp7ceHUJ3RTkKwg0vyCQLFfOCOPlxZm44zBRQDUfRaP5cstDbRXViAWg+KQZmwNKBQWzjj89bUm10Ps9x0H3WvO6P0cDFhdPGYLSmxyNu3sXayCIioNIPeFSgyaLFU2rjR9R5pIDIrpoM8ELSiAucqxmyVITOfOU5wvpXqfeI/hUAbJupRld4tBUbUtJ0uwVFn62fx64tPyIu0mBuV+rqptxkV/WIqf/f0zx7/TMbmHs+S5owsCJc4q1PEcFhhPOfx0QoGSIPk5aguKXZpx0O83zsdxtKDoOfKKaG63LB7jLJ7oqmPERihqnqgEio6cOtcmmNkBIKBY1HTESVZlQVEtlHJKm2gO31vTZBz6JosQ8e3lXY+b60Hv534F1qBnt2J6gBgk60ee5RC7WFvEScZc0MvZ9ZCXFTT6RX1cvfAeNiZmt+yC3FDAKGrmXKjN/HemqrMu/Rzu0EzVkcUxEZcQNAUjm11pYjsTjUHRg5H1ap6Aewl0QH3vit+FmwVFLqlutqCY/y5RS5XsthSttm5uS+NIAcWuXn5/va/j6Wegs25Lt/tXLbjjtaCI35lsIUjUgvLepgNYt6cWf1+xKy5RobclpBTd6vs6nrRfZWaai5U7HusrLShHILYCxSa/PhjwITvonsnT5mhBiS+qXhcohiAy4k1Ed45VsceeM08o+kRkCBQnF49LDIpqEZDTb406K5qGSb9bhMvnLMPa3TXWmBRHF4/zJKP3s15tV8StmB5gdj3o35W+gwmbsnjEhdPdtKr3vVs6tzjh2mURqFwWYryPfQyKtNuUd/amLB7nfpYPv5Q/imtJc7GSrB6DorBU2cWg2C2cej+PGFCIBbdMAODez4BZCKmuUd3buVkBI21TbLP8ds79nJiLBzCPC7fAb6OfpWBk3fKiCn5XbXhkVPVm5NfTMZ3QrSqCGYfgDtjcM07VkS0lChK0oIhWwU/jSO8Wra+9suzdwzUJlihQZaa5l4Kwi1+LLwA6XVCgJEh+nC4e0d+YbQgGJxePfZCs3TkYsfeOLprRBV5/v9b2SOaQKQCr0Wqm1ZF3tjGBEnndeINkVamOKouNnN0ipmTqrpeFX1Y5Z/FYXDzxWVAKlQIlfgtKKBATKLqwaTP1QWyREG/6Cx9airfW7LW8rm4O75Xtls4tBum12sRGWNutL/JA1CTus+7s3Urd2xXrUqG7XnJDAVOgpY7b4Zl6nwUVrjTxveta2o0FTHzczi1aL8RVOQpu6f5Qie64LFXGwmmfmWM5ndshcFmF6OYCgH21sUw1OWtNxrBUBWJuhw5NfRK6LgbFey6eWJ/7pg03flcWEBPeQ2V1ceuDHAeB4hT4Lc+BiVpQxAD7FdLRJyrEwG9LXJWN9VV0g9vdcyrLr5votssMFd+i1SEkIV1QoCSInQWluS2MnYcasakqsmMxFjK/H9mhmGCwQ7858hUCpa6lHb90OKNBH1R+hQVFXsCb2sJobgsrd9my+0E8DwWA7SQAmG/8+pZ2y2dVTUxWF48v+r7mYFOn+hxyaqDbwqlPBEf1stabic/1YN0F6ZOxuKjVNrcb7ZYzZW56/lPL6+o7KXE36GapagtrcZfIF8Wg+B4HG1rx4kc7UKPoZ2sWT/yxEbpbMjcroKyS6XT2FGB2kfaWLFXmImexHWQ8O3v9u+otCEG3jAdAXWhOdR+IwjcS62MVm/LXI3dlIv0MxBa0kGK3rUozFxEr9vYSUl3176dNsbM397OzEMwK+nHVGQMxtDQfgPvmRmUVdDvMMeD3CZsbc3uswc6x3y1zh0uAvSxQ9grVkeM5y0sU3bq1qlHl4hHeR0z7tR3TynO8FJYqU8yUnXtYSKjoRMHNZEOBkiAqgZIbCqClvQPn/GYhLvrDe6isaTa5AtxcPJqmGTeHyoICxI7dViEOfEAUKGHlQK1VLEaAvYsnKx6BIj0mWhAigkjl4lFbUEQLTHVjq2NshPy6brsgvZ9VFpTW9g5XgWOOQYkunMap0ea/NXaccZ6nAkS+O7vAStVj1Q3xWauyhMUrFIhV7b3lpVW485U1uP0fn7kWajMX6HLJlmqPLXyi9UZHJazM7xULktXvCf1v5PfW+9l8fINzMHIvwf3itmgCsaKHTtcA5nGVI1hQzKdGyzFV9kKwNdzhGuiqWzHEk6t13Ps5Nk8FA7G4qrqowBbfWhmD4tLPuri0K1gHyBmA8Y1nsZ8jGYCJZ/EkWqJAF236e4uv5XQavdyWYCC2uWlUjGmxD0SB4mat+v1Vp+KcIcWRtrkE2NsV9DO5LVmo7chD5eIZfnSh8XtLewf+tXpPTDQEfMYC7xSYpI+nvE6UPJaDZEUXj7hg65PF4aY25UIux2DYunjiECi6f/aZD7Zh6P/8B/PW7bP8jbjj02C+GXX2HG5KcJKJL8iuQCFQAPc4lDZhQtfTpBsUQbKAsOOMw0zfKvS1Lh7iCd6Md8cZCkpi0BezoADA2+v2KVxp6jYC8cT6xASXyoJidzqujhgka1hQdEuV9N66laC1Pfa43ffYYmSmxX+2FKCueeG2cPbKChoiqKaxDVMeXIx73/rC1ZUmx0a4uZJ0MXiU4qBRt2JtoqUKiN0Xtc1tlnurRiG43erN6POZk1XQbeGU3W2AuT6LOHdYz/Gyd6dZz/Fynjt0F33f3lbrq51FQiQW7+M3Mq3qFZsb0YJi6mu74xuiY738qFyMOzZaokDRZ2Lf28WvMUj2COfksgLrY+Xmx95eV2nameguHj0waX1lHd5cHYtDEG/Q3tnmSUY83dhuN2S4eHxmC0pruMO0YOs31uHGNuVC3tJurnZr5+JxK6MMxHz2/+/1dQCAu15dY/kb2cWjiljfVNVgmTic6qC4iQH9c6ssKIB7HEpYsXA2tqoXzsNNbdA0TbnA2O2aswL2Jf8B6+dTuR5UO0G7eB8RtwDDdpPrIV4Lir+TFpRYPxvByC1Wfz2gtqAs23wAX1bWQkYM/HY8nTsuC4q1D0SRkCuIoJc/3YUN++rx6JItCsEttbE9sTGtf6Y+Crelq4tH2oToZRRqm9otfaDHuoj9bysEpQqpTmNanHMONynGs4vLskMTBEpYw7LNB/Ds8u2WtkbeK/a7NQYlvvi1zvQzANOmtbfFKhhrS62NQHGzoNi5FGPvb3YjuddKoUA54rh4RBneuXWC4VMFgB+ceyzOGVKMmZOHAIgcYiW6ArKlrJoLHlqC6S98ig+3HARgHoSyBWXJ7ZOM3/fVqk+EDUsunuxA5DU0LRYM5feZ66PYTXoq9W518ajaYO/isUMMAPNBvWgeqG/Byh2HTY+ZBIo0ebm6eIQzkuRKtkD8wZuRGBTzwilPcIcbW23bI/qNw0Igs3ikgKqf5UlFXzib28L46Uur8ObqvcpFIB6BIo8Jq4iK38WjX5sV8BvmbJG4d/YBv3FP1EcDYuVYgdpm68L5ZWUdLnxoqUVIia40XTxomvMpt0D8MSiiZS43y2/ck2LfyTtTaxVqqc1xLpyquCo3IShvQgpyI2O6trnNsrjXKITggfoWZfxFi2BBA5w3N64WFMXfZIkWQU0zuZCufuxD/M9ra/HB5oOO1qpEXTz699ZHYaly62fx9U0WFEXxO1GkiW2yszo2meLXIo+pxUfsPTo0dWYaLShHOD6fD8f16206NKr8qFw8e/1YXD5qAICI+Uw0UesxKPIX/mVlJKBWnLzEMxmAiEvpuOiJqPYCJfKvHiSbLZg/dR9nMOA3dneHm9QWFMB8o8kuHsfskuhjumUintNrgwEfju/fGwDw1eFlcR2qB1gDRUXcbiqx7oPqBFG3g9JiWTwxf72dBaWmqc22fPYhoT6F2OZQwK/MsNGxWFCiAuXJ97fh1ZW7Mf2FT9UTupzSrbSgSK4Fx0qy8bt4enUmSFbIghOrKze2hW0tKCrRVCUdDhkT3T5TH7jFLogWlCff34pZb6xzdfHkhoJGbR8R+T52KogHuC+cLU4Lp0s/ixZBQLSgtCmEYKSfxWrM7R2RkgDvbzpgutYQgtLmRn3Krjr+AogstCohmCVZUIKKQm2b9tc7Z/EkGGCvf+7CXJWLx12gGHNPwGckQ8RcPGbrBmCtlzPtT8vw7AfbrO0SRbdNwTrAuuFxc1u6lbdIBxQonUQ1wesCoLmtwxh4gYDPZEERFyP9cX0y9vusgaNALPitqladMiifxSPevPpOPej3GbU/ahrbbC0oohnR1sXjYBosFtxIbgQDfsz9wTj8/qpT8ZPJQyx9esbgIuXpzuYgWfNdt3ZPjeN76tfbxUbc8MwnjnUXxODnXpLrQY/L0L/Xw43qWB8AONgQ+y7FHXLE9RCfOVx/D8B8KrPq7/pI/ahyp8mTrPwypuwSl4yHFsHFo7KguO04xXTuSEXWyOMNLe3WINlm+1gfMRUUkCfzWB+4VdEV04x/8c/P8dSybRbLHmAWKKGAD4rb2ZT9AShiUGQXT7wWFIXb0tWCIrgdAHMMiq0rTdGex5ZuMf1fdPEBwubGxa0gWl5f+ngHRvxiHpZtOmj5G9EiqCFmQRG/p5Y2a5KA5hSDErcrTdHPre2u9VpUcVV6cK24LjjFrv1P1GWuo2ma8TmyAn6XYprmz6vHoWiahkXrq7Cvttkc+BuH6Eo1FCidRDXB984OGtaG/dGdW0isJNseNgUn6Qu/fmOoxAkQEyh2qWxhfbepB7P6fUb7lm7Yb7RXNwEfbrJ3PTQqqkjqk0E8pe6Le0cqtMZzTkXI70Nx72x87dSjkR0MmI76BoBji/OMc2lETGba6GTeLz/yvh9sPmjc7Ptqm/G7t9ebFqk2wcyqWjgra5uxaX+9sr0dQjBz0O8zLChG+mu0v/Q+sIv1AYCDggWlzSRQYotaIjEo5iqv1r/7+dShGFqaj/+9bBgAm4BkeeEUXlN0QwHA3sPNzqdzC9Y3VT9/vscaH2L6e0MI+uHzmTN5VJYq8T1FdssCJawWKHaFFnWMgzelGiwyokjw+aC0oFgFivl5+XO4u3giL6By8bhll4huBwAoiLoeapusQlAXw6rxJceiiEIQiD9+raE1bPztHS+vQX1LO25VlJIXXTwdHerxfLDB6soWP1KiVagNF49i06RpCQR+B/zoHbVUGS4ek+WiA81t4biy/9qFOcl84rz73KGLwbfX7cN1T36MSb9bpCzMl0koUDqJauLx+WIiQP9y5TRjcWEyyhzru43o4Dq14igAMM5kGTWoDwDgL0s2Y5tCpOj3mbjA6zfw/dHy9aGA34hBOVDXqgzwA8xBou2COTzy+pHHnSaZ4qhQsIsSF7FUkpX+X5gbUmbbmAJ5o59j5ICjcFSvEOpb2rE+6jq78bkVeGThJtzwzCex6wUzay+blO4DdWpLlWjyDoiF2lrMJdgNK1KTNUVaRxRwojnc5/MZY8up3oxupdFdD2KfqL6fo4/KxX9mnovvjBsUab9iQv/Hil2m/zv56w82tBouytb2Dnz/6U/wuLCLjrl4AkoXzysrd+OdL6yZXTr6+NQFv5jJI0+0+mZANaHLYkDc2Ysnt7oFCB+KpnM3ChZGVfpvr+wgzhlSjOFHF2JwcW/lRmavJJqshdrMn0OsNaJpmmkhDQsukD551ntl24EGR7enHL9msqDI/Rwt+qYSTLI7QL9GH6f65kYlbuwWTidCAZ9hrTrnhGJlP1fWNDtm8cj9HG+QbEFOEIq3izt1PuS3BsnK4qjWJtMSsD/Qz9XFI2cARsf0u19G7sPGVrPFSRWjkm4oUDqJqigSABRJu5hgQMzi6TAt3HL9DD0V9Pnvj8Xr08/Cc9ePBQBcfcZAjD+uL5rbOvCbt7+0vGeHsduMtSlbTiv1+1BRFDl/ZGd1o70FRQgSbZVcPPFYUPpFrQeqrAcZ2WIkB632L8hR1p0JaxpeX7UbD7+z0ZjwsoN+lEYtTXqQmW6CXyfs1tuF4M08xc4eAPbV2cX6xD53xIISaVtrtKx3m2RBqWlsszUbq86QiSvWJ6y2VJkPULT+XTxBspb3Mu02Y//RrVrvbYpY595cswcLvtiH/3vzC+OamOhSW1AA4Ldvr7d9bzGdG4DJgqK3RdcXekyHavGzuHhEc7hoQZHWJr3v9e9Er9orBveqFv7sgB/PfO8MvHHzWaYCYiJvf15pfi+XGJR1gtty5kurMG72u8Z5LeK1RyliI2qa2nDPG2stj8feS7/HrTEo+uKu93Ndc3ukppFiIbcrUaBvlFRnEunIu/144tdCAT/+NeNs/OLSUzDz/BOU/by3JrESBaJbevfhJvz6P1+aXKeiVUhVr+pfn1krROuIFb0Dfp8xrxkF8aSxW+1gfVVtbgB9TMfeT0ZOPa42DpONPWaX7pwpKFA6id0EL9ciEEvdt4bDRt0JIBbAqvucdTNrXnYQIyuOMplH7/rqSQCABZ9XKaL+rQIlSxIooYAfFUW9AAA7DjXaxhA0ttm7eBwrb0rWA1UAlkxI6sOcUMAImgWAUysKladH1zS24ba/f4b7528wdvFi6p5ThojJgiLs7H92wYnG75U1agtKu0mgmNNnm1pjxeiMdG6HYGSlK834viOPKycZTW2pEsVMPFk8YgZVieLgRMA+nXvEgKMAALurI5O3ylctjh1VMDIQCS63Q6zEDMCUaqy35ejo3+ul3VViUBYoYl+LFke7+hm6EAx3aKhtbjdlealSbENBH3y+yA+gnid2HjK3SV6z9Y2BHusgnjL++qo9OFDfgjdW74leKwgURWwEALz40U7l44BYSVbO4mk3Fs2+eVmGUFO5TQBgX02zcmevbzpiacaqNkgCxeWAQyCyIako6oVrxx9jOpRRZPmWQ9iy32xxFvtaFpird8WE4Pef/gRzFm02VX1uFca0Kn7tV299gYM2RwuY5o6A32pBkebjytpm202k6LbU26THLyZiQdHXIrvjLuRDKDMBBUonsTtlUg7qFGNQ/rhwM/YJJmc9gLVdMmerGFISWbhbwx0WZSufxRNpn3XHPDAqUPYcbrItUd3k4OKRK3qKGAunsLN3q4CpirkRF61TygtNLh59J/63T3YaN69+swb9sV2NU3CXuHCK/T1mUB/cOOE4AA7ZUmFRoPiQFfQbE3B9a7uxcPY1YlCc0oxjbWyRAgrjOfOonyQERTEjm9v9PutCKYqrS0aU496vD4dMh6ahrrkNf/9kp9Gnfl8sEFQ/GVh85db2jmjgXtRSFfSbSqiLOGUJiGdZAbFTvhta2g1Xmy5QKg0LinVMH25swx8XbjLcSfqilC0EIwPWBUL/LiOl+iPvXd3QanKBqoRw5yxVkgUl2sazjo9UBdVP9TbdT9HfxUwUVQyKG/JBo6IFRTw7Rr+vD9S1KMd0XUu7aV6Qx7QRV+VQfFAXZAfiiV+T+tkfRz/L769/Dt2yvGrnYeO7+GJvxOoqBkKbig/aiG7Zpagjjq9QwGekGeuHaup9rY+1ypomW5eTKLqtsT6Rx53c8PrapbuyRTEj9g8FyhHMmGOKlI/Lk0TA7zO5TR5asMH4XZ/s2oSJwI7sYMDYIf1r9V7887M9lhNHnSbcYMCHfr2zkR30o0MDth9sBADccM5gPP/9sThvaP9om+xdPGIdFRm9DWXGrrbZVgQZbVJMKlNOLgEQESM5oYARtAfAEFgL1+83HquMmmDFm97JFyweeS6mrx7fv7dhSXhq2TZlfIT+tz5frK9160BjS7vR50aQrEOacYMpnTvmdgKcjxTQ26AHBVdHhaC4ZsgLp2pcnXtCP+P30wb2wbhjreO5Q9Pw9T8tw8/+sdo4aiGy+9PrkkTFkfDeX/3DUnzzzx8Y4iOSxRPr5wnC+1baTOaAMJnq4jhLCJLVLSh9ImPtQH0L2sMdShfPJ9ur8du31+P6pyNxSMa9JrsebFw8Qb/PCIo81NhqsqCoxpnc1+JC1qdXCL/75kjL3+iLya7qRjS2xlxYujVRj7FRFc4SKxCL75UbCpisqHZiUK4kGzuhO2zK8DEESn2L7cIpbgzkhVN//bDib/U29M+PuGjtrBAiVougFGAfLc0go3LxnFJWiF5ZAdS3tGPrAXWAPGCOX7I7kqTKxj0sirqA35xmLGbi6FbuypoW20zL11buwbh738HCL6uMMWG1VNnPHXrSxYFoP5ssKNJ5YpmGAqWTfOuMgfi/y4ZhwS3nmh7vK6dzBnxGHRPAXKBLLvDldrS2Ht/x36+txYwXV+J//xXx+bdLyhiwmi9D/siOUb8BFkQX4JxQAGcdX2y4ZpyyePQgvJU7DuPSR97DzLkrjVgK/YbQd7Ut7R2WDAoZ1ee9+oyBuPfrw/HGzWcDMBe+0tsuou9YxNoCTi4eMWvhW2MH4twT+mHuD8ahb+9s01kmNzzzieV15B0IEFs4G4QAM13oVNW2GFlGJQXZ+PnUoTglWnVYFK2yv75Xlv3n0C0l+oLR3qGhrqXdZD2QXQ9+n7WfLxpeZvx+2sCjTMJaF0jr9tRiU1Vkwn57XSRuIisQKzKlj1/RGrSpqh6fbK/GjqgAll08x/bLw6LbJgIAthxowFM2Z0zJ2SWqINnSghwE/D5oGnCgvtU1yLGjQ7O6HmxLpEdFv89nWEWrG1pN34nKxSPHUY0/rtj4/eg+ufjG6AHWdmkalm06gHN+sxC3vPSZ4arS31fPxBHjlvQ+0MeX7HYI+n14745YkUe7EgVyJVld5DQKFsGQ32/MD7oYVPHWmr14YP6GSD9LYzrWz9a/0xfF/tH75mAcLh7ZhV2QEzK5uGacdzxuOGew5e80TcMn2w7h7XWVxnjJzQoY8WsHHN5b3EiIfS0W7bQtBSEIhpBQqK1DiyRLtBvWnKhAqW2y7ef/rKtEZW0z/uupjwUhGPneVPVgdDqk+Un/rKL1VaxxwxiUI5iA34dvjxuE4/vnmx6X/flBvw/TRg/ALV85wfIaRpCsMBE4oe+adf72ScS3rAqSlQWK/tx144+R2mdeFH/79nos/LIq2i7z5KUvYl9W1mH1rhq8tmoP3v0icq1+A+ZmBYzJ7HtPfez4eWQ3FBCZyK4eO9DYPaosKCL6rs3k4lEd2R79LKIfedTAPnjme2cY51eIZyp1aJGUZRHZ7QAIE3pLzGd/fP/eCAV8qG9px7aDDUb7bpxwHK4eOxBAZLFZsmF/JJ2w3dzPxoLY2GYbb9QrK2gU9Yu4HsKWa+R2ixTlZeG568fi0e+MRvlRuab6Hfrvonlbd69FYn0iz+v9rHKp7TocESjZQb/pez7jmCKUFsaE4Kx/fm6KsYh9BrNozxMEiijodNG++3CTsePXD0yTqWlqM33/AJATXeiaWm3EaMBnWA4PNbSaxFg8FhRR9J5YUqBsV2NrGDc+twKaFll89PGgj4PW9g60tIeNUvNALLhS/DxikcfCXiH0z88x3Bd2O3s5fk2sjixWTdbnngP1rbaB3//35hf4wzsb8fa6SoUFRd/ZW8eiLg4NC0pDi6t7WOXiObEkNhefeWyxZb4EItaob/z5A/zw2RXGvRkK+JAfHfNO7mH5M+k8eGXskL59LkLQH7W+irV96ptj1teKPpE5bm9Ns2t6OWDNlnKKXzOEfaHZgiLOF6IAr22yzj/phgIlycgnigb9fhTkhPDj84dYxIs+2bUZWTwuFhTphtNvGP0GF3fKsp9Yf69vjxtkUvz6AiDGJPxXVFjIridVgaJYJHgsDka/AXYcarRcL7pV4jnrQQySFQWKXHE3KygEnjVbiyaN+MU8PLRgg0V0iVQU9cJHd59vuCHECH5AtKDEbht9Qr/68Q+NHUduKGAI17W7a0zvp++8FnxRhe/+9SP89u31lrLguqXqUEMrpv5+Kb4xZ5nhDukQrDj6eFi68YBjaqadqfjsIcWYckopALPoUgVb6tawkFB6vsEQKNad1nbDguLDidHx1j8/GxecUoqcUABlgkjRhbaqzfrCFot/CptiI/TYrC/21hqP337BUCz7+XmW1zzY0GJZZPR4IXnXLo7nmGBstT17Rkc1rv72wzNx8Ygy3PXVoQBgWPqAiLuwsTVsMqfr7hjxzJe65nZTPz/x/lZU1TWbT8EWvsNvnRERwvqi/40/f2CMRZF26R7Xx6doQQkGYhly2w82GALqhnMG4583n21xp2w9GDs/Kzv6unrWimpXbrh4BAuK3bkzOnKWIgCcJJyTVlqYg6K82Hypb3QefneT8djGffXGZ4/Vf7G3GogW5Q+2xDYvQ0vzcdrASCmISpv4tTZp7vD5zMXa5HiYvYebXSsIA1bRpH+Pqrk1ZuHVXWkR97A4V4r93t6huX4PqYYCJcnIAkWs7VFaaM5aWL7lEH4ydyX2R1W3yqIgou8WdVrDHWhsbbf46/XnRMQJWDzccEDUj69KuZV3m6pDsvRdnVHN1u9TuhR0jinuhYeuPBWDi/Nw6chy2+t0zC6eWP9ddpr5b4NC6l5DSzvqpR1xY2sYDy3YaJp0VfTPz8GgvhEh9NInO3H5nGVGwFy7op9VwXIBvw8nlUUW5b8s2WJ6P9l3/cR7WwULirWfv6yswyfbq3H/vPWmNvj9sWMC/vu1tfhsl3Xx6SyqiqR6PFHI70N+trnIlLiz19lVHRM0g4vzsOCWCXjn1gnGIvrYd8cY3//emqZIFpRYqVb6nvS4l13VjaiLxr4E/T6MGBCxej35/lZjcQkK8UgiB+tbY0Gy0QldFx/3/edLTHlwsXGIp2hZ0IXgk+9vwztRi6Ed8qnRQKSe0SNXjzLEkDimy6T5AoiJwZxQTHTXNbebRMzhxjac/euFhjDVXUt3fXUoLh81AN+PujfEoxtufiGWkaLTJtVBMWKqWsN4JLqYhwI+I3NrxfZqo2+ygwEMH1BomRc0zbpw9o2Khc1VDXhw/gZToT7D9RDt54MNre41RRSWmJ9OPgEXnlKKP397NACgSKgLc1z0Xvl8b+x99Q1URKDoFhSrQNFPMW4RPtOtUYv4jyYeB5/PZ2w+X/xoB34yd6Ul5iccts4d+UKxNn3s6/f01gMNxgZgUN9eePK/TsfFI8ogI7ss9fF8qCEy1uVii0BsjWoNd6C2qd1RdOsbjUxBgZJkRPM1YI5XKFGYHF9ftcc46dcpiwewWlCAyEAU/eV2iDf8cf1iqbwXDovsoHOltLkV26uNyU9vl+oE4NrmNlOF1YDfZyxOKgI+Hy477WgsvG0izlRUiZURLShlhbkYMaAQZx3fFxNP7G+6Tk7ds9sJtTpYUHT073Dt7lqs2F6Nqb9fCkAdg6IqQhYK+DFusPmzGZYAhRD88dyVxt/p/xZIC+z26GQqBm8OEVKyVfzumyORnx00xZvEg514AyILsHh4H6Ce1HX0Ber4/r2NCRkAhh1daOzyl285hBG/eBt3vhI78bpdWjh1YTfv8314a00kHibgjy2cm/c3GPFdoYBPmQb6s3+sNnaEel/rMWMrdxzGhn31mP7Cp2gLdwiWKr9hcdxb02zEbolcOabC+L23TfCkiFjbZ2Bfq9tSzIDJF7I95H5ube/AP6Ppxvp4/sG5x+H+K0YaxSEvPTUm5LcdbMThxlbT68gLp9hvH22LuN6Cfh9GR4tFbt7fgKeWbTP9jfyZa5raLKXu9dT7/6yrxO/f2Yiv/mEpth9sMJ03owfYr9hejWv/anUPi+O9RRGAX9grhD9/Z7Qxp4kWlOP7We8VPX4tKxjr59rmdotbY/g9EeurWK/ohnOPxevTz8Lt0fIEJfmxef/1VXvwoeS2lIUgANN8pVtYju3XG8W9s9Aa7sB3//pR9P38mHRif4w91jpftobDxmcAYrFpuw83YcJvF2Lq75calmDDDR8KGHP5nMWblbGC+piXjzBINxQoSaa4d7apyqA4IFXHzgNiZonz19FfUa9i4756PPFeJNDQ5c8NvnPmIFw0ogyPfme0MZHJJtPL5yzDx9uqTe1SlXg+1NCKFTuqjf8HfD7cc8nJtu8d74GAOjnCwYclBTl44+az8fz3x1nEWsgfq+y64IsqXPbHZcrXk9MfVZQVWne12w82mHzyOqoFKej34RujB5gyZYwAWMX1unVCDLDsK1nLdLGoLyh+v8/YFdox7tgifHj3+Xjk6tMcr5MR/fCTT5KEoD9mnWiInj/i5LePp5/DHRrawhr+vmKXUYAsFiRrFijya4+KmtbNbfRHT5s232+iyzHm4rGOafGwT78/IqacOK5/Hv787dH42QUnuopGwCz0cwRXpVyiIOgXBUq70lK1IeqmkOMidH5wzrFYevskw600bvY7mPjbRcZ4kl0POSE/5H1OMOBHn7wsnFBi/mwhw7pl/m4eXbIFr6zcbWqXnDwAAMu3HDRlgA07utB47y8ES4dOXnYQf7/xTJx1fF9crwiAlRHf0+leCQV8hlWrrrnN4tZoDXfgoQUbTae754QCGFlxlFHvZvzxfU33ypur9+DWv30Wi/NQWG71++iaxz8UBJ3PGG+ym7O3wlr7vaci2Wmq8by3phnr99XhofkbAQhuS7/PECB/XrxZ6YqfOTliIVr4ZVVcJzWnCgqUJBPw+0wTjei2kc+akXHauQJAv97WhfPnr6wW3ju+r7MgJ4Q/Xj3KiD8AnIPDYv7pgMXy8OrK3fjmnz+ItSHgw6Ujy/Gna0YpXytRgeLz+bDglnPx+vSzTP0qB8wGhewSIBYAZoddHRsAKC2wFhDbcagRzyzbHv1bMQbFOmkEoxlTN008znjs9GhaumqS0REXGTneR693IlpQBherUynFdvTKChqTqBv6adw3Tzoev/3GCJx1fF/MnjbC1O+hgN9w8Wga8MGWg5ZiaKbP5DCmZWsjEKuyKrvTlEIwEHG/vD79LNPj+qJvlwoa+RyR1+2bZxX91Q1tRupl0O/HsS79HPD7ceGwUkyfdHxcfX2CEMxpDuw075Czgj7D6iTHoOhs2R+Lo1ChZ+6VHRXp6+a2DhxsaMUbn0UsL7prQe9nn89nuTf0/z9wxanKx+1qgkQ+gznWR+Rgg/koiN7ZQUvROpGA34fTjynC898fh6Gl6oBjEXFDpbuyAWDiif1M10XGdOwMIpUQBOyDZIGIJfXxa083jpL42ye78PKnu4T0dnsLiqktfj+mDis1P2YIQXUhPiB2n4nB8zrbD0WCgUXBM+YYq7AXGTXwKDx05alYfPukuKyCqYICJQWIE68YgyL6nlUTd1YnXDxi1HhXIq6dUjRDwuSlOl1YJBCtojnpxP4WNwWQuEABgOP752Nk9Hwinb55WabXDwlpxvGgihXQUVlQNlXV46VoMKd4ErFqEdQnezErSHdnqFxCRpuE779IWjj317Xgqkc/wPzPIy6GgM+HMYP6mCrgyiTa17/9xgi8//PzcNGIMnxzTIVhqRLTu0MBP3JCfsNKeM3jH1oOGRSx29kDESEhB+R+vqcWK7YfMnZ1cn0OET3rTR4bejyA08SaJcWgiBxsaDFiCPx+H4IBPy471T5eyuW2tfCzC0/ERSPK8Ph3x2B6NB32nVsnWMZdSHBbrtp5GKt2Hra8li5c3ayvZVL82/ubDgBQL5yWAPvoDnrY0YWmNOkTorvweBZOlaXqUL1ZoAT8Pkw77Wjb10p0POdlBXDOkGKMGFCIiSf2R//8bJxUVoD/OstsfQkF/DELSovVlaYTcyHa9/XRfcz9/Fn0OwsrrOSqOKlgwIdvjq4wYlyA2FiNZzwDQHG+ua/1+EM9g8rv95nmJhUBf8QVr6rknU4oUFLAKWWxL1+88W+aeByO65eHn08digW3TMBFUtCTa5CsQqCIOAU0He9ier567EAMLs4zFlIR8aYSd38q9EkkNyuA16afhYW3TTS5jzojUFT4fD4MFvzKTsWTVDildKt29mIqrFiATmVBEc+Pee76sXjyutON/hfbKJu9xX4uUhz8tnxLrA0Bf0QITp90vO3ElWhf+/0+o46NyIklYj/7TBkIbrgtnKVSkOiew024fI5gkXMwb4um59umnICckB8v3jDOsGLIO0lTu/z2C+fVj32IO16OxMPo9++DV56qrGECAIF4fatRdAvm5JNLUJATwt0XnYzj+vW23FtiDMqfF2/Gv9dWql4OgLMQBKzHCqzZVYMvK2vx2NKIe9jJeiueZfXV4ZHd/WkDj8LEqAszHqtgscJStf1QI16NuoKASF/P+topGDlAvXg6WT1V+Hw+PPO9M/D69LPQOzuIJbdPwqs3jbe4qrKEfn5rTSWu+MsHqpezfCYVquMbdh9uMg7iFO9J1YYqFK1wfM24QcYm4GtRcaw6l0zVJtkqqJe013Vn0O/DeUNLcP5Qs/tWJFnzdFehQEkBIyrUAqV/QQ7euXUibpxwHAb27YU/Xj3KJAjcCrWpsitENuyrM35/+Udn4vRj+uDVm8bjoStPxQvfH+v4t8W9s7HwtomYPW04/vbDM03PiYuMu7k79hmO7dcbg4vzTALFKZA3UY4T2hIMRFweg6Sgw7HRE6FlnPo6JxSwTAZy0JuOKhhT7K+zhxRjkjARiEGyd0wdijGDYqZW0ap29FHW4EkRsZ9nTxuO8cf1NaWPy9d0BXHh1BeyeKtMugV+y1YDOWDPybwtupZuPm8I1s66wBR4LaaJi5amUMBnZBOpXDwieh/6fD7b6qSJLpx2DC1TCRTr5w4FfLj9QrPlzMmVBgDlUj/vrW3Gr4TDHeVzsUTENPVJJ/bHSz8Yh2evH2sIQZUlQG5XQW7Q0k/zP99nJAgAkbmhICeE+y4foXytzoxn8VyknFCkOnVpQY7JhRoK+EyWArdzxBwtKAqBsnJHNZ5dHnEPi0cl2MWvARHL3sPfGoUHrhhpuI3itqBIovtQQysmP7AYSzZEKnAHosd0PHHd6bavR4HSjRkn+JLdvujBxbGFyG2ScTtv4sfnDzF+Hz2oCH+/cTxOG9gHl512NPor0hntGCHtYMRF5hgXgaJqohgcnKzJHDAHvoX8kcC1RbdNxL9mnG08/p0zB+E74wZZhJVbO2TLyCGb80HEvrlv2nA8/t0xjt+5uFM9vn9vk4tDnGRGVribYHUuGVmOF24YZ9mBJ6uvTxSEjz5G5WDQPr1CSiud285eTr3fIVkBY9ao2Pfh80V2n1dJ1j7ZCiAuNKL1UVxgBtuIDuP9BUF9zdhBuOr0CvzXWcco29hV5O8vS5HNBQBPf+8M/GjCcaYduJsQlHf2mgbTQXpOsTPnCQLb5/Nh7LF9TYulaBX87TfM4kL//iOpuM5zkD5eBxfnobQgB/0li3Eyra9izZSQkMUjYmexUNVg0VEJlEXC0RxipVqVsBM/40UjyjBt1AClEDy5rACnDTwq1qaAvQUFgFERWn4P2w1cnPGMqSZz0S/dmOP69cYfvnUacoJ+16C5wcWxSd3NgiJy+jF9cOXpA7Fs8wFMn3Q8soN+DOjjvOuOl5xQAL2yAkZ+vDjxTxs1AHMWbUb/gmys3W2NtFd93sknleD5D3fYPt9ZThNiD8QgPzFmoqQgB/972TCs2F6Ny+dEMnt0N4UTTu4BEXF3ecWYirgOLfvN5SOwt6YZp1UchcJccwCqzqlSXIWMarKWJ85kTejiZK7vAO+55BS8v/kA5izaHH0vP165aTy2H2jE95/52IiNchPdsgVFrgIcUgTJ/vLSU/CtMwa6BpUP6tsL2w82YuzgIpP1URRNsmVBRiwvX5gb2d3P/3wfnnx/m/G4W/B7vOSEAhjQJzdWQyaottoc1683fD4fBhT1MrJd3ISgHiQrIlqr7A7I/Mt3RltS5mUOC0Jw8kklpufEdp1Ymu94/IV+7+SEAlhw6wRomoZTfzlfmd7fVU4uK8CyaKXoUMCvjEW64ZxjcVSvEJ75YLtpgXeyoMiiCgAWb9ivuNJsfZ1wQj8MLc13nJfEe2DcsX1N5waJ/ezmzhf78d5pw7F8y0EsXr8f8z6PpdDTgtLNuXRkuSlLxo5Rggq2OwlTxZCSfHxj9AA8cMWpOK5f76SJEx2x+JK4yBTmhvD+z8+zuIFyQwGLi0HnnktOMX5XpbR1ltOEFFOxgmNhbggnlRWgX342hpVHLBEVQvCaD+43n5j+Kc8Zw46OLdhiQGG8J6pecXoFfjJ5CHw+n8mCIk58qrNxRA4qLDo5kqhK1iRTLGRg6KL07CHFuOPCocbjBTlBFOSEMHxAoSnA1zUGxUUg6IuTuEvPCvpdxQkAPPqdMbj2zEH44zWjTP0pjmc3oaqfJCwipr4DiW0s3BCDF0MBP745ugJ/++GZpp25vgiKY9qtn1U7e5GtBxqUj19wSikKFZWFRfQaKX3zstAnL8sk7sW+Vh1VYUfv7CDyc0LGUQRAchdNce7ICvhxfP/euGnicaaYqOP798Z3zzzGOOUcUJ8MLuL3+ywbBf2wRxlxc/PYd8fgzq+e5Nhm8XWnjTraPKaF54bbxPAYbRTG/HH9euOasYMs1hwKFALAnH6326HAmc7r08/Cd88cZBQIShV9hCBNuQS/fu6HbmI+vn9vfHT3+XjlpvHK1xJvHnEn0lVE19GgIvNO8/XpZ2HxzyYa14iLbDxnXIguntlfH46ywhxcNLwML3x/LF64YZzxnJP/PR7sdvYA8O6tE/AXofCUyCDFZC9H5idrZy8i993/u/hkZAf9mD1tuPGY6AN33dkLAkW2ppw3tD+O6Rv5XsUF2G0x1jmxNB+/+NowFPfOthWCAPC9aFaHahetOrb+qFzzdcmczEXLWdAfiZU5Y3ARvnVGrBicLqpES6GbpcpNCKqKgMXL2MFFmPuDcXj7p5GDU+3clm4B9irE+yuZbgcxzbalPQyfz4fbLxyKt35yjvG4Hs8mxrW5jWcgvmJ9gPm8tHhe1+fz4ZWbxuOZ752BYUcXmurpiN//KeXOKdjVimMxZIuxR/QJBYoXeP77Y1FWmIN7Lj3F9dqRFUfhl18bZlLPqUC0oKgmBp/Ph/m3TMA3Rw/AbVNOQH5OyDGF1ikCvSssum0ifvfNkbjgFKtpWWyP3+9TVsK1Y8wxMd/sVWcMxAd3no8/XjMK448vNgXUfXP0AEw6sR9++TX3706FuDuV08yP7dcbF5xSiu+fHVlAQwEfXp9+Fv787VE4+3jrgXhXnF5hejxei0483P/NkQAiNVJEvnf2YKz9xQWmBU6um+KEKEru/+ZI9M3LQv/8bPxrxtn463WnKz9DZxY6UQjK8Ro/nzoUz39/rKmeyoWnlOLEknz86ZrRltc6pbwAlwjHNCRTCE4QanSI1p3vn3Msrht/DF4UxHEiFhS9ICMQOVFa74PcUAD3TRuOHwlWAt1i8N8XOe/oxXaOO7avsQkozFWLwWmjjsbZxxfjx+cdb9owABGXi4pbvxLbiLmdjp4IYjyMeG5NUV4WvnJyCU4/po9Ro0bcDMRjfRVP75Yz9fT7CIgEDifKqIF9jAKQdkIwXzjZWZ4XASit7bK1P5mu+K7AGBQPcNbxxfjgzvMz3QwTJ5bkY+nGA8gK+C1R4TqlhTn4rXDDOfHiDePww2dXWLIPusoxxXmugbs63x43EH9cuDmua2dOHgJN0/BVlzLxOaEAnvyvM+J6TRX9hRLZNmf64bSBfbDkZ5NQ09SG4QMKLXU/RK48vQLvRWtcJJNpo47GGYOLlK4CeXEcNbAPXl8VKQSW5XIAprhQnHJ0Id674zxkBf1Kq8Rr08/C7uom18quKkQhuE0KxM0K+nFWVNi9etN4vPjRDtw65UTboE6/34f7pg3HP6PFzva7FAVMhKGlBfjTNaMsu/CcUACzpA2MWCY/ETdTWWEOfjr5BCzesB8/OX+IyRIDAHdceCKuOr3CkhEXL+LCKbolckIBPBfNJrx89AD8+MWVuPTUo3H5qKNtLQhXnF6B21+OFKNU1YHpCg9/6zT8e+1efF2qvfLYd8eY/i8GWMdzeJ4YW3LvtOH42d8/w0UjyvGry4ZZDnRcvuUgzj/JKiLiwcn6+s4tE7CvtgVH98nFiu2L0dIexos3jMOOQ40YrzhiZMIJ/XDFmAH42ye7OtWWVEGBQpT8fOpQnHNCP/TNy0qKtWbY0YV4X3HCbDqZcd4QVNa04FQh7seOXllB3H2Rfcn+ZDFpaD8jMNKpMqzqzBYVFw4rxXlD+7ua9BNFDj524tvjBmHF9mqs2V2DE10qfubnhDB72nC0hztcLVynVhzlGjxsR3YwcoKyW5zXaQP7mOIT7MjLDuKyU8vx77WVSmtWV3ATxTpnCMGrqlgZmUtGluOfn+3BD849DhNO6GeyAon4fL64Rb+KY/v1Nmr22AmPQX3z8PrNZyufk/nhucfiL0u24NozB3W6TSouGVlu2wciPl/kYM543dPnDe2PLyvr0CsrgAtOKcWUk0uUFomcUAB/+c4YxSvER5mwWWiSDvzr2zvbCB+Y99Nz0RbuQElBjqO4/9YZAz0nUHxaV8qPZoja2loUFhaipqYGBQXuJY8J8TLNbWF8tvMwRg/qE1fw55GCpmmeMRUDkbooP31pFS4deTSuHmstSJgomqahsTWcUIHAZDP9+U/x5pq9+H8Xn4zvnT3Y8dr2cAf21jTHLTQ7S1VdMyb9dhH8Ph8+vPt8R9dvPIQ7NCzbfABjBhXZnmeWapZvOYirHl2OM4/tixd/MM7x2ua2MJ5etg3nn1TimlHTFdrCHRhy978BAL++fDiuPL3rY3r+5/twVK+QcTRHKkhk/aZAIYSQI5Rwh4aPth7CqEFHmeJMMk1NYxtawx2u1a+PJDbvr0+aRTlZVNU14+11+/CNUQMyJt4ShQKFEEIIIZ4jkfW7+9iTCSGEENJtoEAhhBBCiOfIqED505/+hMGDByMnJwejR4/G0qVLM9kcQgghhHiEjAmUl156CTNnzsTdd9+NlStX4pxzzsHUqVOxY8eOTDWJEEIIIR4hY0GyY8eOxahRozBnzhzjsZNOOgmXXXYZZs+e7fi3DJIlhBBCjjw8HyTb2tqKFStWYMqUKabHp0yZgmXLllmub2lpQW1tremHEEIIId2XjAiUAwcOIBwOo6TEXOK3pKQElZWVlutnz56NwsJC46eiosJyDSGEEEK6DxkNkpWrTNpVnrzzzjtRU1Nj/OzcuTNdTSSEEEJIBshIjebi4mIEAgGLtaSqqspiVQGA7OxsZGd3n4qEhBBCCHEmIxaUrKwsjB49GvPnzzc9Pn/+fIwfPz4TTSKEEEKIh8jYKVe33HILvvOd72DMmDE488wz8eijj2LHjh248cYbM9UkQgghhHiEjAmUK6+8EgcPHsQvf/lL7N27F8OGDcNbb72FQYOSe6Q2IYQQQo48eFggIYQQQtJCIut3xiwoXUHXVKyHQgghhBw56Ot2PLaRI1Kg1NXVAQDroRBCCCFHIHV1dSgsLHS85oh08XR0dGDPnj3Iz89X1k3pCrW1taioqMDOnTvpPlLA/nGG/eMO+8gZ9o8z7B9nvN4/mqahrq4O5eXl8PudE4mPSAuK3+/HgAEDUvoeBQUFnvxyvQL7xxn2jzvsI2fYP86wf5zxcv+4WU50MlpJlhBCCCFEBQUKIYQQQjwHBYpEdnY27rnnHpbWt4H94wz7xx32kTPsH2fYP850p/45IoNkCSGEENK9oQWFEEIIIZ6DAoUQQgghnoMChRBCCCGegwKFEEIIIZ6DAkXgT3/6EwYPHoycnByMHj0aS5cuzXST0sKSJUtwySWXoLy8HD6fD6+99prpeU3TMGvWLJSXlyM3NxcTJ07EunXrTNe0tLRgxowZKC4uRl5eHi699FLs2rUrjZ8idcyePRunn3468vPz0b9/f1x22WVYv3696Zqe3Edz5szBiBEjjMJQZ555Jv79738bz/fkvlExe/Zs+Hw+zJw503isp/fRrFmz4PP5TD+lpaXG8z29fwBg9+7d+Pa3v42+ffuiV69eOPXUU7FixQrj+W7ZRxrRNE3T5s6dq4VCIe2xxx7TPv/8c+0nP/mJlpeXp23fvj3TTUs5b731lnb33XdrL7/8sgZAe/XVV03P33fffVp+fr728ssva2vWrNGuvPJKraysTKutrTWuufHGG7Wjjz5amz9/vvbpp59qkyZN0kaOHKm1t7en+dMknwsuuEB78skntbVr12qrVq3SLrroIm3gwIFafX29cU1P7qM33nhDe/PNN7X169dr69ev1+666y4tFAppa9eu1TStZ/eNzEcffaQdc8wx2ogRI7Sf/OQnxuM9vY/uuece7ZRTTtH27t1r/FRVVRnP9/T+OXTokDZo0CDtuuuu0z788ENt69at2oIFC7RNmzYZ13THPqJAiXLGGWdoN954o+mxoUOHaj//+c8z1KLMIAuUjo4OrbS0VLvvvvuMx5qbm7XCwkLtz3/+s6Zpmnb48GEtFAppc+fONa7ZvXu35vf7tf/85z9pa3u6qKqq0gBoixcv1jSNfaSiT58+2uOPP86+Eairq9OGDBmizZ8/X5swYYIhUNhHEYEycuRI5XPsH0274447tLPPPtv2+e7aR3TxAGhtbcWKFSswZcoU0+NTpkzBsmXLMtQqb7B161ZUVlaa+iY7OxsTJkww+mbFihVoa2szXVNeXo5hw4Z1y/6rqakBABQVFQFgH4mEw2HMnTsXDQ0NOPPMM9k3AtOnT8dFF12EyZMnmx5nH0XYuHEjysvLMXjwYFx11VXYsmULAPYPALzxxhsYM2YMvvnNb6J///447bTT8NhjjxnPd9c+okABcODAAYTDYZSUlJgeLykpQWVlZYZa5Q30z+/UN5WVlcjKykKfPn1sr+kuaJqGW265BWeffTaGDRsGgH0EAGvWrEHv3r2RnZ2NG2+8Ea+++ipOPvlk9k2UuXPn4tNPP8Xs2bMtz7GPgLFjx+KZZ57B22+/jcceewyVlZUYP348Dh48yP4BsGXLFsyZMwdDhgzB22+/jRtvvBE//vGP8cwzzwDovmPoiDzNOFX4fD7T/zVNszzWU+lM33TH/rv55puxevVqvPfee5bnenIfnXjiiVi1ahUOHz6Ml19+Gddeey0WL15sPN+T+2bnzp34yU9+gnnz5iEnJ8f2up7cR1OnTjV+Hz58OM4880wcd9xxePrppzFu3DgAPbt/Ojo6MGbMGNx7770AgNNOOw3r1q3DnDlz8N3vfte4rrv1ES0oAIqLixEIBCwqsqqqyqJIexp6JL1T35SWlqK1tRXV1dW213QHZsyYgTfeeAMLFy7EgAEDjMfZR0BWVhaOP/54jBkzBrNnz8bIkSPx+9//nn2DiGm9qqoKo0ePRjAYRDAYxOLFi/GHP/wBwWDQ+Iw9uY9k8vLyMHz4cGzcuJFjCEBZWRlOPvlk02MnnXQSduzYAaD7zkEUKIhMrqNHj8b8+fNNj8+fPx/jx4/PUKu8weDBg1FaWmrqm9bWVixevNjom9GjRyMUCpmu2bt3L9auXdst+k/TNNx888145ZVX8O6772Lw4MGm59lHVjRNQ0tLC/sGwPnnn481a9Zg1apVxs+YMWNwzTXXYNWqVTj22GN7fB/JtLS04IsvvkBZWRnHEICzzjrLUtpgw4YNGDRoEIBuPAelPy7Xm+hpxk888YT2+eefazNnztTy8vK0bdu2ZbppKaeurk5buXKltnLlSg2A9sADD2grV640Uqzvu+8+rbCwUHvllVe0NWvWaN/61reU6WsDBgzQFixYoH366afaeeed5+n0tUT40Y9+pBUWFmqLFi0ypUE2NjYa1/TkPrrzzju1JUuWaFu3btVWr16t3XXXXZrf79fmzZunaVrP7hs7xCweTWMf3XrrrdqiRYu0LVu2aMuXL9cuvvhiLT8/35h/e3r/fPTRR1owGNR+9atfaRs3btSef/55rVevXtpzzz1nXNMd+4gCReCPf/yjNmjQIC0rK0sbNWqUkUba3Vm4cKEGwPJz7bXXapoWSWG75557tNLSUi07O1s799xztTVr1pheo6mpSbv55pu1oqIiLTc3V7v44ou1HTt2ZODTJB9V3wDQnnzySeOantxH3/ve94z7pl+/ftr5559viBNN69l9Y4csUHp6H+k1O0KhkFZeXq5NmzZNW7dunfF8T+8fTdO0f/7zn9qwYcO07OxsbejQodqjjz5qer479pFP0zQtM7YbQgghhBA1jEEhhBBCiOegQCGEEEKI56BAIYQQQojnoEAhhBBCiOegQCGEEEKI56BAIYQQQojnoEAhhBBCiOegQCGEEEKI56BAIYQQQojnoEAhhBBCiOegQCGEEEKI56BAIYQQQojn+P+nhG5vxx4HeQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14fecf743d10>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5bElEQVR4nO3deZwU5bU//k/1Oguzssww7CgIAoKCGxpBRYxxidckxiXRLPeXGKORmMQlJjck3xswJjEmeqPR63WJ8ZrkusQsKrhhCC4IoizKIjvMMAyz9Sy91++P6ufp6urq6q16uof5vF8vXsosPTXFTNWp85xzHkVVVRVEREREJcRR7AMgIiIiMmKAQkRERCWHAQoRERGVHAYoREREVHIYoBAREVHJYYBCREREJYcBChEREZUcBihERERUclzFPoBcRKNRHDx4EFVVVVAUpdiHQ0RERBlQVRU+nw9NTU1wOKxzJIMyQDl48CDGjRtX7MMgIiKiHOzbtw9jx461/JhBGaBUVVUB0L7B6urqIh8NERERZaK7uxvjxo2T93ErgzJAEcs61dXVDFCIiIgGmUzKM1gkS0RERCWHAQoRERGVHAYoREREVHIYoBAREVHJYYBCREREJYcBChEREZUcBihERERUchigEBERUclhgEJEREQlhwEKERERlRwGKERERFRyGKAQERFRyRmUmwUWSqvPjwde3wmPy4HbLphW7MMhIiIasphB0fH5w/iff+3Ck2/vKfahEBERDWlZByhvvPEGLr74YjQ1NUFRFDz33HPyfaFQCLfeeitmzZqFyspKNDU14ZprrsHBgwcTXiMQCODGG2/EiBEjUFlZiUsuuQT79+/P+5vJl8epnY5QRC3ykRAREQ1tWQcovb29mD17Nu67776k9/X19WH9+vX44Q9/iPXr1+OZZ57Btm3bcMkllyR83JIlS/Dss8/iqaeewurVq9HT04OLLroIkUgk9+/EBh6XdjqCkWhRj4OIiGioy7oG5YILLsAFF1xg+r6amhqsXLky4W333nsvTjnlFOzduxfjx49HV1cXHn74Yfz+97/HokWLAABPPPEExo0bh5dffhnnn39+Dt+GPdyxDEokqiISVeF0KEU7FiIioqGs4DUoXV1dUBQFtbW1AIB169YhFAph8eLF8mOampowc+ZMrFmzxvQ1AoEAuru7E/4UgsigAECIWRQiIqKiKWiA4vf7cdttt+Gqq65CdXU1AKClpQUejwd1dXUJH9vQ0ICWlhbT11m+fDlqamrkn3HjxhXkeN3OeMaEyzxERETFU7AAJRQK4YorrkA0GsVvf/vbtB+vqioUxXxJ5fbbb0dXV5f8s2/fPrsPF0C8SBYAQmEGKERERMVSkAAlFArh8ssvx65du7By5UqZPQGAxsZGBINBdHR0JHxOa2srGhoaTF/P6/Wiuro64U8hKIoisyjMoBARERWP7QGKCE62b9+Ol19+GcOHD094/9y5c+F2uxOKaZubm7Fp0ybMnz/f7sPJmiiUDYXZakxERFQsWXfx9PT0YMeOHfLvu3btwoYNG1BfX4+mpiZ89rOfxfr16/G3v/0NkUhE1pXU19fD4/GgpqYGX/3qV/Gd73wHw4cPR319Pb773e9i1qxZsqunmDwuB/qCEQSL3PJMREQ0lGUdoLz77rs4++yz5d9vvvlmAMC1116LpUuX4vnnnwcAzJkzJ+HzXnvtNSxcuBAA8Ktf/QoulwuXX345+vv7ce655+LRRx+F0+nM8duwj8igBJlBISIiKpqsA5SFCxdCVVPfvK3eJ5SVleHee+/Fvffem+2XL7j4NFnWoBARERUL9+Ix4DRZIiKi4mOAYiC6eNhmTEREVDwMUAxEBiXADAoREVHRMEAxiLcZM0AhIiIqFgYoBqJIljUoRERExcMAxUAs8bCLh4iIqHgYoBjIDAqXeIiIiIqGAYqBHNQW4aA2IiKiYmGAYuB2sUiWiIio2BigGLBIloiIqPgYoBh4XBzURkREVGwMUAyYQSEiIio+BigGbgYoRERERccAxUBuFsglHiIioqJhgGIgR90zg0JERFQ0DFAM5CTZMOegEBERFQsDFAMWyRIRERUfAxQDt1NrM2YNChERUfEwQDEYVuYGAPQEwkU+EiIioqGLAYpBdZkLANDVHyrykRAREQ1dDFAMqsu1DEq3nwEKERFRsTBAMagRAUo/l3iIiIiKhQGKgcyg9Iegqmw1JiIiKgYGKAYigxKMRBFgJw8REVFRMEAxqPQ44dA6jdHNQlkiIqKiYIBioCiKXOZhJw8REVFxMEAxUcNOHiIioqJigGKiuoydPERERMXEAMVEDZd4iIiIiooBiolhXm2arI9LPEREREXBAMVEuccJAPCH2GZMRERUDAxQTJS5RYASKfKREBERDU0MUEyUxwKUfgYoRERERcEAxUSZWzstDFCIiIiKgwGKiXIu8RARERUVAxQTLJIlIiIqLgYoJryiBiXIDAoREVExMEAxwSJZIiKi4mKAYoIBChERUXExQDFR7tFOS4ABChERUVEwQDFR5mIGhYiIqJgYoJgo8zBAISIiKiYGKCZkDUqQbcZERETFwADFhNiLhzUoRERExcEAxYTIoPgCYWxt8RX5aIiIiIYeBigmRIACAOff80YRj4SIiGhoYoBiwutOPC3RqFqkIyEiIhqaGKCY8LoST0t7X7BIR0JERDQ0MUAxoShKwt9buvxFOhIiIqKhiQFKCo9/5RT5/80MUIiIiAZU1gHKG2+8gYsvvhhNTU1QFAXPPfdcwvtVVcXSpUvR1NSE8vJyLFy4EJs3b074mEAggBtvvBEjRoxAZWUlLrnkEuzfvz+vb8RuZ00difNnNAAAmrv6i3w0REREQ0vWAUpvby9mz56N++67z/T9d911F+6++27cd999WLt2LRobG3HeeefB54u36y5ZsgTPPvssnnrqKaxevRo9PT246KKLEImU1tyR0TXlAJhBISIiGmiubD/hggsuwAUXXGD6PlVVcc899+COO+7AZZddBgB47LHH0NDQgCeffBJf//rX0dXVhYcffhi///3vsWjRIgDAE088gXHjxuHll1/G+eefn8e3Y6+RVV4AwJGeQJGPhIiIaGixtQZl165daGlpweLFi+XbvF4vFixYgDVr1gAA1q1bh1AolPAxTU1NmDlzpvyYUiG6efwhjrwnIiIaSFlnUKy0tLQAABoaGhLe3tDQgD179siP8Xg8qKurS/oY8flGgUAAgUA8i9Hd3W3nYadUHts00M+R90RERAOqIF08xjZdVVWT3mZk9THLly9HTU2N/DNu3DjbjtVKmSsWoISZQSEiIhpItgYojY2NAJCUCWltbZVZlcbGRgSDQXR0dKT8GKPbb78dXV1d8s++ffvsPOyUxKaB/iAzKERERAPJ1gBl0qRJaGxsxMqVK+XbgsEgVq1ahfnz5wMA5s6dC7fbnfAxzc3N2LRpk/wYI6/Xi+rq6oQ/A6HcE6tBCTNAISIiGkhZ16D09PRgx44d8u+7du3Chg0bUF9fj/Hjx2PJkiVYtmwZpkyZgilTpmDZsmWoqKjAVVddBQCoqanBV7/6VXznO9/B8OHDUV9fj+9+97uYNWuW7OopFXKJhzUoREREAyrrAOXdd9/F2WefLf9+8803AwCuvfZaPProo7jlllvQ39+P66+/Hh0dHTj11FOxYsUKVFVVyc/51a9+BZfLhcsvvxz9/f0499xz8eijj8LpdCZ9vWLyiiUedvEQERENKEVV1UG3VW93dzdqamrQ1dVV0OWezQe7cOFvVmNklRdr7yit7A4REdFgk839m3vxWCh3c4mHiIioGBigWBBdPAEu8RAREQ0oBigWRIASjEQRiQ66lTAiIqJBiwGKBbHEA3CZh4iIaCAxQLEg9uIBGKAQERENJAYoFhwOBR6xYSDH3RMREQ0YBihplMUClH6OuyciIhowDFDS4I7GREREA48BShqy1Zj78RAREQ0YBihpiP14HvnX7uIeCBER0RDCACWNrYd8AIC/fdCMv3/QXOSjISIiGhoYoKRx/owG+f+/eWV7EY+EiIho6GCAksaPL5mJuz57AgAtm9Lq8xf5iIiIiI5+DFDSaKwpw+XzxmFGk7br4psfHynyERERER39GKBk6OSJ9QCATQe6inwkRERERz8GKBkaXVMGAGjrCRb5SIiIiI5+DFAyNGKYFwDQ1hMo8pEQEREd/RigZGj4MA8AZlCIiIgGAgOUDDGDQkRENHAYoGRoZJUWoLT3BhGNqkU+GiIioqMbA5QM1VdqSzyRqIrO/lCRj4aIiOjoxgAlQ26nA7UVbgBc5iEiIio0BihZGF4pCmUZoBARERUSA5QsxAtl2clDRERUSAxQsiAClCPMoBARERUUA5QsjBjGJR4iIqKBwAAlC3KJx8clHiIiokJigJKF4WKJp5cZFCIiokJigJIFscRzmEWyREREBcUAJQvDWSRLREQ0IBigZGEk9+MhIiIaEAxQslBXqU2S9Yei8IciRT4aIiKioxcDlCwM87rgdCgAgC7ux0NERFQwDFCyoCgKqstcAIDOPgYoREREhcIAJUs15doyDzMoREREhcMAJUsMUIiIiAqPAUqWaiq0WSgMUIiIiAqHAUqWmEEhIiIqPAYoWaop14pk/9/ftmBHa0+Rj4aIiOjoxAAlSyKDAgB3vfhREY+EiIjo6MUAJUtel1P+fyAcLeKREBERHb0YoGSpJxCW/19f6SnikRARER29GKBk6apTxsv/7+zjrsZERESFwAAlSxNHVOJ3X5wLAOhkJw8REVFBMEDJQa1oNea4eyIiooJggJKD2tiwtg4u8RARERUEA5Qc1FXEh7VFo2qRj4aIiOjowwAlBzWxACWqAj5/OM1HExERUbYYoOTA63KiwqPNQ+ns5zIPERGR3Rig5Ih78hARERUOA5QclccyKH3BSJGPhIiI6Ohje4ASDofxgx/8AJMmTUJ5eTkmT56Mn/zkJ4hG42PhVVXF0qVL0dTUhPLycixcuBCbN2+2+1AKSizx9IcYoBAREdnN9gDlZz/7GR544AHcd999+PDDD3HXXXfh5z//Oe699175MXfddRfuvvtu3HfffVi7di0aGxtx3nnnwefz2X04BVPujgUozKAQERHZzvYA5c0338SnP/1pXHjhhZg4cSI++9nPYvHixXj33XcBaNmTe+65B3fccQcuu+wyzJw5E4899hj6+vrw5JNP2n04BVPucQHgEg8REVEh2B6gnHnmmXjllVewbds2AMD777+P1atX41Of+hQAYNeuXWhpacHixYvl53i9XixYsABr1qwxfc1AIIDu7u6EP8VW7tZOHZd4iIiI7Oey+wVvvfVWdHV1Ydq0aXA6nYhEIvjpT3+KK6+8EgDQ0tICAGhoaEj4vIaGBuzZs8f0NZcvX44f//jHdh9qXipiGZT+IOegEBER2c32DMof//hHPPHEE3jyySexfv16PPbYY/jFL36Bxx57LOHjFEVJ+LuqqklvE26//XZ0dXXJP/v27bP7sLMmunj6g9E0H0lERETZsj2D8r3vfQ+33XYbrrjiCgDArFmzsGfPHixfvhzXXnstGhsbAWiZlNGjR8vPa21tTcqqCF6vF16v1+5DzYsoku0LMYNCRERkN9szKH19fXA4El/W6XTKNuNJkyahsbERK1eulO8PBoNYtWoV5s+fb/fhFIxoM/azSJaIiMh2tmdQLr74Yvz0pz/F+PHjMWPGDLz33nu4++678ZWvfAWAtrSzZMkSLFu2DFOmTMGUKVOwbNkyVFRU4KqrrrL7cAqmzM1BbURERIVie4By77334oc//CGuv/56tLa2oqmpCV//+tfxH//xH/JjbrnlFvT39+P6669HR0cHTj31VKxYsQJVVVV2H07BcFAbERFR4SiqqqrFPohsdXd3o6amBl1dXaiuri7KMfxx7V7c+vRGnDttFB7+0slFOQYiIqLBJJv7N/fiyRGXeIiIiAqHAUqO5BwULvEQERHZjgFKjrgXDxERUeEwQMlROYtkiYiICoYBSo7KWYNCRERUMAxQclRT4QYAdPUHEY0OukYoIiKiksYAJUejqrxwKEAooqKtJ1DswyEiIjqqMEDJkdvpQGN1GQDgQGd/kY+GiIjo6MIAJQ9NteUAgIOd/iIfCRER0dGFAUoe4gEKMyhERER2YoCSBxGgcImHiIjIXgxQ8tBY7QUAHPaxSJaIiMhODFDyIPbjCYQ5C4WIiMhODFDy4HFppy8Qjhb5SIiIiI4uDFDyIAKUIAMUIiIiWzFAyYPHyQwKERFRITBAyQMzKERERIXBACUPMkCJMEAhIiKyEwOUPHiZQSEiIioIBih58Di1NmMGKERERPZigJIHLvEQEREVBgOUPHCJh4iIqDAYoOSBXTxERESFwQAlD/olHlVVi3w0RERERw8GKHkQAQrAOhQiIiI7MUDJg5gkC3CZh4iIyE4MUPKgD1A47p6IiMg+DFDy4HAocDsVAMygEBER2YkBSp5EFoUBChERkX0YoOSJw9qIiIjsxwAlT5yFQkREZD8GKHkSAQqLZImIiOzDACVPXhc3DCQiIrIbA5Q8ySJZ1qAQERHZhgFKnliDQkREZD8GKHligEJERGQ/Bih58so240iRj4SIiOjowQAlT6IGJRBiBoWIiMguDFDyVObWunj8IWZQiIiI7MIAJU/lHi1A6WcGhYiIyDYMUPJUEQtQfvbiR7jv1e1FPhoiIqKjAwOUPJXHlngA4BcrtkFV1SIeDRER0dGBAUqexBKPsL+jv0hHQkREdPRggJKnCkOA8mFzd5GOhIiI6OjBACVP5R5Xwt8/avEV6UiIiIiOHgxQ8qSvQQGAnYd7inQkRERERw8GKHkyLvEc7PIX6UiIiIiOHgxQ8mQskm3uYpEsERFRvhig5Mm4xNPS5Uc0ylZjIiKifDBAyZNxiScUUdHWGyjS0RARER0dGKDkyRigAEBzJ+tQiIiI8lGQAOXAgQP4whe+gOHDh6OiogJz5szBunXr5PtVVcXSpUvR1NSE8vJyLFy4EJs3by7EoRRcmdskQGEdChERUV5sD1A6OjpwxhlnwO1244UXXsCWLVvwy1/+ErW1tfJj7rrrLtx999247777sHbtWjQ2NuK8886Dzzf4ZohU6OagOB0KAKCtJ1iswyEiIjoquNJ/SHZ+9rOfYdy4cXjkkUfk2yZOnCj/X1VV3HPPPbjjjjtw2WWXAQAee+wxNDQ04Mknn8TXv/51uw+poPRLPKOqvGju8qO9lwEKERFRPmzPoDz//POYN28ePve5z2HUqFE48cQT8dBDD8n379q1Cy0tLVi8eLF8m9frxYIFC7BmzRrT1wwEAuju7k74Uyq8rvgpHFXlBQAGKERERHmyPUDZuXMn7r//fkyZMgUvvfQSrrvuOnzrW9/C448/DgBoaWkBADQ0NCR8XkNDg3yf0fLly1FTUyP/jBs3zu7DzpmiKPL/TxhbCwA4wgCFiIgoL7Yv8USjUcybNw/Lli0DAJx44onYvHkz7r//flxzzTXy4/Q3dkBb+jG+Tbj99ttx8803y793d3eXVJDy9DdOR1tPEH3BMH7/1h60s82YiIgoL7ZnUEaPHo3jjz8+4W3Tp0/H3r17AQCNjY0AkJQtaW1tTcqqCF6vF9XV1Ql/SsncCfU4f0Yj6iu1JZ4jLJIlIiLKi+0ByhlnnIGtW7cmvG3btm2YMGECAGDSpElobGzEypUr5fuDwSBWrVqF+fPn2304A2p4pQcAa1CIiIjyZfsSz7e//W3Mnz8fy5Ytw+WXX4533nkHDz74IB588EEA2tLOkiVLsGzZMkyZMgVTpkzBsmXLUFFRgauuusruwxlQ9bEApaMvaLlkRURERNZsD1BOPvlkPPvss7j99tvxk5/8BJMmTcI999yDq6++Wn7MLbfcgv7+flx//fXo6OjAqaeeihUrVqCqqsruwxlQIkAJRVR0+8OoKXcX+YiIiIgGJ0VV1UG3s113dzdqamrQ1dVVcvUox/3gBQTCUay+9WyMraso9uEQERGVjGzu39yLx2ZVZVrWpLs/XOQjISIiGrwYoNisukxbNfP5Q0U+EiIiosGLAYrNqmJ1J91+ZlCIiIhyxQDFZsygEBER5Y8Bis2qYzUoPmZQiIiIcsYAxWZVsQxKdz8zKERERLligGKz6lgNii8w8BmUnkAY0eig6xonIiJKwgDFZlXe4tSgvLe3A6ctewVff2LdgH5dIiKiQrB9kuxQJzIoAzkHJRiO4vO/ewvBSBQrtxxCOBKFy8nYk4iIBi/exWwma1AGMIPyx7V7EYxE5d93H+kbsK9NRERUCAxQbCa6eAZyDsqf3t2f8PetLb4B+9pERESFwADFZnWxDQPbewPwhyIIhqNpPiN3qqriP/+2BRsPdAEAFk0fBQDY2tJdsK9JREQ0EBig2GzEMC1AOdDRjzN/9houuW91wb7WzrZe/PfqXQCA2WNrcNrk4QCAj9t6C/Y1iYiIBgKLZG02YpgXABBVgbaeANp6AgiEI/C6nLZ/rZYuv/z/7yw+Dv5QBACw5wgDFCIiGtyYQbFZhceJMnfiae0NRArytdp6AgCA0ybX46ypIzFxRCUAYM+RPqgq56EQEdHgxQDFZoqiyCyK0FugoW1tPUEA8azN+PoKANqY/c4+TrIlIqLBiwFKASQFKMFCBSiBhK9X5naioVr7/91c5iEiokGMAUoBiEJZoWBLPD4tQBlZFQ+IxtZpWZRmXX0KERHRYMMApQAChtbiwi3xaAHK8Mp4QFThccaOoTBBERER0UBggFIAn5s3Dm6nIv/eV7AlnsQaFADwurR/0kCocPNXiIiICo0BSgFcMrsJm3/8SZw1dSQAoKdASzztvVqAMly3pCTamY1ZHCIiosGEAUqBeFwODPNqwUKhlnhE8a3Y/weIZ1DETBQiIqLBiAFKAVV4tMChUF08/UEtCNEPgfO6mUEhIqLBjwFKAQ3zxgKUAmRQolFVBiHlHl2AImpQWCRLRESDGAOUAqqUSzz2Bwv6DEmZW59BYZEsERENfgxQCkgu8RQgg9KvqzEpc8X/GVkkS0RERwMGKAUklnj6gvZnUEQRrNupwOXUByhc4iEiosGPAUoBiaFpPQXMoOiXd/R/93OJh4iIBjEGKAUkilcL0fIrXrPcEKAwg0JEREcDBigF5HGKYMH+bIY/RQYlHqAwg0JERIMXA5QCEjNJggUJUGItxsYARcxB4RIPERENYgxQCqiQyy1iSFuZO/GfkEs8RER0NGCAUkCeWLAQjBQggxJmkSwRER29GKAUUCF3Fo5nUFgkS0RERx8GKAVUyIJVfzhFDQqLZImI6CjAAKWAxFTXghTJxjIo+n149F+TAQoREQ1mDFAKyFPIItlQiiJZuRcPl3iIiGjwYoBSQGK5JaoC4TSFspGoihc3taC125/Ra6eagyL+zgwKERENZgxQCkgstwDpA4Zn3zuA655Yh88+8GZGr51q1L2+BkVV1WwOd8C98uEhnHXXa3j1o0PFPhQiIioxDFAKyKPbZThdgPLipmYAwN72voxeO+Wgtiy+ZjEd6vbjq4+9i73tffif1buLfThERFRiGKAUkNOhwOVQAKQvlNVnQjLZu8efqgZFn7Up4VkoD6z6WP5/JFramR4iIhp4DFAKLNNCWX0As6utN+3rptos0ONyyKCov4QLZf9v3X75/x19wSIeCRERlSIGKAUmllzSZVAO6Ypjdx5OH6CI4MNrCFCAeNBiR4BypCeAs+56DT/6y6a8X0vwhyLw+cPy74d9Adtem4iIjg4MUArMk+HgtOaueICypz33DAoAlMVmo4hps/l45aNW7G3vw18/aM77tQR9cAIAR3qDCBVgOwAiIhq8GKAUWHxwWupgIRiO4nBPPIvQ1RdK+7r9KYpk9W+zI4OybncHAKC9N2hLwAMAPr/2/VV6nHI56kgPl3mIiCjOVewDONplMnr+ULcf+o7grv70AUogRZsxEA9QMim2NROKRPH9ZzZiZ1sv1u3pkG9v7urH5JHDcnpNPZFBqSl3I6oCLd1+tPr8aKwpy/u1iYjo6MAMSoFlssSz50hia3FnRhkUMeo++Z9QLPH05ZjxeH3rYfx53f6E4AQADnZmNkQune5YBqW63I1R1V4AiUtcREREDFAKLJMiWePsk0wyKGK5Rd9WLFTkucTz/PsHTd9+sKs/p9czEhmUqjIXjh2lZWQ+bO625bWJiOjowAClwDLKoMSKYieNqAQAdGYQoMgiWY/JEk/sbf4cMyjv7Dpi+vaDnfYEKN2x76+6zI0TxtQAADbu77LltYmI6OjAAKXAZJGsRTZjXyyDMit2s+7OKEDRAh6rGpRcMyi9Ae3zRMA0cXgFgMRW6HzoMyizxtYCAD440FXyo/mJiGjgFDxAWb58ORRFwZIlS+TbVFXF0qVL0dTUhPLycixcuBCbN28u9KEUhcigBC3aaPcaApTONIPLIlFVvp5pm3EeAYqqqvLzHvziXDz576fiy2dMApDZ0lMmRA1KVZkbx4+uBqDNQsmk9oZyF4mqsoOKiKjUFTRAWbt2LR588EGccMIJCW+/6667cPfdd+O+++7D2rVr0djYiPPOOw8+n6+Qh1MUsovHYuy8aLGd2lgFAOgNRizngui7c0zbjGOFs7kUyQYjUTl6vqGmDPOPHYHaCjcA+wIUkUGpLneh3ONEXez1D/lYKNvtD+Gpd/ba1tItdPYF8en/Wo1TfvqKbZkwIqJCKliA0tPTg6uvvhoPPfQQ6urq5NtVVcU999yDO+64A5dddhlmzpyJxx57DH19fXjyyScLdThFk64GRVVVtPdqAcqE+gr5dqtgQB+g6DcHFCo8rqSPy5Q/GD9OEfxUl2sBhF0ZDrGEVVWmvW5DtdZe3MJOHvz8xa247ZmNePzN3ba+7g//shmbDnSjPxRhvQ8RDQoFC1C++c1v4sILL8SiRYsS3r5r1y60tLRg8eLF8m1erxcLFizAmjVrTF8rEAigu7s74c9gIQKIVBmR/lBEBi8jqryoKtOCC6sARY65dzngiA0605NLPDk8hfeFtOyG26nA7dSOvabc3gxKpwxQtO9VzD9p7ebI+1XbDgMAth6yL5v4YXM3/qrrzGpmBoWIBoGCDGp76qmnsH79eqxduzbpfS0tLQCAhoaGhLc3NDRgz549pq+3fPly/PjHP7b/QAeAx2kdoHTEshIepwOVHidqyt3w+cOW2QqrAlkgvyJZEdToX7tWBCg2ZFBUVcWmA9oT/LGxoW8NVbEMyhC9cfYHI/j7xmYMr/TIeqT9HfZ0TAHJLdwtNrWLExEVku0Byr59+3DTTTdhxYoVKCtLPRlUURKf/FVVTXqbcPvtt+Pmm2+Wf+/u7sa4cePsOeACE1mIVHNQOmLLO3WVbiiKgtoKN/Z39Ft28ljtw6O9XfuauQQoom6lQte+LDIovkAY4UgULmfuibfmLj9afQE4HQpOiHXwNNQM7QDltmc+wF82JM6e2W+YjZMPY+aLQ/GIaDCwfYln3bp1aG1txdy5c+FyueByubBq1Sr85je/gcvlkpkTkUkRWltbk7IqgtfrRXV1dcKfwSJdF4+oP6mr8ACIBwOd/ak7efrlmHvzf77yPDYLNAt+xDEBQLdho79svbe3EwAwfXSVPM6G2DTZ1iEYoGw/5EsKTgAtWEu3A3amRDauMna+WetTeL2BMH798na8trW12IdCNGjZHqCce+652LhxIzZs2CD/zJs3D1dffTU2bNiAyZMno7GxEStXrpSfEwwGsWrVKsyfP9/uwym6tBmUWEtxfaUWoNSWa/+1Wk7xW+zDo397TjUoQTEALp5cczkdGOZNXxuTCbGEMbWhSr5tXJ1WHPzB/i6EB8muxpsOdOGHz23CgTyH16X6/Kiq7X1kB/FvNi3W0s0AJe77z27ElQ++ZVswCGjLuRfduxq/enkbfvDsJttel2iosX2Jp6qqCjNnzkx4W2VlJYYPHy7fvmTJEixbtgxTpkzBlClTsGzZMlRUVOCqq66y+3CKzpOmSFZmUGIBiuyYsSqSNakT0RNdPDnVoMgMSmLsWlPuRk8gHJvRUpn16wriZikCMQA4bfJw1Fd60OoL4J/b23D2tFE5v/5AeOKtPfjBc9qNx+cP4Z4rTsz5tUSwOa2xCs1dfrgcCrwuBw52+dHc5ceE4bmfa0HM1ZnWWIV1ezpwsKsf0ahqWmA9lLR2+/Hk23sBaHU6s8fV2vK6j7+5B7vatOnQBzr7EQxH5XWAiDJXlN+aW265BUuWLMH111+PefPm4cCBA1ixYgWqqqrSf/Ig40mbQdFu2PWxJZ5MZo74w6JINsUSTx67GffLGpTE2NWuTh7x+fplI4/LgU/NagQArN7RltfrF9q7u9tlcAIAf/2gWQaZuRAZq5FVXvz9W2fi+RvPlF1NdrV1i3M+c0wNPC4H/KFo0v5PQ4XPH8JvXtmO//zbFvztg2b59n0d9p2Pfxl+hjl3hig3BeniMXr99dcT/q4oCpYuXYqlS5cOxJcvKrdTe0oNRczHuB/p0Vpr6+QST/qOmWA4TRePJ/8iWeMeP2KJR4zBz1W3DFASf/SOiy35GHd2LiX/t24/vvvn9wEAJ42vhc8fxvbWHqzd3Y7zZzTm9Jr9upqfsbGlrtpYsNplUYeUDZGNq6/04LiGKmw80IWPWroxcUT+2ZnB5t5Xd+DBN3Ymvd3OrqkOwyToA539GKebcTRU9Qcj+NHzm3DOtAZ8cmZuvy9mIlEV//XaDvxjYzP+89KZmDex3rbXpuJi3rHAPGIvnhQZlLZYgDKySisUzSRTIQIUd4puGhG46CfJ/v6tPfjOn96XU2JT6U/RIeSKBVrhaH5r9TKDUuFOeLtYytgb2zixFL2uK3j8wmkTMGustjXB1pbcZ5b0mwSEds+dEcFubbkb02LTij9sPvqmNmciVSH2fhszKF260QEAcMDG4Gcw+8uGA/jTu/vxyxVbbX3d373xMe5euQ0ftfhS7sROgxMDlAKLZ1DMb+yHfbEAZZgWoIglHqsaFPFanhQBilzi0QUoP3xuE55evx+vfmTdVdAf1Lp0KjzGAEXU0uS3oZ/Yh0e/xAMAE2IbEu450odomiCqWHa09gAAFkwdiUvnjJE3ezsCFLO2bruXeGoq3LJQNp9jHsxSbf9QiAzK8U3aubZrF/DB7p/btaWvfR19tm0MGopEce8rO+Tfea6PLgxQCixdkexhQwalOoOnZ/FaIvgxkm3GsWxIIBy/KPcErG96/Sk6hDwig5Jnl434vqrLEgOUptpyOB0KAuEoWn2lN1E2FIli52Etu/Ofl86Ew6HguEbtBvRRS+6TjftMzncmQWqmVFWVr1Nb7sH42FLDwSE6rE38fM+JFcSKpct9NtXkRKOq/BkXAYqdwc9gs2JzC778yDu449mNeHGzNlrCH4qircee5cuOvmDCUvaBTtb7COv2dOBrj787qGugBqQGZSizKpJVVVVmUEbFAhTR3WL19CxmqqTqDKhwa/+s4aiKUCSaMEI+nCYDYjaoDQBcjliglWd2w6xIFtCWq8bUlmNvex/2tvfJQtFSsedIL4KRKCo8ToypLQcAHDOyMva+3G9uZhkUOyf37m3vk8t6tRVuNA7xfY/Ez/fXz5oMp0NBbYUHl//uTRzJo9BZz+cPQ/yKzJtQhyff3ottrUMzWwUAtzz9gem1bH9Hn3woy4fxtQ/YuFQ32P3shY/wzu52zBpTgxvPnVLsw8kJMygFZpVB6QmE5dj6EbElnhrZxRNMmQYNhbW3p6xB8cTf3h+KJGQkjAV8Rqmm1LpsyKBEo6quSNad9H4xsE3U5ZQS0fUyaUSlbM8Vmx2Go2rOczRkDYp+MJ6Nu0f/IdZG+4kpI1DmdsrA73BPwHLH7KOVDMC9Liye0YiJI7SMUld/yJalRfH7VelxYuYYrUZpW4vPtiWNwSQaVVM+aO2zKaskOuhE4N3tD8Pnt2dpdDA61O3Hv3a0oaXLj3f3tAMY3Bk8ZlAKTAQRZkWyIs1Z5XXJZRnx9ByKqOgPRZLafQEgGIkkvLaRx+mAQ9GGffUHIzjsiz8tt/da//KKSbHDyhK/rvha6TIwVnqC8afLapMAZXilFqAcKcEA5VAsCyUuhEBi1qMvGIbH5Un6vHRkUbLu31lm0Wzo4lnzsbbu//mTta0hhld64HYqCEW07F1TLBs0VBhrrESgrKpa9sNYvJ0tuZxW4cGkEZVwOxX0BiPY3zH0Onn84dQdf3YtqYmtQsbWlaM/FEFXfwgHO/04rjG/f8fBaEerD5/6zeqkh6X9nYM3q8QMSoFZZVBER8EIXaqzwuOEK/aEnurpQxSqplriURQlvmFgMCJvrgDQ3mt985dFu4b0qzimVCP7MyG7G1wO0xbp4cO0G7Nd69N2Euu4o3QBitvpkHVAqYov0+mzyKDYUSTbEQtIRQuzw6FgVGxzxqG4J4/xfHtdThms2JGxEhmU2go33E4HjoltiLnNxt2pBwv9SIKnvnYavnrmJHz1zEkA4teZfIk5UrUVHoyr14Lt3UdKtxOwkLa29JhmcgdzBoUBSoHJUfcmN/Z/fXwEQLyWAYDcMBBIfcGMtxmnngSqL5RtzSKDYuwqkt+HK/8MSnyKrPnTzfDY1zySJogqBhHkiWUoQWS4cg1QxJKaWRePHTUoYoqs/pyLZZ7BXDyXK7GkVunVZ6zS73+VqQ7D3lqiOy3fLREGI/3y5WmTh+OHFx0vf3860yw1Zyq+VYgbU0ZpXXXbh2AwCGhZXDMHO/tLtjMyHQYoBeYVGZRw4g+Iqqp47r0DAICLZzclvK86TZtpvM3YfFAbYAhQbMiguB35z0Ex7jtkNCKWQTnSE0Qkqqad2TKQRLaroTqxeLcij40ZAfOuqco8tirQC4aj6I0dl7hhApBFvqJteqhQVVV2TekDwnS/b9m8/jPrtd9pUdsilgSHZLYqpN0wK736DjWxfGlPnYg+IJzSILJVQ+vnWhAPSadMqkd1mQvj6svhcmjLuaXYGZkJBigFliqDsn5vJ/a296HC48R5xyfu4lybptVYthm7LDIoulko+otBh8VFuC8YRk9Au6iMMtyI7ZiDYty52UjUoLywqQUn/mQFTl32sm1r1fk65BMBSmLgJgLBVE8v6Zh1TcWH4ql5FVeKjICiAFW6mqLTjxkOAENup91AOCqDXv1gPLvaug909mP1jja4HAq+ftYxAIAGka0aigGKyRBCcW2zug5lo70vvpeZmEY9FJfTgPj5HldXgZU3L8Bz158hu0NbBmm2lAFKgckaFMPaoMiefHJGo8W+N+ZpULHEk2pQGxAPUPqCkYRAp80ikm7zBeXnViYNasu/i0c87aTKoIgaFEAr1m3rCeKO50pjN9iWLtEObp5ByXeJR38R1xc/5xMQiiWimnJ3wsaAZx+nbca4YV9nXvsIDTb6LFeFfu6M3EE8v3MhnlIbqstkQezoWIAyWG8Q+eiL1aCIsQdAfEuPfM+1cKRHPPS45Q7pOw/3DtoljXyIAvBKrxMN1WUYPswrM1bpujdLFQOUAhN1IsYMyps7tfqTC2aNTvqc+F4s1kWyqbp4gPiSQX8oIlt7AcAXCKd82j/co11ER1Z5oSiJ2Rl3bA5KOI9f/HZZ0GZegzJiWHLg8sa2w9i4vyvnr2kHVVXl0phx6UtcfHMvktX+LfRFsvraonyW1ERGwJixaqwpw7j6cqjq4FnmiUbVvIcEiuUdj9MhM4KALoOS51N9p8kSZsMQnjsjfrYrdEs8dRX2ZVDW7WnHP7cfBgBMHjkMjTVlcCjatbatBOvYCq3XJGNVVyl+thmgkAmRQQlGojJd7w9FsPOwdmOYFZuVoJdu1HlQTpK1yKDoalCMgY6+JkUvVf2J/mvl08VjdgHXM7a8ih2On3xnT85f0w59wYhsj64ytF+Li2+uSzxme/GIoXhAfhkUkbEymzkj6lBKeTT4H9fuxb8/thbL//Ehzr17Feb8ZCX+Z/WunF9PPGEaN8KssWmJR3RM6QNwORiv2z/kZqH0mxaAa7/73f5Q3jVmr37UiqgKnD+jAfMm1MHtdMhr19AMCGMF4PqRBSKDkqY5olQxQCkwsQyjqpC/kNsP9SCqak8TxpoGIP1mcaE0k2QBXQ2KLkARSZFU3Ru+2AwU400YsGeJJ10NSoXHhdlj4wHbZ04aCwBYu7sj569ph95YXY5DSR5gV2HYViAbqqqa1qDoMyj5DFOLz+QwC1BKu7skElVx+zMb8fKHrfjdGzuxq60XPYEwfrFia843tlRTksW2C935Bih9yT/fomOqLxgZUstpgL6lW3/DjM+dyfd8i47E40fXyIxvY40WeA/FomSzfdTqKphBIQv6LIfIPnzYrO3dMn10ddJSChD/oUp1QUu3Fw8Qf0r0+cPyQjE11oZ3KEUdipyvYpKZccsAJY8n+jQZFAC476qTcMqkevz6ijlyv5QdrT227eybC19ArO26kv69yvNY4unqD8klM/05URRFzp3J53x3mtwwhTF12oW8VGckbDnYLbNWY+vK8f99Qpuf0ReM5LzRoVnRJqDrtMtzCcns57vC45KbSr6+9XBerz/Y9AaSu3jcTofc/yjfugj5810ZD8CbaobukprZEk+9rEFhBoVM6LMcotV4T7s2SEgMcTISQ7X2pdhXIpsiWX225NhR2tdLteV8vDso+XXt2ItHPPHUWQQo4+or8Kevn45PzxmD4cO8cvjSeXevkgWldvjTu/tw/q/ewJ4Mhjr1iMySNzmzJItkA9kv8YjZKnUVbnhdiTdNtzP/m2anrkjWaGxsiadUMyhvxWq0FkwdiX/ecjbuuPB4nHGs1n20fm9uGTWzfY+A+BDCfPeZ6khRY7V4hrZU+VJss7zBoCcQxtYWX17FpqnOt11dU2YZWZGxGoqbYfZbLfEwg0JmXLruiUBsRL24UQ83KQoF4jMU9rSZb0sezKBIVsx22NWm3YCrvC7ZUZBq0mJ8vopJBkUOasv9hilG2NdlMU78vOnaxb3VF8Cja3bn/LWNbvm/D7D1kA8//uuWtB8rngSN4/8BfQ1K9sHToRSzVYD4klrBlnhiGZRS3Vxt80GtMPqUSfUya3XiuLqE92VLtNAbu+Zczvx/toHUGaszjx0BANjSnPuu1wMlElXxzPr9OG3ZKzj/njfwxNu513/1hZKXeID4HlYi8M+VWcZq9JDOoCTXWMWLZJlBIROKoujG3WuBRbp227F1FVAUbWnBbJlHtCybZToEUXD6YbOWDq8ud8uniyfe2ms6KyBosXQkBrXlesPsCYRlG+b4LPYk+eFF0/Gt2E6cT8Y2vrOTKFa2ol/iMZJdPDlkd8T5MM6cAXR7H+XxBGu1xCN+FlIVTBeb2Exu4vD4lGXR5dXdn9uNTdy0jAGhWwaD+WVQxO+qMSAUWcCWLn9JDR/U6/aHsPhXq3DM9/+Bm//0vgzmXvso91k58am9xuxg/kMfAfOM1fh67efl/X2dQ68o2WxndGZQKB2RkRBLM+1pajHK3E401Yh9JZKfcDOpQREpfLEzcHW5G5fMaZIXS7ObvdUuyfkOavs41s46QtebnwlFUfDl+RMBaDsK9+SwlGKk36/Cl8FTnHjSG2axxJPLJFm5v49p15SSdKzZ6rRo6xa7Z/sCYVuXzuwido8WP6+AfluB3H4GxHLWGEO3mB3LaUD8fBt/r0dVlcHlUBCOqgnbTpSS17ceTpjAevzoagDAB/u7cr7Ri8yjseZH7usVzj2AUFXV9EFP27Xbgd1H+rDxQHHHE2RKVVVsbfHlvdwaLwLXzZ0Rk3uZQaFUjBsGyl8sixu12MPjY5MnfPE6XosMikjhC7XlboyqKsN/XDQDALByy6GkC0/Ion0536ee7bEAZcoo87obK3WVHnkTz7VAUk+f/u3oC6a9QYvUqVl3Uz6TZOPj85MDFJcNc2c6LGpQqstcMnBuK7Hdo/2hiGx5H1cXz7aV5zkULx6gmE9JzqcgGTDv4gEAp0ORGasDJVqUvHZXu/z/P193Op65fj5cDgVHeoM53zjltgJu8/qqfDIoPYGw/N3Qn+9KrwvnTNMGEf5ze1vOr19owXAU7+5ux182HMD8O1/F+fe8gbN/8Tqa86id6TPp4hmW5xiEYmOAMgDEjUDcCDt045lTmRmbj/KeSUFgJoPajE+JV506HoC2Hl7hceJAZ39STYdV+7Isks3xIr69VQssxH4Z2Tou1glhR4CyX1d3EVUT/25GZFkqPckBisiq6HduzVR8A0KzJZ7827q7LJZ4FEWRNVAtXf6SyqKIf49hXldC9ieflm4gPvPFGLznu3wJxJ7oLTJWY0q8KPmdWIDywBdOwskT61Hmdsoi/o8P57Y7cHuPWPJK/Plz2xAQirke5W5n0s7ox8a6FUu1Qw0Afvv6Dnz2gTdx01MbZEt0MByV/w65MJuDIh908gy+i4UBygCo1U1PjEbjFzKrdttTJtYDgOkPbCCcOtMh6OslTp88XG5IWO5x4pbzjwMA/PylrbJwFUhTg5LnDfPjPDIoAGSrph1pW+OFK92FrMeiSFZkVXz+eAo1ElVx94qtcsplKlaZGVsG41kUyQLxZZ7PPvAmTl32Sl71BlaiURVffXQtvvHEuoyWC/a1a/8eY+vKE9q67cqgGAcCyiWePLJVfcGIXI6zausuxQAlFIliRyxTOzvW2g/Efy5z6VADgP2dWqA51hAQ2lEAbrVMPnYQDCF8+cND8v8bq8vk72iuU7OjUVUG7uUm+3rlcx0pJgYoA0BMN2zzBRImKKa6cQDAvIlax8LHh3vlkpBgtRSjt2i6luq89YJpCW+/dv5EzBpTg75gBL97Y2dGr5tv0aZY4jkmxwBl/jFaJ8RrH7XmXfy2y9DFlC5AEWvpZm3GoiNBX8vy3HsH8JtXd+CLD79j+brxdvHkXanzXXYIhCPyRi72mjHSby3Q1R/CdU+sK0j3w4HOfrzyUSte2NSS0Q36sM88syR3ec4hQOkPRuQ6vDFAsWWfqdgN0+NyJLXVApA1Zc2dpVeDIop3PS4HGnR7TeUTEIYjUfm9jq1LLIp351nPBsTPt9k1tKnEAxSfP4QtB7WOrke/fDLe+v65uONT0wEAH+T4AOYLhCEui/paOY8NxfbFxABlAAyPRflHegOy0r/K60qafaFXW+GRNxDjRmNW7cB691xxIlbferYceCYoioKbz5sKAHjwjZ245n/egaqqaYpkcy/a9IcisuhxSiz9mq3TjxmOcrcTLd1+bD6YX7vm9lgHk3g4T3fTFEWyZl084imzWxegZLqbqlWxsyfPmh+xUaBDMc/QAPEMihAIR/GTv23O6etZ0QeAoqvMSqqBfhV51Pv06j7HGGjaOXOmrsJtOnxxVKzOqNTqfQDIHcPH1pUnbCopAsJcOtQO+QIIR1W4nUpSEbgdXTxWnZD6bFUpdvJs2NeJqKoVgC+Mbdx5fJNWlJzr3lji33DEMI8hg6L9bEei6qDcQJEBygAQN4K2nmB8nboy/SyQVC1imYy6B7RI2vj0Iiw8biTmTtCyNG9sO4yOvpBl4JNP0ebHh3ugqtrTjtmGgJkocztx+jHaoK581mmBeDZn4dSRANIXLvoslnjE04p+iSegC+KsajtkLZFZzY/s/MrtotKRYidjvRG6G8fkkZVwOhT8Y2ML1u3J7/wa6Wt8tmQQXHbIm33iz4q48Pbm8ESvDwaTNsK0oybCot4HAEbGrgGtFruJ2+VAZz+u/Z938PrWzJbsRABpvFbEO9SyDwj3x26YY2rLk37+8q1nA/Qtxsnne7Rue4FiTqBORcymmtZYLd8mCtlz7VLcE+v2NI5wcOm3zcizrbsYGKAMgOHD4k9P3bEbmdj/w0qt2JNH1yKmqqquSDZ1m3E6iqLgf649Wf69NxAuWA2KKLI7duQw06fLTIlM0Pv7O3N+DX02Rzy9pMug+E02PRPEv2MgHJXZpW5dsHLY4oZkHRDm95QZn8mROiA8VjfJ+OITmnBhbGft5f/4yNYL+z5dAJjJkLUOOSE08XdEtE8Gw9Gs54lkkh3M5wKeagaKIJZ5tx3y4WuPv4sHVn2c92C4VJb940Os2nYYX3pkbUYfLyZWjzPUisiAMIcC8FRBD2BPxireCZl8vsvcTvkgVIo1P3tNgol8fraB+HRy/dwgIL4LPTA4C2UZoAwA0S1xpCdouSGfUa3JPgr6YierQW2ZqNFlNHqDYctR9/msG4t22tGGtf9siQK+D3IsJAO0pxdV1Z5YxOuly6CIAKXMZElOn1URWRT92rdVSt9qV2qPK7+nen3aPpVPz2nC2cdpWaQFx43EWbGM0rt7OvBvv/1XTrUeZvQZlFRTjPVSdbnpA0T9Mk+rz4/H39ydEBgaieDDtL5KPNHnMZcj1QwUQQQoPn8YK7Ycwp0vfIT//PuHOX89K3t1s5MyWeJIm0HJYYmny6JA244OtfY0nZCjYrU0A5GxypZ4QBKjJIDUP9uZ2tMWC3qGG+t94g+EDFDI1EhdBkXcxKoyyKDUye6f+BKPPkBIV4OSCRG59wbClu3LrjzWjY/EnnaGW3QtZeKEWOu12Nk2FyJ4GFtXLls/D/n8lrU1YsnG604+L06HgkrdxoxA4lNbW0/qCY5WNShymFWOF3FRCGx8okr4Gk4HHr72ZLz7g0U4aXydHMkOADsP9+KJt3Ifc663vz1+Pg50pK8LSLVc4nU5IFYL9MHT//fYu/iPv2zGMosbvtW5drtsqInos85YjTQZxvfomt14cVNzzl8zFf33mMmuvmJgYGNN4jGW5zEYz3JkgQ2Te62mJAPxmp/DAzApuaXLj9cyXE4D9EMI48GE1+WQNXG5PBiILNgEQ4Di1C2vDcZOHgYoA0BkULQAJXVHiJF4+tCn20O6G2m6Lp5MiMLPnkDEei+ePNbpxTyEXOtPhLpKj6z5OJRiw8N0xAV7dE0ZRgzzwOtyQFWt9+4IhMRgPPOiZn0nj6qqCa9lucRjseyQb13E7tg696QRqQMUAHA4FFkj1VhThnuvPBEnjNUCQbFhX752tsUL/3p13TSpyBoUQ52Woii6abLxi/j7sYza3z9IfbO3XOKxoyYixbKUUOFxJXRXiIDlB89ttn38vf7n78MM9v8Ry1PGounKfLp4olY7o+e/xCM3CkyVsYp9L4+u2Y3LfvsvvLvb3roqvSsefBNffmQt/rLhQNqPVVVVZjf1SzyKosiBdrmcb9FpaCwdUBTFtq0FioEBygAQ6ca2nqAMNrJa4tG1GYso2OlQEqLjXMlJg4GwzCKYX8Rzf6I/0qvdpOsrk58isyWejHIPULSn+dE12owNkUURMxvM+MPaBSPV5F79LJTeYCThRme1xGP1lJnvRXxXhgGK0cWzm/CTT88EAKzb25F3F0R7b1BmkcQNOl1dgNXTsVXra5lJjZBgtZzmtmEuh/ieGk2G7gn6LMpD18xDldeFtp4AfvfGx7Z1WPhDETTrfjfMJlEbiX+fVF1TuTzRi2uJy7SezY59puJdU2bEdWJLczfW7+3EZx94E5sKNPpebEfyzPr0AUp3f1gWeRuHaVZ4k4PvTFltIGtHEXixMEAZACOGeeBQtFYv8WSbyRKPfsCbIC4W5e7UF+NsiCfSnkDYOg2ewQ95KBLFCxubky6K4gKYavfmbIg5DbluciczKLFx5/FdfVPfNEUGxTixUtC3GhuLS61eV9w0XSaBZj7DrCJRVVb1T8wyQAG0fVi8Lgc6+0I5tz0K4vPH1pXj2NgMHKvJvfqJrGb1HMZWY30dQ5nJEpyQ7892OjtjheCTR6ae8/PpObFhiW4npjVW4ZRJ2jDGu17cirte2prz19bbc6QP+pjyYJq5K9rgSPMMiljiMXZN3ffqdnznT+9bBlVWM5VcNkzulRmUNF1Tel///Trb27z13XuZLDu3xR7WqspcSdeTeM1P7ktqdj9cFhsDlAHgcjrk05Nocc0kgyJ++br64xkUUbCW6maZrfiodl0Xj8UTvVWa8IsPv41v/GE9ljy1IeHtIoOS7xIPEN+3JtdN18TwKNGKmMkI8kDaDIpY4gnJp3/BquOoUIPxdrX1oD8UQbnbmdXO0YLH5ZA3zxVbDqX5aGtyi4NRw2TBrtVgPF8gLJc8zPYQKjekwfU1Fg6LDrFwBvVVuXbxhCJRWVcweWTqgPCmc6fg0S+fjMe/egrK3E6cO71Bvu+BVR/bMljMuKSTbghhV398cKTxZm/WZhyKRPGLFdvw9Pr9Gf1sF2KJJxiOyro2Y1AlGHcIH1NbjgOd/fjNK9tz+pqp7NEVJO9u602bcWzziWth8nGLn+1cuqbi2djCBODFwgBlgDTGJknukAFKbhkUvxxnbM8/ndgKvTcYkev0pm2vusI2s1/C/mAEb+3U1nmN4+hFDcpwG5Z4xHTRO1/4CEueei/r9LN+iQfQBShWGZRwuhoULcjr6g/Fl/Bigd+2Qz65PmwkLhjmSzyx853DYDxx/mc0Vee8DHjRCVrL8d8s6joysSuWWThm5DCZrbK6aYqfb4diHhBWGtLg+3TZmPaMCpJTd/GoKnKqB9nX3odwVEW525kwidVIURQsPG4UTo5tY3H5vLH41edny5/BNR/nX/OzJRagiF2g0wU94uGhptyd9HNYYbKcpn89qxupVcF9vIsntxvmniO9iERVDPO6TDfaBBKX06Y2DMP/u1TbJPXxN/fg5TyDbj2xlApozQBHelP/DALxbLLZw5rZ+QaAIz2BtD+XVgG4Xbt1FwMDlAHSaPhFyqgGpVxslW2SQbGYQpuNSq++iyf9RRwwv4jr0/b65af+YESmiOttyaBoN4CoCjy34SD+vjHzG6iqqvKJW4weT3fTVFU13macYglB1Bgd9gXkzJqpjVUYXVOGqGpevBmNqjI7Ylm4mcMNc+N+7SYlNpzMxaLY0/2Hzd0JaexsyfNdWy7bWC2zVbqCZLOZOeIiLtLp+qU+XyCccjCe1YyfhGFWecz5mTSiMuVQPDMupwP/duJYuU/W2zYUJYtBeOLfL129j9Xya4XJ1gL6jMHhntRZTMslhzxH3YuHvGNGVqacqzRZt7Q5Z1yt3CoDAP798Xfx4qaWnL620U7DRorpAkKxxGSWQZHnW7fE81FLN+b+58v43p/ft3zd+HKx1cMlAxRKwVg8l9EST6yLobMvJLMWfpMNofJR6TFZ4kl7EU++sOifZPtDEVkbIOYVuJ1KRp1L6Yht64VsLjQdfSGZDWmItVSmW+IJR1WIGCFVBkUsFzV3+WUGpabcjc+cNBYA8B/Pb0reT0m3nGBdF5H9RUUsq4jx2bkYPswrv6+P8thBOp6xKpObuFllUMRyWqpgULSqi/NprPlJ1TWVyXKa/uOyIYICsaFltk6drGVU/rWjLe9iWbHNwrnTtAClqz9kWRtxRDzRm2Q3K+Tk3vjn72mP/55b1YGJ82hVJJvrDTOTfb2GD/Pi9e8uxD2fn4PbLpiOMrcTl8ZqgADglyvsqfnZ0pyYLU43U+mIRYBiVgD+29c+BgA88551AW5GSzwcdU+piCUeIbM5KNrFOBxV5UWmP2hdsJktszZjs4u4Pt1uNhfBeNMRx9slR6578poiKyw8biQumd2Ebyw8BgDwxvbD6A2E0d4bxNLnN+OjltRtleJmqbUXa+dPZFCau/pNbw76sfVmc1CAeNDUogtQasvd+PZ5UzF9dDX8oWhSC6I+yLO7syTVZnvZmj5aC3A+yqBVNZV4UXK5rEE5YFEk60/T0i06wY6kCFCM+1YJmXRMAbktO2yKTcfNNWN1+uThqPK6cLDLj7fz2MbBH4rIwWTTR1ehOvYQZPVUHx+KZ1LvY3LD3KsbtGc1BE38fJvXoOTX9rpd7oxuHRBOHFGJS08cI4utf/652Vjx7bOgKNpr2LExptgXTAQc6TJWhy0zVsldU/oheVb1LSGLDkw7utSKhQHKAGmqzT6DUuZ2ysBAtNXJLbVtK5KNd0WELGoiXE6HLFrsMMyxCEWi+PXLicVnYt5LZ6zAt6Y8/+wJoKVBf3Plibjl/OMwYXgFguEoXt96GLc+/QEeXbMbVz/0dsrPjRfIxoPFxuoyOB0KQhHV9IKrXzJIVSQrMyjd/eiM3TCry91wOhRccfI4AMBD/9yFbn8I6/d2aMtpaebZ5DO5t92mwXgiI7Algw3+zIQjUXlOR9eUyWCw2x9OOfVVFiSnyqDIqcza6xoDlFR7/VjNQXE6FDkkK5eLuGhfzTVAKXM7cWGs5ucfWSxZGolgsMztQH2lB2PEkloGNT9ieUFPv3u0uDnu0w3dswpQLLOxec6dEed72ujsMlZupwNTG6owK/bvtHpHW05fX+jqC8kHs8UztIxVuqLkTJZ49AGhPljRb0hqZDlk04Y5P8XCAGWAjDN0U5i1wZmpM2wYmK4eIlvxDErYMgoH4m2f7Yblil+/vD2pOExkULp1Sx52UhQFn5zRCAB4cXMLVsYK36yK1PTLDYLL6ZDLbwdMZqGIDIrH5UiZARKZikNdARlIiu/3s3PHyg6CE5auwGW/XYP/97ct8kaYap5NrpN7VVWNByh51vxMadBS6HsyGE9vpq0niEhUhSs2DK7C45I/Q6lumrKlO0UGZbjhZ1D8fIkbobFAWxBLamYt3drn51bz09UXkoFBPktqYiPMLXlkqw7oRtbrZ/xYPdWL64lZ8F0de6gIR1VZR6afan3YopNOXkusCsBzCAY7+4KyMHXO2NqsPx8AzpqibemQTzAIQGZrx9aVY3osmE9Xg9Jh8fBgViSrzwimmv2kqqr1Vg42bC1QLAxQBoi+3bO6zJVyAqKR6OQRNz6/zRmUigxrUID4UKT23viTU1d/CP/zr10AtMmTVbqAR7xf+z7yL5A1On+mFqC8+mFmVfn6KbJ6Yjy02cyPgMUFXBABSjASxf++sxdA/N+t0uvCfVedmLAnztu72tOea3nDzHJ/mO7+sFxrTrUvTKZEpinXVPjBWEDYEMtSAUjbauxPk0ER31ObYYlHjOnfsK/TNBVudcMEALcjt4u4KBStLkucFJstsbPtthZfzsPxRIAtApMxtSLwTt+hZrZkrJ9+K5YN9RkrqzH6GbXQ5/BEL/bhmjC8IuNrqNFlJ40BALy+tTWvZR7RWj5pRCWaMggGgfjPt1kNobGtOxpVE/ZVShWgRKKqnH1jXj/IDAqloY+YK7O4kNUa9uORg9psKpLVB0BWswuA+Pp/e2/8IrVmRxv6ghFMGlGJTT8+Xw4G6xFLPH2FyaAA2hNUQ7U3aZBUKtsOaQFIk2GC46zYaPf3TTYhTFcTAWjZlSZD0KMfkHbi+Dq89t2FuHyeVjRb6XVapmS1t+c2m0MOgvK6LI85EyKz1Nzlz+mmKS7++sLmeFu3eR1KvIvHeolHBMnihrlg6ki4nQp2tPbgD2/vTfo8q5oIQH8RzzJA8cWKTE322snGpBGVcDkU+AJhHMzxpikyKGIpTfzX6qneKoMCxNt1zQKUPUf65EagRvEONXuHEIoi4JlNuXeoTR45DLPG1CCqAu/uyb3mZ58uYyUHPqYJUKy2zZC7R8euZ139oYThaqmCqULWsxUbA5QBol8eyCb7IZZ4jDUodhXJisDpcE9AdqukXuKJZ1CiURVLn9+Mb/xhPQDgrCkjoCiKfOISNQZdBVriAbR9ZC6YOTrhbW6nYnoz7egNYtU2bUMvsWuvIFLF7+/rTPq8dF0lwid1x3HD2cdiwZTEr+F2OnD5PK0epcdv3dINxNeNrZ4yD/sCSRdEu5Z3gHhg0R+K4OPDPVlvGidujPqMVboMitUTPRCfpSNmnoifr0kjh+HWT04DANz76nY5al38+2WcscryKVMOIcxzxo/H5cAxsSm023LsmtofO98iCGzKasZPigBlWOJgRHG+RQHuvz42r+Ow3jYj9y6ewz12FYBrSzLioSUX++Wmf/GNRzv7QinnHgHWGULROCGWLY31VakyVgk73FsOfWSAQhbEMs9Fs5vSfGRcbYoAxa4lHpEm9ekKsFKlwfUZlJUfHsKja3bL950emzMwrMx8iacQAQoAedMXQhHVdHv4598/iFBExYymatmdIsweVwtAa6c1jmFPdwEXvnj6BJS5HZjWWIWbz5tqOg9Df27iF/AUN0yX9UX8w+ZunLLsZZxx56v42wcH5dtF8Wi+yzuAFiSIZb1Fd7+BKx98K6tMSovJktqYNK3G6Z7oxSyd3mAE/lAkocbpmtMnYmSVF4e6A1j489dwzi9exwlLV+DD5u60AWGuw8PkZNCq/M/3xBHa9cFqKwAr8RqUxCGEVhkU+USf4nqiz6AEw1FZHyGuYY/+a7fpz6jV+fbI3aOzz8q1yYxVfud7aoMWoGw/lHsLvRitMK6uAlVl7oy6pqxqrOLBoHkB+Ht7O0xfM5QQoKTeGZ1LPGTpD/9+Kn7y6Rn45tnHZPw5xiUef5p9YbJVV+GBsfYz1U1Tn0HRd0ucPLEOZ03VAhTRnSSXeAocoBzfVI2LThidsCmesYgXAP5v3X4AWtGqUVNtOU6bXI9IVMU9hm6kdFNkhUkjKvHqdxbij18/PeWwLpFd8mWQQXGn2a9k7e52ue6sLww9IjMo+U/tBRID4ff3d8kagEw0yyWe+JJaumFtaaf2el0ym9Xc5ZedDdVlLnhcDnxjgfa7dbDLj51tvQiEo/hgf6flpE0gvuyQ7X4l8nzbMCVZ1PxY1XZYOWDIoIhlh5Zuf8qfo3QbYeoDFHHDVBTgm2cfi+oyF97f34VnTTbJs1pSy6erxKoLJhtTGkQGJfcAZa9hV+ImufFoBktqJhkUscGhWE7rNAQob+9qN/13jP9sK6aF/JwkSxkZV1+Ba06fmFVtgKgDEFG53UWyToeCWkPw4DaZRgjEl5va+0Kys+PWT07Dn6+bL4tt9UWyPn9ITlEtVIACAPdddRJe++5C+aTe0Zv4i73zcA82HuiCy6HgkhTZq6/HbmwbDMs82XRNNdWWW36fVV7tfQHdk2iqmgiR7jU+RQn6Edv67NeRHntajAWnIVh9Zr0W6L358REsf+FDmQkyI7qm9PU5Y2Mj2Pe295lmY6wu4IC2VDpxuBaMftzaIzN14rx/af5EfG7uWMwcE8+SJQaE1ks8qYpktx3y4Xt/fh//9dqOhLfHR5fnH6Do5+lkKxJV5eeJwGREpRcepwNRNXWBZbqNMBMDFO17rS5zY0xtOa4/+1gAwGNv7k76t7SeJJt7TYQIUDLtgkxlaqxDbfeRvpy6W/yhCA7FBtWJDs2xmWw8apGRHaU716qqyt/9UyfVo77Sg75gBC+YDKaUQ/FSXLe5Fw8VjCi2FCOmRZGs1dby2dIvB4yq8qbMAMTrYYJyi/GJwxPbp8Uyxt72Plx072r59kIGKMbjazds2Cc2vDv9mOEpMwviKeiQ4eaQaQYlE2LfIyCeEUv1RC9uDG0p9pfRjxzXByh21qAAwO0XTMf00dX47uKpALSlsmA4iisfegu/W7VTZqbMNJsUyU4cXgm3U0FXfyhhpoaQyfkWAcoTb++JfawD1bGfL4dDwc8/Nxt/u/ETuOrU8QBiS2ppM1bW0zbvXrENf163Hz9/aWtC27W4YdpxvkWAva+jD6u3t1kGf0aHuv0Ix1q6xdYLDoci5y+lumlmmkE5pMugiN/lz88bhzK3A5sPdmPS7f/AGXe+im8+qdWkWQWEnjTBIKDVDm1t8ckaIuGwxWZ72RhVVQaXQ0Ekqsq6lmyIbFWlJ74Mmm5JTVVVyxorca6DkSg6++L7etVVePCF0yYAAH7y1y1J2zmkq6/iqHsqGBEA7GnvRTSq2l6DAiQGKJedlLwEIogqc38oIi/SE4Yn7t4q9g/6y4aD8ibqdChyzbeQ6iqT26AB4NUPteLYxbG5KWZEpsoXCCeMBg+keaLPhsvpkP9uYh6C22Q0NRDfTMxsdHs4EsXa3fHug25dlqVN1qDYs8TzqVmj8cJNn8B1C47BqCovOvpCcuYMEM+SGPUEwvKpfYyua6rM7ZQDzdbtTe6gSLdzNBAP2l/fehgAcM3pE0wDD5nNy6QoOc0Sz47D8WJK/aBCq9Hl2RI/g2t3d+ALD7+Ne1/NfOddccMcXVuWMFcnXXdJuhqUcbElub1HemUdnFh2rqv0YMmiqQnH8PcPmhEIR+Tyjcs0g2K9xBONqvjUr/+J8+95A9/98wcJb5e7GOdZg+J0KLLQNpcltX2yQLZCLqukPdf6qdQmP99eVzzYafUFEuqrbjj7WIypLUdbTwB/ff9gwudZTUkGMh91n2t7eyExQClxY2rL4XIo8Ie0qZz9Ng9qAxJ/ccTkUzMi6m/1BeRFerwhg2KcTXDLJ4/DW7efm/RxhVAdWxbpMUxc3Nmm3VxOGl+b8nMrvS55Q9On2P3iicemzRlFhkm0aqe6YYq21R6TDfBuePK9hKyJfjO/drkNvb1zZ1xOBy49UZsf8cuV8X1MUqWVV29vQ1TV5lWMNLTgzh1fBwBYsyN5c7xMaqz0WTtFAb52lnlNl6iH8vnD8Z26013ETW6aEcM8Cv35ttqdNlujDdth/HHtPplliEbNdxEXtse6UURAIYhNMVM91YsMSlmK8zJ5pBYM7uvol8GvPhv6tU9Mxi8/Nxs/uHC6fJs+IDSvQbF+om/u9ssNGDcfjNc8dfaH5Eal9tT8aAHKb1/bgTtf+CirpR59i7EwptZ6cm9igGL+8y2yX4e6dft6VWg7TX/xdC2L8r3/+wB/eHsP/vufO9Hc1W85JVl7u/XO6Ac6+/HJe97ArKUrkpa4i40BSolzOR1ybXNXW698orczgxLVXfj08zuMRFCkn21iHE5Vb9jT44KZo5NuUIUii1B1GZBQJCqfutK1JprVANiZQQHiT/XplniqvC55M9VnUd7eeQQvbk5chzarQbGji8dIDLjS7+B6pNc8Pf7qR1qW5Zxpo5IK986ZNgqAtgGasUgxkwzKHF2g+YkpI1P+fA3TT0mOWqfBraZtNnf1J2RWEs+3fRmUUYYdz1t9Afzr4yPoC4Zxzi9fx9d+vy7l576+VcsSnjppeMLbxQ109xHzzqB0GZRRVV5UepyIRFX88C+bY68ZD6QcDgWfmTsW//6JyQk7TcuMlUmGUPxcp3qi362rr9K37OoDpFSBZjbE7/vLH7bigVUfJ/1eWdlnKJAF4tuZpM5WaT/bDiX1z6H4GWjp9std7EVAePWp42X26o5nN+E///4h7lm5Pe3yZbqd0V/a1IKPWnzoCYTxrzzH/9uNAcogIIqw9nf0yeJKOwOUpRfPwOyxNXj2+vmWH2f8mqNMbgx1uomxZW5HUo1KIQ0zdBAB2kVNVbWntvo002xlgKIrKBTLPdkM18vkGEWmI1WRrKIoshBQv0b+x3f3AdDW//96w5kADDdMG7tKjKY1VuN4Q4t2m8n6fW8gjH9s1C72i49PXlabf+wInDV1JCJRFa/Elt+ETDIo0xqr8esr5uATU0bglvOPS/lxw2IZNV8gvs9UukLCgMlT5msfJR6jyKD0ByNyqJYdNShlbifu+fwc/PiSGbg29rT89Lr9eO2jw9h9pA8rtxySGQQ9fygibywi+BNmxMbvp3oyThcQKoqCybH5LMFwFHUVbtxwzhTTj9VnrKznoFhnUFIVgMuWbpuyg8aJ0n94Sxvwt6+9Dzf/aYPlxqPiGMfVx4M1scRzKEXXlL6+KtW2GWKq9a623vjMmViAUlXmxtKLZyQsmR7y+WVQbbZztP7tqTJEu4+Yn+9SwABlEBgrJ0L65ROFXTdMAJg3sR5/ueFMnBhLvadivGkYn/iAxCf30TXltuxgnCnjmH0gviX8iGGpi38FkWFp0dVViF/YTDZ3zMSwpAxK6mMSF+I2XwBvfnwEn//dm3gm1tL56RObdDcE7UIWjaryde0qkjX6t9gyj2BWI/P3jc3oCYQxcXgFTp1Ub/o6M2M3TmMNS6ZzZz49Zwx+/9VTLTfokxkUfyjtqHuRATF+PzsP98jMgSB+JkRw5nU58hpzr3fpiWNw7fyJ+EysHf6lzS0JWzCYZaye33AQvcEIxtaVy4BEOGmC9ju9o7VHPpHrZRIQHjtqmPz/y08el3CD1NO30YvsiPluxtZtr/oApS8YkUGZCNTtysjqr6GKAry58wh2Hu7B9X9Yj2fWH8BXH33X9PMiURXvxHadPmFs/OdvRKUXHpfWNWXWiZXJ0EexQ/PWFh92t2lZGv2S2qUnjsG/bjsHv736JABiOc16SrIni/PtS7GJZ7EwQBkE9OvIYvlimE03zGwkBShVyUsm+hoUUfA1UMwyKGLoUYNJMGXUUJ18kxKvVWVXBiXDJR4gsZPnVyu34e3YRVFRgHkT6mWA0hu7iK/5+Ii8mNcVYO8jQLtBLTxuJM6NPambdRmJTdg+c9LYlEHh6Np40K1n55Jatb4GRdZEmB+PyJ4ZCybvfVVrKx5TWy6DLWOAMmKY1/ZAfNaYGkwZNQyBcBS/0RXLioBb7w+xbqYvnjYh6XzXV3pkHcmrhkwQkFlA+LWzJmN4pQdup4LPzU1doyYyVvolHrOneqt6n71H+vDw6l0Jb+uR59u+lm4AOO/4BjgU4MpTxuOc47Sf5/99Z6+cK5Rqqeb9/Z3o6g+husyF2boNCx2O+AaNe0yW1DLZNkMEg69+1Iqth3yo8DhxysTkIL/K5Gc7XQF4qqLkIZVBWb58OU4++WRUVVVh1KhRuPTSS7F169aEj1FVFUuXLkVTUxPKy8uxcOFCbN68OcUrkn4jKpFBseuGmQ3jEo/Zk4z+uOwaJpepYd54Sl8QnSQjTYIpI3Hh0990fQHtiULMJcmXWENu6dJuNFYBiij67faHZLq5qsyF718wHR6XI+GY/vr+QXzh4bflx9ixRm+mptyNR798Cr4fK4psM2QcfP6QXG64YNbopM8XmmRAkHgTsLMoOWFyb5qLuOig0c8L6Q2E8fdYsHX/F06SGUZxEZczZwqQrVIURWZR9Ms6xgzPvvY+vL+/Cw4F8uONLp2jZb1+/tLWpDR/IIOtM6aPrsar312Ild9ekJBNMRIBYXd/yHKvKXEdCUfVpALw/3h+EwCtfVcQ22bYNaRNmNFUgw+Wno9l/zZTtqT/2aJtXnh+g9ZF84kpI5O6lERGz2zqayDNRpgAks7vzedNTWjTF6p0wWDaNmPZQp+cQTnY2Z/Q7t9jMaa/GGy/iq1atQrf/OY38dZbb2HlypUIh8NYvHgxenvjUdpdd92Fu+++G/fddx/Wrl2LxsZGnHfeefD5cp/qdzQTAcrHh3vkfjl2LvFkyviUZVaDon+SHOgARcwZ0RfWZZNBMW6MBti/xCOyTuJiaxVIiFk3e470otsfhtOh4N0fLML/d9Zk+bni3+TnL8UfAr5yxiRbjtWK2HvGFwgnzKr4qMWHUETFmNpyy5tZqqmpdmZQhmXRZtxoCJiefHsvZvzoJQTDUUwYXoFZY2qSltTsvmEamU09NgYoYsbPKZPqUx7H186aDI/LgeYuf/L5znBJrabcbVlADyRnBwHz811dHp8GrF8K2XywC69vPQynQ8HT18+X34/MWPnsXeIRx6woChYeNwpNNWWyAQAw/93sCYTl7J8rTknOJs2LLamt3ZMcoPgtxtwLo6q8Cd/fZ1KMfRA/i93+UNqfbfF9GHdGj0ZVfO33ictYR/0Sz4svvogvfelLmDFjBmbPno1HHnkEe/fuxbp1WgW6qqq45557cMcdd+Cyyy7DzJkz8dhjj6Gvrw9PPvmk3YdzVBBpQ3FxUZT41twDyeFQEi5k6S4U6S56dqsqS65BOZzFRS2eQUkOUOyqMTDW7UyyuOiLJ83393XJjzWmh8WTlEhHv/KdBfj2eVNRaPolRn1a2Gz2iRnR8dDeG0x4ivbbOBhPPmUG0+991CAzKAG09QTw/Wc3yvctPr4BiqIkLBm9trUVtz2jfYxdU3uNRgzz4kvzJya8TWzaJ4i9ZE6bnNi9o1fmdsoMkb4APBpV5dO3Hb+rVYYCcMC8LkJRlPiydVd8QvYvYkH2oumjMK2xWp5v8fscDwjtP99Oh4KrY8PQhGA4mlS38cqHh2R91ZnHjkh6nXkTtQDl3d3tSTs9Z5JBURQFT3z1VJw0vhbfXjQ1aWyDoK+3sypIBnRFyYYMyoubW7DpQDcqPU78x0XHAxgCSzxGXV3axbW+XltH27VrF1paWrB48WL5MV6vFwsWLMCaNWtMXyMQCKC7uzvhz1DSWJM4fElE/cWgz4qkuumLX9xrDRfXQhNLPD0mbaCZ7E1jlkERF0e7lniMdTuzLIo8RYCypVn7eRfjufWqy+OBwqgqLyanecq1i9OhyDR8T0KAop07swJqvZpyt/z+9E/18SJwOwIU7dyoanxfk1QXcdHRcajbj4+a45ncJYum4Fvnal0rIig73BPADbFdvAFYFurm644Lp+NvN54p9+9qNWRQ4hnCNC30sgBc10Kv61iyI9spfv8SMyjm16kmXQ3SYV8An7znDbwWG7z3yZla59cwXcZq7e52+f5CZayuPGV80jK2sUvtxdio+QtPGG16DZ7eWI1ZY2rQF4zg7pXbEt4nW7rTBIPHNVbhmevPwE2LzLulgPj1SFXjYx9SnesKk99TAPhTrCPwy2dMksXUQypAUVUVN998M84880zMnDkTANDSov0DNzQ0JHxsQ0ODfJ/R8uXLUVNTI/+MG5e6UOto5HE5MEWXLrfraT4X+l/gVLM2/vvaeXjtuwstn+oKwWwOihz9nsFTrghQfLrhaCLladsSj+HGbXVzKzdkycbVJ7ds6y/Wc8bVDmzXlG4dXBBPjelumIqiyGU3/ZOmmJ5ZbUNA6HU55FKCmN2S6mdW/NuHoyreiU3pXTS9AUsWTZXfp9hLad2eDvQGI3A6FDx7/XxcHatfKAS304GZY2riLeeGAOWQPN/WN+2GmuQaG/3SXKEyKM5URdJiSa2zH396d5+c09JUU4ZzpzckvN6aWAeb0JQmO5er+koPfv/VU/C7L87VBayJ51t07yya3pD0+YCWZf5mbI+iTbohc4BuKJ4NwWCZ2yEzI+kK7vU1jIB2X/7dqo/lJOZLdR2B3f4QVFXF3z44iPte3Y5V2w4jmsOu03YpaIByww034IMPPsD//u//Jr3PeCFVVTXlxfX2229HV1eX/LNv376CHG8p07ezFTNA0acnU3WKlLmdlksXhWLcSRnILkAxG47WY3MNiv7G3VRTZrn0ZLxpjDW5MOs3TSvUhTuVYbqLmpDpDROIZ5P0c17Ea9mxd5OiKDJzIExJseWC2xmv53k/NjPEmLEy/gxcOGs0ThxfZzrO3W41FfGCaT2RQTHrqNNrFAPA9FOSQ2KTOcWW70GcH7FZp8fpSHlNl11cXX7ZRr1k0RSsvvUcGZyKgPBPa/chqmqv/+NLZmC6YRaPneZNrMf5MxplfZ0+eA6G40MfjVt86InZKM1JHWr2LacpiiLP9xG5bYb564phfftjE24fXr0Ly1/4CIA2KfjYUVUJS0b3vLwdNzz5Hn6xYhu+9+f3k3a7H0gF+8268cYb8fzzz+O1117D2LHxQp/GRi19Z8yWtLa2JmVVBK/Xi+rq6oQ/Q80sXTtbMVqMBf245NoBbiNORwRu/aGI7FbIZjM3/XC0Vl8AkagqB3HZFRTqA4pT02SYjBkUswBEvx6fblnFbmYBoXjiTJdBAZKX1ALhiLxp2pFBARI3KhxTW2757yhS4aLNdIohQKk1BOSnpJjxUgjiZq1PwYcjUbmEaVawrtdgUoMiMih2dXyJc9uewYwffReXmCZ8/OjqhDZpucQTy9D96OIZA7ZsXBP7t9bvJi4CabdTsRyhIOqvjhjrq0QBuE3bZojMXkeaoY9igFxXfwg+fwhPrdUe8Gc0VePuy+ckvJaqAo+/uRsAMHlEJT41y3wpa6DYHqCoqoobbrgBzzzzDF599VVMmpTYUTBp0iQ0NjZi5cqV8m3BYBCrVq3C/PnWk0yHMv0ApmJmUPpD+rTwwBfqWtF3NvUGIwiGo+iOXdAz3TxPzIz4qKU7YenCrqBQfzO41DD0zMi4Hm4WoOgzMA0ZtFLbST+YSzgUK+JM90QPJAco+tex63zr97c5rtF6w0pxvttTPCUbs10DVe8DxKeJGqcGR1VtdHq6GqtGkyUeuwvARUGnyIhY1W2JDFl3f0h+vDG7ZQxSUw39KwR9QbQgsimjqsosb9qp6qtkx5RN22aIfzeZQUkREA7zumRAtedIn9xK4KFr5mHOuFoAxiWjEFwOBX/71plYeskMW441V7YHKN/85jfxxBNP4Mknn0RVVRVaWlrQ0tKC/n4tvaQoCpYsWYJly5bh2WefxaZNm/ClL30JFRUVuOqqq+w+nKOGvgbFbMDRQBFPuKXI43LIws3mrn65NutQgNoMlwxE0erG/V2y/kRr57UvGHvm+vm476oTsWDqSMuPMwYoY+rMMii6ACWDrIWdTLumMiySBeI3fLFMIepPqspcKWsXsqU/J+kClDJDxsq4pFZb7k64CYwawPNtbHEGEqckpztfZl08Xf32LacByaPjrc63ONc7WnsQCEfhcTkwzvDzrd+xuMrrMq3BKhQRXPlMsoPpOgIVRZFdas26YW9+G5d4tGNMrPmxWqYTyzyrd7QhHFVR6XEm/Hvpl4wArZ6twlO8B2HB9gDl/vvvR1dXFxYuXIjRo0fLP3/84x/lx9xyyy1YsmQJrr/+esybNw8HDhzAihUrUFVlfQEZyvRPIwdTbHE/EPoNg5VKjRim9c6u9oSN89KNuRdErc8H+7vkxana5iW1k8bX4aITmtJ+nP6GOczrMl32SAxQBniJRy47aDc6fygi0/EjMshYGTMo3fJ827d0qD8nnzBpC9XTt+57nI6kbhGHQ0m4aA/k+Y4XMepn/IghhJlMSY4XfYpdkUWAYtdSrXGgmFWtiAi+xfcztq486Qarz8I1mAwrK6Rqk4DwsC/z+ipjYSoA9BRo6KPIQI2wqLMTx/zmx9oO4seOGpaUBdJn4QpZ55MN20Mkqy3BBUVRsHTpUixdutTuLz8kpNo6nYDTJtdj9Y42vPnxEVmom83GeaKrZtshnwxwqm16wsyWfqBTqhoD/VPPQD7RA8k1AvJJzqEktD+nMsoYoBg2R7ODPvM1z2RkuJ4+YzW6tsw0qNVf3wZyqVXc1ILhKALhCLwuZ3xjyAzabkWAEgxH0dEXQn2lx/YMyohKL1wORe7DM3106gdO4xwns7k5+p/5AQ++TZZ4ZAt9BsuXTSaDCPW7wNtBv3wJANOsAsJYYL0pVl91jMkQxYZqrwx2zKbXFgP34hlErontcLpkUeEHcQ1Wpx+jPSWv2nYYW1u04rtsikebaspR7nYiHFVlsWSmy0N20xfJpmqPHatLe9ud6UnHWCSrH/2eSWGduAju6+iDqqrx3Vtt/D4unj0ap0ysx+0XTEtbDKpv/0w1aE7/+DWQxYP6YEjcNEVAaPXkLHhcDtnJJjp5jLvl5svhUBJe6wRdYb+RcflyrMnypf73dqDrq+QST0C3pCbrq9JfT0bHlnj0D5OFXlKbZrGkVh6re5FdSPXJ9VP6wCuT73EgFH+RiTL2gwuPx2UnjbUc7jXUnTS+FtMaq/BRiw/L/vEhgPj6ayYcDgUTR1Tiw+ZubNinjau264KSLf1FPNVEyTG15Xj8K6egptw94NX2xiJZsdNuxgXJI4bB43LA5w9jb3ufbKG1M4NSVebGn647PaOP1Z/vVC3bGSSIC8LpUDDM60JPIAyfP4wRw7wyQEkVvBo1VJfhSG8Qh7r9OL6p2vYbJpA4A2Xi8NS/d8YONfMMSvyGmen3aBezDIoIwEdkcPNu0rVRC502L6mN1p2zMrfDsvXZWE+SNiAc4GxsKsygDCIelwNzxtXaVkCYi8tinSdXnlK44VT5UBQF31ioTd0U84XMfhmtiO6M9/Z2AkhuLx0oCUPxLI7hrKkjMTtWjT+Qqg2D2uQFPMNR5B6XA9NjT30bD3Shu9/+GpRs6JcdUi0pGFuPB5KxUFbWWGV4vkXGShTKFiJAEfUwk0dWWgbMmRSA61t5M60hs4vcqFPXZnwki5lKcolHl0HpLmAGZUZTjeV9ISkgNDnf+iwVAxQalH76b7PwyJdOxo8uPr7Yh5LSxSc0YeaY+Hps1gFKrNVYdJcUK4NS5on/etZWltbMGSCe6RCtqyKDks3eNLPGxrum4ksOxUns6i/iqYYQ/uryOVg0fRSe/kZmWRk7GZ/qsz3f4qbTbFjisXMJ86Fr5uH8GQ14/CunWH6c8Yl+TG1ytkUf4Az0Q5lpBkWc7wwCQv0Sj6hbEjUoteX2PPDoA5QzjrGeqVSRwZKaPrMz0DU/qTBAoayUe5w4e9qoAd+pOBsOh5LQJZPNEg+QPI+hFJZ4hpVAy5+RmKGwpbkbnX1BXQ1K5he340fHi5LFwCmrbFEhlWWwjcPEEZX472tPxtwJAzeTQ4i3vmo3uviU5MzO9zGxwHvLQW1vpy5RtGnjwMU542rxuy/OS/s7Z2y1TZV1+/y8cajyumT93UAR51rfNdUuuwIzWOKJZVB6gxH5GnZnrPRZjrnpCsB1wbfTkTxhWbxdKNY1z4gBCh2VzpoSnzFinK+QzjnTRiWk+4uWQdHdMI0p2lLQWFOGKaOGQVW1/VKOZFkTAcSzVR8f7pUTSFPV2xRaRQYZlGISxcPiRpftEo9owX9vb0dCUXIxfr4dDkUOBgNSn+87PzML7/5wUVLHSqEZl9P8oYicKp1JBqXc45S/B3uP9CEQjsgRDXYFhG6nA987/zh88bQJpjsrG49HaKwuM52Zcs60URhZ5cWi6Q1FnR6rV3qPZUQ2mD66ClecPE4bX59lRfowrwufnNmIZ9YfAFC8kf76zb9KMUABgAVTR2J7aw/+sbFZPtFns359zEitpmNfR5+8UWazRGQnfcaq1LZxAIBJI4bhta2H8faudnz+5PFZ7TMFADPHVMPjdOBIbxB72/uKGqAAkO3IQOrCaEVRijKxWtSgBGJt3fpprVUZtpfPaKrGP7e34b19HWio0a5BioKMPz8TYmPCdPTBd6psVVWZG2tuOychcCw2ZlDoqKQoCu78zAlYftmsnJ4Gzjgm/kRSCulO49yIUiHG9a/Ycggb92tt2RMsujeMRgzzoLrMBVWN74FTrAxKJks8xXTBLG0fs5VbDuGwLyCfyDMNwL0up5xNsulAt64LqPj1BsUs/DdTVeaSv/cb9nbqlncya6EHgHmxZcC1uzsSCmQHuuAXAMrd8aDIqujfbbHBYzEwQCEyod8Izq7N1HIxb0IdXA4FZx83qmjHYGVGUzWmj65GMByVA9smZDGSXFGUpKFRxcqg6G+SxercsjJ3fB2aasrg84fxq5e3AdCCk2xGkk9tiHdNie6rTJYshhqHQ8G507XfuZc2H9IVJGcezJ08UVtSW7+nAx02D2nLVmIBePEfuDLFAIXIxNi6chmYHNdQvC0Ynvraafhg6eKSvGECWoBx2wXTEt6W7ZLa+TMaE/5erAyKfp+pgR56lwmHQ8FXPzEZAPDk23sBWM8aMSMClDd3aiPPPU6HrUsORxPxc/nS5hbZ0ZdNMDcz1qF2oLMfOw/HxtFnUUBuJ30GtlSvJWYYoBCZUBQF/7r1HLx884IBHyGv53I6SmLTLivGTQ+zTRFfe/rEhL8Xa3KvX7fPVCmlufWuOmU8xusyVFbDucxMjc2deX9fJwBtia1Uv9diO2vKSJS5HTjQ2Y9/bGwGkN3yZXWZG02xVuB/7dACwpFFClBKvb4qFQYoRCmMrPLiWJM9KyjZDbFivXOmZb8UVe5xJozpttqVtZAGw4W73OPEjz89Q/4923S9cRx6Ni3hQ025x4mFU7Wf59e3HgagFSpnQ+zovHpHG4Dss4t2KfUOtVRK+9GMiAaFm8+bimmjq3BKmnkMqSw4biQ+iu2dVCxXnjIeG/Z15hRkDaSFU0fC7VQQiqg4ZZL1gC6jhuoyLD6+ASu2HAJQGvUnxazxSufLZ0zEi5tb5N/FlOlMHddYjde2HpYFycUKUMo9gzODwgCFiPJmHI6XrZvOnYJDXX4sOG5k+g8ukDK3E7++4sSiff1MKYqCN245G+/sasei6dkHU987/zgZoJRCd9jMptS78BbbqZOH49NzmvCXDQcBQO6QnqkFU0figVUfy78XrQZF18UzkLtw56t0Q1ciGjIqPC7cc8WJ+LcTxxb7UAaF0TXl+PScMTnVj+iXLfe299l5WFl5/oYzcMnsJvzmytIOCv/9zMny/7PdNuP0Y4bjwlmj5d9LIYNSjLkyuWKAQkQ0hCiKgpvOnQIAuOncqUU7jhPG1uI3V56Y9VYUA23W2Bo8/pVT8PQ3Ts+pPurTc+KZxUw30rSbfhmtFGf8pDJ4cj1ERGSLJYum4OpTxxftiX6wOWtq7kuPZ06JD31sqh3Ykf16P7r4eBzqDuD4El5SM2KAQkQ0xCiKUtT2+aGkwuPC09+Yj+7+UFbbQNjty2dMKtrXzhUDFCIiogKaO6Gu2IcwKLEGhYiIiEoOAxQiIiIqOQxQiIiIqOQwQCEiIqKSwwCFiIiISg4DFCIiIio5DFCIiIio5DBAISIiopLDAIWIiIhKDgMUIiIiKjkMUIiIiKjkMEAhIiKiksMAhYiIiErOoNzNWFVVAEB3d3eRj4SIiIgyJe7b4j5uZVAGKD6fDwAwbty4Ih8JERERZcvn86GmpsbyYxQ1kzCmxESjURw8eBBVVVVQFMXW1+7u7sa4ceOwb98+VFdX2/raRwueo8zwPKXHc5Qez1F6PEeZKYXzpKoqfD4fmpqa4HBYV5kMygyKw+HA2LFjC/o1qqur+YOeBs9RZnie0uM5So/nKD2eo8wU+zyly5wILJIlIiKiksMAhYiIiEoOAxQDr9eLH/3oR/B6vcU+lJLFc5QZnqf0eI7S4zlKj+coM4PtPA3KIlkiIiI6ujGDQkRERCWHAQoRERGVHAYoREREVHIYoBAREVHJYYCi89vf/haTJk1CWVkZ5s6di3/+85/FPqQB88Ybb+Diiy9GU1MTFEXBc889l/B+VVWxdOlSNDU1oby8HAsXLsTmzZsTPiYQCODGG2/EiBEjUFlZiUsuuQT79+8fwO+isJYvX46TTz4ZVVVVGDVqFC699FJs3bo14WN4noD7778fJ5xwghwGdfrpp+OFF16Q7+c5SrZ8+XIoioIlS5bItw3187R06VIoipLwp7GxUb5/qJ8f4cCBA/jCF76A4cOHo6KiAnPmzMG6devk+wf1eVJJVVVVfeqpp1S3260+9NBD6pYtW9SbbrpJraysVPfs2VPsQxsQ//jHP9Q77rhDffrpp1UA6rPPPpvw/jvvvFOtqqpSn376aXXjxo3q5z//eXX06NFqd3e3/JjrrrtOHTNmjLpy5Up1/fr16tlnn63Onj1bDYfDA/zdFMb555+vPvLII+qmTZvUDRs2qBdeeKE6fvx4taenR34Mz5OqPv/88+rf//53devWrerWrVvV73//+6rb7VY3bdqkqirPkdE777yjTpw4UT3hhBPUm266Sb59qJ+nH/3oR+qMGTPU5uZm+ae1tVW+f6ifH1VV1fb2dnXChAnql770JfXtt99Wd+3apb788svqjh075McM5vPEACXmlFNOUa+77rqEt02bNk297bbbinRExWMMUKLRqNrY2Kjeeeed8m1+v1+tqalRH3jgAVVVVbWzs1N1u93qU089JT/mwIEDqsPhUF988cUBO/aB1NraqgJQV61apaoqz5OVuro69b//+795jgx8Pp86ZcoUdeXKleqCBQtkgMLzpAUos2fPNn0fz4/m1ltvVc8888yU7x/s54lLPACCwSDWrVuHxYsXJ7x98eLFWLNmTZGOqnTs2rULLS0tCefH6/ViwYIF8vysW7cOoVAo4WOampowc+bMo/YcdnV1AQDq6+sB8DyZiUQieOqpp9Db24vTTz+d58jgm9/8Ji688EIsWrQo4e08T5rt27ejqakJkyZNwhVXXIGdO3cC4PkRnn/+ecybNw+f+9znMGrUKJx44ol46KGH5PsH+3ligAKgra0NkUgEDQ0NCW9vaGhAS0tLkY6qdIhzYHV+Wlpa4PF4UFdXl/JjjiaqquLmm2/GmWeeiZkzZwLgedLbuHEjhg0bBq/Xi+uuuw7PPvssjj/+eJ4jnaeeegrr16/H8uXLk97H8wSceuqpePzxx/HSSy/hoYceQktLC+bPn48jR47w/MTs3LkT999/P6ZMmYKXXnoJ1113Hb71rW/h8ccfBzD4f44G5W7GhaIoSsLfVVVNettQlsv5OVrP4Q033IAPPvgAq1evTnofzxNw3HHHYcOGDejs7MTTTz+Na6+9FqtWrZLvH+rnaN++fbjpppuwYsUKlJWVpfy4oXyeLrjgAvn/s2bNwumnn45jjjkGjz32GE477TQAQ/v8AEA0GsW8efOwbNkyAMCJJ56IzZs34/7778c111wjP26wnidmUACMGDECTqczKVpsbW1NijyHIlE5b3V+GhsbEQwG0dHRkfJjjhY33ngjnn/+ebz22msYO3asfDvPU5zH48Gxxx6LefPmYfny5Zg9ezZ+/etf8xzFrFu3Dq2trZg7dy5cLhdcLhdWrVqF3/zmN3C5XPL7HOrnSa+yshKzZs3C9u3b+XMUM3r0aBx//PEJb5s+fTr27t0LYPBfkxigQLuYzp07FytXrkx4+8qVKzF//vwiHVXpmDRpEhobGxPOTzAYxKpVq+T5mTt3Ltxud8LHNDc3Y9OmTUfNOVRVFTfccAOeeeYZvPrqq5g0aVLC+3meUlNVFYFAgOco5txzz8XGjRuxYcMG+WfevHm4+uqrsWHDBkyePJnnySAQCODDDz/E6NGj+XMUc8YZZySNOti2bRsmTJgA4Ci4Jg18XW5pEm3GDz/8sLplyxZ1yZIlamVlpbp79+5iH9qA8Pl86nvvvae+9957KgD17rvvVt977z3ZZn3nnXeqNTU16jPPPKNu3LhRvfLKK01b1caOHau+/PLL6vr169VzzjmnJFrV7PKNb3xDrampUV9//fWE1se+vj75MTxPqnr77berb7zxhrpr1y71gw8+UL///e+rDodDXbFihaqqPEep6Lt4VJXn6Tvf+Y76+uuvqzt37lTfeust9aKLLlKrqqrkNXmonx9V1VrUXS6X+tOf/lTdvn27+oc//EGtqKhQn3jiCfkxg/k8MUDR+a//+i91woQJqsfjUU866STZPjoUvPbaayqApD/XXnutqqpau9qPfvQjtbGxUfV6vepZZ52lbty4MeE1+vv71RtuuEGtr69Xy8vL1Ysuukjdu3dvEb6bwjA7PwDURx55RH4Mz5OqfuUrX5G/RyNHjlTPPfdcGZyoKs9RKsYAZaifJzGvw+12q01NTepll12mbt68Wb5/qJ8f4a9//as6c+ZM1ev1qtOmTVMffPDBhPcP5vOkqKqqFid3Q0RERGSONShERERUchigEBERUclhgEJEREQlhwEKERERlRwGKERERFRyGKAQERFRyWGAQkRERCWHAQoRERGVHAYoREREVHIYoBAREVHJYYBCREREJYcBChEREZWc/x8dioQgB5Z59QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(moving_average(res[0], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  14340 MiB |  29047 MiB |  28681 GiB |  28667 GiB |\n",
      "|       from large pool |  14340 MiB |  29037 MiB |  28389 GiB |  28375 GiB |\n",
      "|       from small pool |      0 MiB |    186 MiB |    291 GiB |    291 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  14340 MiB |  29047 MiB |  28681 GiB |  28667 GiB |\n",
      "|       from large pool |  14340 MiB |  29037 MiB |  28389 GiB |  28375 GiB |\n",
      "|       from small pool |      0 MiB |    186 MiB |    291 GiB |    291 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  14340 MiB |  29021 MiB |  28337 GiB |  28323 GiB |\n",
      "|       from large pool |  14340 MiB |  29012 MiB |  28045 GiB |  28031 GiB |\n",
      "|       from small pool |      0 MiB |    186 MiB |    291 GiB |    291 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  14636 MiB |  37110 MiB |  37112 MiB |  22476 MiB |\n",
      "|       from large pool |  14620 MiB |  36916 MiB |  36916 MiB |  22296 MiB |\n",
      "|       from small pool |     16 MiB |    194 MiB |    196 MiB |    180 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 302159 KiB |   6724 MiB |  21948 GiB |  21947 GiB |\n",
      "|       from large pool | 286464 KiB |   6718 MiB |  21643 GiB |  21643 GiB |\n",
      "|       from small pool |  15695 KiB |    146 MiB |    304 GiB |    304 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     408    |    1898    |    5152 K  |    5152 K  |\n",
      "|       from large pool |     292    |    1143    |    3333 K  |    3333 K  |\n",
      "|       from small pool |     116    |     974    |    1819 K  |    1819 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     408    |    1898    |    5152 K  |    5152 K  |\n",
      "|       from large pool |     292    |    1143    |    3333 K  |    3333 K  |\n",
      "|       from small pool |     116    |     974    |    1819 K  |    1819 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     236    |     621    |     622    |     386    |\n",
      "|       from large pool |     228    |     524    |     524    |     296    |\n",
      "|       from small pool |       8    |      97    |      98    |      90    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      87    |     400    |    3164 K  |    3164 K  |\n",
      "|       from large pool |      67    |     335    |    2158 K  |    2158 K  |\n",
      "|       from small pool |      20    |     219    |    1005 K  |    1005 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
