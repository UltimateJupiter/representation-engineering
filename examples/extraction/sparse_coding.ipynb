{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rep-reading is already registered. Overwriting pipeline for task rep-reading...\n",
      "rep-control is already registered. Overwriting pipeline for task rep-control...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/scratch/network/yc6206/representation-engineering')\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import copy\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pynvml\n",
    "import pickle\n",
    "\n",
    "from repe import repe_pipeline_registry\n",
    "repe_pipeline_registry()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    print(pynvml.nvmlDeviceGetName(handle))\n",
    "\n",
    "from sklearn.decomposition import DictionaryLearning\n",
    "from sklearn.decomposition import SparseCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag = \"USER:\"\n",
    "assistant_tag = \"ASSISTANT:\"\n",
    "\n",
    "# Uncomment for first time loading the dataset\n",
    "# ds = load_dataset('tatsu-lab/alpaca', cache_dir='../../storage/cache')\n",
    "# ds.save_to_disk(\"../../storage/cache/alpaca_filtered/\")\n",
    "\n",
    "ds = load_from_disk('../../storage/cache/alpaca_filtered/')\n",
    "instructions = ds['train']['instruction']\n",
    "outputs = ds['train']['output']\n",
    "\n",
    "control_template = \"{type}\"\n",
    "template = \"{user_tag} {instruction} {type} {assistant_tag} {response}\"\n",
    "# Not sure why they set this offset\n",
    "cutoff_offset = 5\n",
    "\n",
    "def get_augmented_ds(instructions, responses, num_examples, user_tag, assistant_tag, aug_prompt, control_template, max_res_len):\n",
    "    \n",
    "    ds = []\n",
    "    for p, s in zip(instructions, responses):\n",
    "        # Replaced \\n since it resulted in nontrivial peak\n",
    "        # s_tokens = tokenizer.tokenize(s)\n",
    "        s_tokens = tokenizer.tokenize(s.replace(\"\\n\", \"\"))\n",
    "        for cutoff in range(1, min(max_res_len, len(s_tokens)) - cutoff_offset):\n",
    "            s_truncated = tokenizer.convert_tokens_to_string(s_tokens[:cutoff])\n",
    "            ds.append(template.format(\n",
    "                user_tag=user_tag,\n",
    "                assistant_tag=assistant_tag,\n",
    "                instruction=p,\n",
    "                type=control_template.format(type=aug_prompt),\n",
    "                response=s_truncated\n",
    "            ))\n",
    "            if len(ds) >= num_examples:\n",
    "                break\n",
    "        if len(ds) >= num_examples:\n",
    "            break\n",
    "    return ds\n",
    "\n",
    "def get_contrastive_ds(instructions, responses, num_examples, user_tag, assistant_tag, pos_type, neg_type, control_template, max_res_len):\n",
    "    \n",
    "    pos_s = get_augmented_ds(instructions, responses, num_examples, user_tag, assistant_tag, pos_type, control_template, max_res_len)\n",
    "    neg_s = get_augmented_ds(instructions, responses, num_examples, user_tag, assistant_tag, neg_type, control_template, max_res_len)\n",
    "    assert len(pos_s) == len(neg_s)\n",
    "    \n",
    "    contrastive_ds = []\n",
    "    for i in range(len(pos_s)):\n",
    "        contrastive_ds.append(pos_s[i])\n",
    "        contrastive_ds.append(neg_s[i])\n",
    "    return contrastive_ds\n",
    "\n",
    "def get_rep_directions(aug_prompt, num_examples=2048, max_res_len=64, batch_size=32, rep_token=-1, verbose=False):\n",
    "    augmented_ds = get_augmented_ds(\n",
    "        instructions,\n",
    "        outputs,\n",
    "        num_examples,\n",
    "        user_tag,\n",
    "        assistant_tag,\n",
    "        aug_prompt,\n",
    "        control_template,\n",
    "        max_res_len\n",
    "    )\n",
    "\n",
    "    hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "    rep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "    if verbose:\n",
    "        print(f\"Computing Rep Activation {aug_prompt}\")\n",
    "\n",
    "    hidden_reps = rep_reading_pipeline._batched_string_to_hiddens(\n",
    "        train_inputs=augmented_ds,\n",
    "        rep_token=rep_token,\n",
    "        hidden_layers=hidden_layers,\n",
    "        batch_size=batch_size,\n",
    "        which_hidden_states=None\n",
    "    )\n",
    "    \n",
    "    for k in hidden_reps:\n",
    "        hidden_reps[k] = torch.Tensor(hidden_reps[k]).to(device)\n",
    "\n",
    "    return hidden_reps, augmented_ds\n",
    "\n",
    "def get_rep_reader(pos_type, neg_type, num_examples=2048, max_res_len=64, rep_token=-1, verbose=False):\n",
    "    contrastive_ds = get_contrastive_ds(\n",
    "        instructions,\n",
    "        outputs,\n",
    "        num_examples,\n",
    "        user_tag,\n",
    "        assistant_tag,\n",
    "        pos_type,\n",
    "        neg_type,\n",
    "        control_template,\n",
    "        max_res_len\n",
    "    )\n",
    "    contrastive_ds_train = contrastive_ds\n",
    "\n",
    "    hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "    n_difference = 1\n",
    "    direction_method = 'pca'\n",
    "    rep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)\n",
    "    if verbose:\n",
    "        print(f\"Computing Rep {pos_type} - {neg_type}\")\n",
    "\n",
    "    rep_reader = rep_reading_pipeline.get_directions(\n",
    "        contrastive_ds_train,\n",
    "        rep_token=rep_token, \n",
    "        hidden_layers=hidden_layers, \n",
    "        n_difference=n_difference, \n",
    "        train_labels=None, \n",
    "        direction_method=direction_method,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    return rep_reader.directions, contrastive_ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/network/yc6206/representation-engineering/examples/extraction/reading_vecs_sc.pickle', 'rb') as f:\n",
    "    reading_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = []\n",
    "with open ('list_of_emotions.txt', 'r') as f:\n",
    "    emotions = f.readlines()\n",
    "    emotions = [emotion.strip('\\n') for emotion in emotions]\n",
    "stimulis = {}\n",
    "for emotion in emotions:\n",
    "    stimulis[emotion] = 'Respond with a tone of {}'.format(emotion.lower())\n",
    "stimulis[''] = ''\n",
    "\n",
    "stimuli_pairs_gen = {}\n",
    "for s in stimulis:\n",
    "    if s != '':\n",
    "        stimuli_pairs_gen[s] = [s, '']\n",
    "\n",
    "stimuli_pairs = {k: [stimulis[stimuli_pairs_gen[k][0]], stimulis[stimuli_pairs_gen[k][1]]] for k in stimuli_pairs_gen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_vectors = {}\n",
    "for k in (pbar := tqdm(stimuli_pairs)):\n",
    "    pbar.set_postfix_str(k)\n",
    "    if not k in reading_vectors:\n",
    "        rep_reader, _ = get_rep_reader(stimuli_pairs[k][0], stimuli_pairs[k][1], num_examples=256)\n",
    "        reading_vectors[k] = copy.deepcopy(rep_reader)\n",
    "\n",
    "with open('/scratch/network/yc6206/representation-engineering/examples/extraction/reading_vecs_sc.pickle', 'wb') as f:\n",
    "    pickle.dump(reading_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "with open('/scratch/network/yc6206/representation-engineering/examples/extraction/sparse_coding.pickle', 'rb') as f:\n",
    "    sparse_coding_dict = pickle.load(f)\n",
    "\n",
    "for n_components in (pbar := tqdm(range(5, 105, 5))):\n",
    "    sparse_coding_dict[n_components] = {}\n",
    "    for layer in reading_vectors['Happiness']:\n",
    "        X = []\n",
    "        sparse_coding_dict[n_components][layer] = {}\n",
    "        for emotion in emotions:\n",
    "            X.append(reading_vectors[emotion][layer])\n",
    "        X = np.concatenate(X)\n",
    "        dict_learner = DictionaryLearning(n_components=n_components, transform_algorithm='lasso_lars', transform_alpha=0.1, random_state=42)\n",
    "        dict = dict_learner.fit(X)\n",
    "        sparse_coding_dict[n_components][layer]['dictionary'] = dict.components_\n",
    "        coder = SparseCoder(dictionary=dict.components_, transform_algorithm='lasso_lars', transform_alpha=1e-10)\n",
    "        for emotion in emotions:\n",
    "            sparse_coding_dict[n_components][layer][emotion] = coder.transform(X)\n",
    "\n",
    "with open('/scratch/network/yc6206/representation-engineering/examples/extraction/sparse_coding.pickle', 'wb') as f:\n",
    "    pickle.dump(sparse_coding_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {}\n",
    "tmp[15] = sparse_coding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/scratch/network/yc6206/representation-engineering/examples/extraction/sparse_coding.pickle', 'wb') as f:\n",
    "    pickle.dump(tmp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
